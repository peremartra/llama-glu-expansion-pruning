{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peremartra/llama-glu-expansion-pruning/blob/main/notebooks/00_Expansion_Rate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VLK5XNkz11a"
      },
      "source": [
        "# GLU Pruning Research - Expansion Rate Documentation\n",
        "\n",
        "### Exploring GLU Expansion Ratios in Llama-3.2 Models\n",
        "by [Pere Martra](https://github.com/peremartra)\n",
        "\n",
        "[![Paper](https://img.shields.io/badge/OSF-Paper-blue?logo=osf&logoColor=white)](https://doi.org/10.31219/osf.io/qgxea)\n",
        "[![GitHub](https://img.shields.io/badge/â­_Star-OptiPFair-orange?logo=github&logoColor=white)](https://github.com/peremartra/optipfair)\n",
        "[![PyPI](https://img.shields.io/pypi/v/optipfair?logo=python&logoColor=white&label=v)](https://pypi.org/project/optipfair/)\n",
        "\n",
        "**Repository:** [github.com/peremartra/llama-glu-expansion-pruning](https://github.com/peremartra/llama-glu-expansion-pruning)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“‹ Notebook Objective\n",
        "\n",
        "This notebook documents the **actual expansion rates** achieved after applying width pruning to GLU-MLP layers across all model configurations. It serves as a reference for:\n",
        "\n",
        "1. **Verifying pruning accuracy:** Confirm that each `pruning_pct` produces the expected expansion rate\n",
        "2. **Architecture documentation:** Record detailed layer dimensions for reproducibility\n",
        "3. **Parameter reduction analysis:** Calculate exact parameter savings per model\n",
        "4. **Cross-model comparison:** Compare expansion rates across 1B, 3B, and Instruct variants\n",
        "\n",
        "### Key Features:\n",
        "- âœ… **Automated calculation:** Uses OptIFAIR to recreate all pruned models on-the-fly\n",
        "- âœ… **Complete documentation:** Records all architecture details in structured JSON\n",
        "- âœ… **No external dependencies:** Self-contained, no need for pre-existing model files\n",
        "- âœ… **Reproducibility:** Establishes baseline for all future experiments\n",
        "\n",
        "### Output:\n",
        "- `expansion_rates.json`: Complete architecture details for all 18 model configurations\n",
        "- Summary table with expansion rates and parameter reductions\n",
        "\n",
        "---\n",
        "\n",
        "**Colab Environment:** CPU sufficient (no GPU needed for architecture inspection)\n",
        "\n",
        "**Estimated Runtime:** ~30-45 minutes (depends on download speeds)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD1UlhWnz11b"
      },
      "source": [
        "# 1. Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyMZUljXz11b",
        "outputId": "c0a2bb92-e4bd-44a6-d998-476efca10723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m293.6/293.6 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "âœ… OptIFAIR installed successfully\n"
          ]
        }
      ],
      "source": [
        "# Install OptIFAIR library for structured GLU pruning\n",
        "!pip install -q optipfair\n",
        "!pip install -q lm-eval\n",
        "\n",
        "print(\"âœ… OptIFAIR installed successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2PZ9qEUz11c",
        "outputId": "fe2a636a-11e6-4c2c-9c0f-8e44926449e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… utils.py downloaded successfully\n"
          ]
        }
      ],
      "source": [
        "# Download utils.py from GitHub repository\n",
        "!wget -q https://raw.githubusercontent.com/peremartra/llama-glu-expansion-pruning/main/utils.py\n",
        "\n",
        "# Verify download\n",
        "import os\n",
        "if os.path.exists('utils.py'):\n",
        "    print(\"âœ… utils.py downloaded successfully\")\n",
        "else:\n",
        "    print(\"âŒ Failed to download utils.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8UjTDzBz11c",
        "outputId": "d7ef122e-9955-4814-85bd-36166c0e1b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded 14 model configurations\n",
            "ğŸ“… Timestamp: 2025-11-01 19:12:09\n"
          ]
        }
      ],
      "source": [
        "# Standard imports\n",
        "import json\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from transformers import AutoModelForCausalLM\n",
        "from optipfair import prune_model\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Import experiment configuration\n",
        "from utils import EXPERIMENT_CONFIG\n",
        "\n",
        "print(f\"âœ… Loaded {len(EXPERIMENT_CONFIG)} model configurations\")\n",
        "print(f\"ğŸ“… Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpFIFECJz11c"
      },
      "source": [
        "# 2. Configuration & Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RIsswLUz11c",
        "outputId": "2661672a-adc4-42c7-8e73-5e075a4545e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš™ï¸ Configuration:\n",
            "   Output file: expansion_rates.json\n",
            "   Pruning method: MAW\n",
            "   Pruning type: MLP_GLU\n"
          ]
        }
      ],
      "source": [
        "# Output configuration\n",
        "OUTPUT_FILE = \"expansion_rates.json\"\n",
        "\n",
        "# OptIFAIR pruning parameters (matching paper methodology)\n",
        "PRUNING_CONFIG = {\n",
        "    \"pruning_type\": \"MLP_GLU\",\n",
        "    \"neuron_selection_method\": \"MAW\",  # Maximum Absolute Weight (optimal for GLU)\n",
        "    \"return_stats\": True\n",
        "}\n",
        "\n",
        "# Model loading configuration\n",
        "MODEL_LOAD_CONFIG = {\n",
        "    \"torch_dtype\": torch.bfloat16,\n",
        "    \"device_map\": \"auto\",\n",
        "    \"low_cpu_mem_usage\": True\n",
        "}\n",
        "\n",
        "print(\"âš™ï¸ Configuration:\")\n",
        "print(f\"   Output file: {OUTPUT_FILE}\")\n",
        "print(f\"   Pruning method: {PRUNING_CONFIG['neuron_selection_method']}\")\n",
        "print(f\"   Pruning type: {PRUNING_CONFIG['pruning_type']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FjvbARez11c"
      },
      "source": [
        "# 3. Core Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86uQ5Vcez11c",
        "outputId": "97855e54-48be-42a3-bb6d-48093de67bcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Functions defined\n"
          ]
        }
      ],
      "source": [
        "def get_model_architecture_info(model):\n",
        "    \"\"\"\n",
        "    Extract architecture information from a Llama model.\n",
        "\n",
        "    Args:\n",
        "        model: HuggingFace model instance\n",
        "\n",
        "    Returns:\n",
        "        dict: Architecture details including dimensions and expansion rate\n",
        "    \"\"\"\n",
        "    config = model.config\n",
        "\n",
        "    # Get dimensions from model config\n",
        "    hidden_size = config.hidden_size\n",
        "    intermediate_size = config.intermediate_size\n",
        "    num_hidden_layers = config.num_hidden_layers\n",
        "\n",
        "    # Calculate expansion rate\n",
        "    expansion_rate = intermediate_size / hidden_size\n",
        "\n",
        "    # Count total parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "    return {\n",
        "        \"hidden_size\": hidden_size,\n",
        "        \"intermediate_size\": intermediate_size,\n",
        "        \"num_hidden_layers\": num_hidden_layers,\n",
        "        \"expansion_rate\": round(expansion_rate, 2),\n",
        "        \"expansion_rate_percentage\": round(expansion_rate * 100, 1),\n",
        "        \"total_parameters\": total_params,\n",
        "        \"total_parameters_millions\": round(total_params / 1e6, 2)\n",
        "    }\n",
        "\n",
        "\n",
        "def calculate_expansion_rate_for_config(config_entry):\n",
        "    \"\"\"\n",
        "    Load model, apply pruning, and extract expansion rate information.\n",
        "\n",
        "    Args:\n",
        "        config_entry: Dictionary from EXPERIMENT_CONFIG\n",
        "\n",
        "    Returns:\n",
        "        dict: Complete model information including original and pruned architectures\n",
        "    \"\"\"\n",
        "    base_model_name = config_entry[\"base_model\"]\n",
        "    pruning_pct = config_entry[\"pruning_pct\"]\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Processing: {base_model_name} @ {pruning_pct}% pruning\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    try:\n",
        "        # Load base model\n",
        "        print(f\"ğŸ“¥ Loading base model: {base_model_name}...\")\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            base_model_name,\n",
        "            **MODEL_LOAD_CONFIG\n",
        "        )\n",
        "\n",
        "        # Get original architecture info\n",
        "        print(\"ğŸ“Š Analyzing original architecture...\")\n",
        "        original_arch = get_model_architecture_info(model)\n",
        "        print(f\"   Original expansion rate: {original_arch['expansion_rate_percentage']}%\")\n",
        "        print(f\"   Original parameters: {original_arch['total_parameters_millions']}M\")\n",
        "\n",
        "        # Apply pruning\n",
        "        print(f\"âœ‚ï¸ Applying {pruning_pct}% pruning with MAW method...\")\n",
        "        pruned_model, stats = prune_model(\n",
        "            model=model,\n",
        "            pruning_percentage=pruning_pct,\n",
        "            **PRUNING_CONFIG\n",
        "        )\n",
        "\n",
        "        # Get pruned architecture info\n",
        "        print(\"ğŸ“Š Analyzing pruned architecture...\")\n",
        "        pruned_arch = get_model_architecture_info(pruned_model)\n",
        "        print(f\"   Pruned expansion rate: {pruned_arch['expansion_rate_percentage']}%\")\n",
        "        print(f\"   Pruned parameters: {pruned_arch['total_parameters_millions']}M\")\n",
        "\n",
        "        # Calculate reductions\n",
        "        param_reduction_pct = (\n",
        "            (original_arch['total_parameters'] - pruned_arch['total_parameters'])\n",
        "            / original_arch['total_parameters'] * 100\n",
        "        )\n",
        "\n",
        "        expansion_reduction_pct = (\n",
        "            (original_arch['expansion_rate'] - pruned_arch['expansion_rate'])\n",
        "            / original_arch['expansion_rate'] * 100\n",
        "        )\n",
        "\n",
        "        print(f\"ğŸ“‰ Parameter reduction: {param_reduction_pct:.2f}%\")\n",
        "        print(f\"ğŸ“‰ Expansion reduction: {expansion_reduction_pct:.2f}%\")\n",
        "\n",
        "        # Clean up to free memory\n",
        "        del model\n",
        "        del pruned_model\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Return complete info\n",
        "        return {\n",
        "            \"base_model\": base_model_name,\n",
        "            \"pruning_pct\": pruning_pct,\n",
        "            \"original_architecture\": original_arch,\n",
        "            \"pruned_architecture\": pruned_arch,\n",
        "            \"reductions\": {\n",
        "                \"parameter_reduction_pct\": round(param_reduction_pct, 2),\n",
        "                \"expansion_reduction_pct\": round(expansion_reduction_pct, 2),\n",
        "                \"parameters_saved_millions\": round(\n",
        "                    (original_arch['total_parameters'] - pruned_arch['total_parameters']) / 1e6, 2\n",
        "                )\n",
        "            },\n",
        "            \"optipfair_stats\": stats,\n",
        "            \"status\": \"success\"\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error processing {base_model_name} @ {pruning_pct}%: {str(e)}\")\n",
        "        return {\n",
        "            \"base_model\": base_model_name,\n",
        "            \"pruning_pct\": pruning_pct,\n",
        "            \"status\": \"failed\",\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "print(\"âœ… Functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJqYBD9Nz11c"
      },
      "source": [
        "# 4. Process All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBVRYihyz11c"
      },
      "outputs": [],
      "source": [
        "# Initialize results storage\n",
        "all_results = []\n",
        "\n",
        "print(f\"\\nğŸš€ Starting expansion rate calculation for {len(EXPERIMENT_CONFIG)} models...\\n\")\n",
        "\n",
        "# Process each configuration\n",
        "for i, config in enumerate(tqdm(EXPERIMENT_CONFIG, desc=\"Processing models\")):\n",
        "    print(f\"\\n[{i+1}/{len(EXPERIMENT_CONFIG)}] Processing configuration...\")\n",
        "\n",
        "    result = calculate_expansion_rate_for_config(config)\n",
        "    all_results.append(result)\n",
        "\n",
        "    # Brief status update\n",
        "    if result['status'] == 'success':\n",
        "        print(f\"âœ… Success: {result['pruned_architecture']['expansion_rate_percentage']}% expansion rate\")\n",
        "    else:\n",
        "        print(f\"âŒ Failed: {result.get('error', 'Unknown error')}\")\n",
        "\n",
        "print(f\"\\n\\n{'='*80}\")\n",
        "print(f\"âœ… Completed processing all {len(EXPERIMENT_CONFIG)} models\")\n",
        "print(f\"{'='*80}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vettar5kz11c"
      },
      "source": [
        "# 5. Save Results to JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67iPmsdzz11d",
        "outputId": "7eb69b5b-814a-4886-8c37-79f65eca8fb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ’¾ Results saved to: expansion_rates.json\n",
            "   Total models: 14\n",
            "   Successful: 14\n",
            "   Failed: 0\n"
          ]
        }
      ],
      "source": [
        "# Prepare final JSON structure\n",
        "output_data = {\n",
        "    \"metadata\": {\n",
        "        \"generated_at\": datetime.now().isoformat(),\n",
        "        \"optipfair_version\": \"latest\",  # Could get actual version if needed\n",
        "        \"total_models\": len(all_results),\n",
        "        \"successful\": sum(1 for r in all_results if r['status'] == 'success'),\n",
        "        \"failed\": sum(1 for r in all_results if r['status'] == 'failed'),\n",
        "        \"pruning_method\": PRUNING_CONFIG['neuron_selection_method'],\n",
        "        \"pruning_type\": PRUNING_CONFIG['pruning_type']\n",
        "    },\n",
        "    \"models\": all_results\n",
        "}\n",
        "\n",
        "# Save to JSON file\n",
        "with open(OUTPUT_FILE, 'w') as f:\n",
        "    json.dump(output_data, f, indent=2)\n",
        "\n",
        "print(f\"\\nğŸ’¾ Results saved to: {OUTPUT_FILE}\")\n",
        "print(f\"   Total models: {output_data['metadata']['total_models']}\")\n",
        "print(f\"   Successful: {output_data['metadata']['successful']}\")\n",
        "print(f\"   Failed: {output_data['metadata']['failed']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba-E2C0Cz11d"
      },
      "source": [
        "# 6. Summary Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qbb1aaWDz11d",
        "outputId": "a754afce-59f4-4530-d4c5-c17fdb6f0098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "ğŸ“Š EXPANSION RATE SUMMARY\n",
            "====================================================================================================\n",
            "Model Family  Pruning %  Original Expansion %  Pruned Expansion %  Expansion Reduction %  Original Params (M)  Pruned Params (M)  Param Reduction %  Params Saved (M)\n",
            "          1B         10                 400.0               360.0                  10.00              1235.81            1155.30               6.51             80.51\n",
            "          1B         20                 400.0               320.0                  20.00              1235.81            1074.79              13.03            161.02\n",
            "          1B         30                 400.0               280.0                  30.00              1235.81             994.28              19.54            241.53\n",
            "          1B         40                 400.0               240.0                  40.00              1235.81             913.77              26.06            322.04\n",
            "          1B         50                 400.0               200.0                  50.00              1235.81             833.16              32.58            402.65\n",
            "          1B         60                 400.0               160.0                  60.00              1235.81             752.65              39.10            483.16\n",
            " 1B-Instruct         40                 400.0               240.0                  40.00              1235.81             913.77              26.06            322.04\n",
            " 1B-Instruct         60                 400.0               160.0                  60.00              1235.81             752.65              39.10            483.16\n",
            "          3B         10                 266.7               240.0                  10.11              3212.75            3001.41               6.58            211.34\n",
            "          3B         20                 266.7               213.3                  20.22              3212.75            2790.07              13.16            422.68\n",
            "          3B         30                 266.7               186.7                  29.96              3212.75            2578.73              19.73            634.02\n",
            "          3B         40                 266.7               160.0                  40.07              3212.75            2367.38              26.31            845.37\n",
            "          3B         50                 266.7               133.3                  50.19              3212.75            2155.79              32.90           1056.96\n",
            "          3B         60                 266.7               106.7                  59.93              3212.75            1944.44              39.48           1268.31\n",
            "====================================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Create summary dataframe for successful models\n",
        "successful_results = [r for r in all_results if r['status'] == 'success']\n",
        "\n",
        "summary_data = []\n",
        "for result in successful_results:\n",
        "    # Extract model family (1B, 3B, 1B-I, 3B-I)\n",
        "    base_name = result['base_model'].split('/')[-1]\n",
        "    if '1B-Instruct' in base_name:\n",
        "        family = '1B-Instruct'\n",
        "    elif '3B-Instruct' in base_name:\n",
        "        family = '3B-Instruct'\n",
        "    elif '1B' in base_name:\n",
        "        family = '1B'\n",
        "    else:\n",
        "        family = '3B'\n",
        "\n",
        "    summary_data.append({\n",
        "        'Model Family': family,\n",
        "        'Pruning %': result['pruning_pct'],\n",
        "        'Original Expansion %': result['original_architecture']['expansion_rate_percentage'],\n",
        "        'Pruned Expansion %': result['pruned_architecture']['expansion_rate_percentage'],\n",
        "        'Expansion Reduction %': result['reductions']['expansion_reduction_pct'],\n",
        "        'Original Params (M)': result['original_architecture']['total_parameters_millions'],\n",
        "        'Pruned Params (M)': result['pruned_architecture']['total_parameters_millions'],\n",
        "        'Param Reduction %': result['reductions']['parameter_reduction_pct'],\n",
        "        'Params Saved (M)': result['reductions']['parameters_saved_millions']\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "# Sort by model family and pruning percentage\n",
        "summary_df = summary_df.sort_values(['Model Family', 'Pruning %'])\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"ğŸ“Š EXPANSION RATE SUMMARY\")\n",
        "print(\"=\"*100)\n",
        "print(summary_df.to_string(index=False))\n",
        "print(\"=\"*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOLQBx9nz11d"
      },
      "source": [
        "# 7. Model Family Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuGFbjbuz11d",
        "outputId": "91cc1466-90ae-45de-d249-b4648ef505d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "ğŸ“Š COMPARISON BY MODEL FAMILY\n",
            "====================================================================================================\n",
            "\n",
            "ğŸ”¹ 1B Model Family:\n",
            "   Base expansion rate: 400.0%\n",
            "   Base parameters: 1235.81M\n",
            "\n",
            "   Pruned variants:\n",
            "      10% pruning â†’ 360.0% expansion ( 1155M params, 6.5% reduction)\n",
            "      20% pruning â†’ 320.0% expansion ( 1075M params, 13.0% reduction)\n",
            "      30% pruning â†’ 280.0% expansion (  994M params, 19.5% reduction)\n",
            "      40% pruning â†’ 240.0% expansion (  914M params, 26.1% reduction)\n",
            "      50% pruning â†’ 200.0% expansion (  833M params, 32.6% reduction)\n",
            "      60% pruning â†’ 160.0% expansion (  753M params, 39.1% reduction)\n",
            "\n",
            "ğŸ”¹ 1B-Instruct Model Family:\n",
            "   Base expansion rate: 400.0%\n",
            "   Base parameters: 1235.81M\n",
            "\n",
            "   Pruned variants:\n",
            "      40% pruning â†’ 240.0% expansion (  914M params, 26.1% reduction)\n",
            "      60% pruning â†’ 160.0% expansion (  753M params, 39.1% reduction)\n",
            "\n",
            "ğŸ”¹ 3B Model Family:\n",
            "   Base expansion rate: 266.7%\n",
            "   Base parameters: 3212.75M\n",
            "\n",
            "   Pruned variants:\n",
            "      10% pruning â†’ 240.0% expansion ( 3001M params, 6.6% reduction)\n",
            "      20% pruning â†’ 213.3% expansion ( 2790M params, 13.2% reduction)\n",
            "      30% pruning â†’ 186.7% expansion ( 2579M params, 19.7% reduction)\n",
            "      40% pruning â†’ 160.0% expansion ( 2367M params, 26.3% reduction)\n",
            "      50% pruning â†’ 133.3% expansion ( 2156M params, 32.9% reduction)\n",
            "      60% pruning â†’ 106.7% expansion ( 1944M params, 39.5% reduction)\n",
            "\n",
            "====================================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Group by model family for comparison\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"ğŸ“Š COMPARISON BY MODEL FAMILY\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "for family in sorted(summary_df['Model Family'].unique()):\n",
        "    family_df = summary_df[summary_df['Model Family'] == family]\n",
        "\n",
        "    print(f\"\\nğŸ”¹ {family} Model Family:\")\n",
        "    print(f\"   Base expansion rate: {family_df.iloc[0]['Original Expansion %']}%\")\n",
        "    print(f\"   Base parameters: {family_df.iloc[0]['Original Params (M)']}M\")\n",
        "    print(f\"\\n   Pruned variants:\")\n",
        "\n",
        "    for _, row in family_df.iterrows():\n",
        "        print(f\"      {row['Pruning %']:2d}% pruning â†’ {row['Pruned Expansion %']:5.1f}% expansion \"\n",
        "              f\"({row['Pruned Params (M)']:5.0f}M params, {row['Param Reduction %']:.1f}% reduction)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea-D-CKlz11d"
      },
      "source": [
        "# 8. Target Expansion Rate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "612xa_Qzz11d"
      },
      "outputs": [],
      "source": [
        "# Identify which models achieve the target 140% expansion rate\n",
        "TARGET_EXPANSION = 140.0\n",
        "\n",
        "print(f\"\\n{'='*100}\")\n",
        "print(f\"ğŸ¯ TARGET EXPANSION RATE: {TARGET_EXPANSION}%\")\n",
        "print(f\"{'='*100}\\n\")\n",
        "\n",
        "# Find models closest to target\n",
        "summary_df['Distance from Target'] = abs(summary_df['Pruned Expansion %'] - TARGET_EXPANSION)\n",
        "\n",
        "for family in sorted(summary_df['Model Family'].unique()):\n",
        "    family_df = summary_df[summary_df['Model Family'] == family]\n",
        "    closest = family_df.loc[family_df['Distance from Target'].idxmin()]\n",
        "\n",
        "    print(f\"ğŸ”¹ {family}:\")\n",
        "    print(f\"   Closest model: {closest['Pruning %']}% pruning\")\n",
        "    print(f\"   Achieved expansion: {closest['Pruned Expansion %']}%\")\n",
        "    print(f\"   Distance from target: {closest['Distance from Target']:.1f}%\")\n",
        "    print()\n",
        "\n",
        "print(f\"{'='*100}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvaUjyUmz11d"
      },
      "source": [
        "# 9. Export Summary to CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQi34jrfz11d"
      },
      "outputs": [],
      "source": [
        "# Save summary table to CSV for easy reference\n",
        "csv_filename = \"expansion_rates_summary.csv\"\n",
        "summary_df.drop('Distance from Target', axis=1, inplace=True)  # Remove helper column\n",
        "summary_df.to_csv(csv_filename, index=False)\n",
        "\n",
        "print(f\"ğŸ“Š Summary table exported to: {csv_filename}\")\n",
        "print(f\"\\nâœ… All analysis complete!\")\n",
        "print(f\"\\nğŸ“ Output files:\")\n",
        "print(f\"   - {OUTPUT_FILE} (complete architecture details)\")\n",
        "print(f\"   - {csv_filename} (summary table)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}