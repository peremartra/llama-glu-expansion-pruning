{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peremartra/llama-glu-expansion-pruning/blob/main/notebooks/02_Evaluate_1B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzfjNg_SIvXD"
      },
      "source": [
        "# GLU Pruning Research - Llama-3.2-1B Evaluation\n",
        "## 02 - Comprehensive Benchmark Suite Evaluation\n",
        "\n",
        "### Exploring GLU Expansion Ratios in Llama-3.2 Models\n",
        "by [Pere Martra](https://github.com/peremartra)\n",
        "\n",
        "[![Paper](https://img.shields.io/badge/OSF-Paper-blue?logo=osf&logoColor=white)](https://doi.org/10.31219/osf.io/qgxea)\n",
        "[![GitHub](https://img.shields.io/badge/â­_Star-OptiPFair-orange?logo=github&logoColor=white)](https://github.com/peremartra/optipfair)\n",
        "[![PyPI](https://img.shields.io/pypi/v/optipfair?logo=python&logoColor=white&label=v)](https://pypi.org/project/optipfair/)\n",
        "\n",
        "**Repository:** [github.com/peremartra/llama-glu-expansion-pruning](https://github.com/peremartra/llama-glu-expansion-pruning)\n",
        "\n",
        "---\n",
        "\n",
        "**Colab Environment:** GPU L4 (or T4)\n",
        "\n",
        "**Models to Evaluate:**\n",
        "* Llama-3.2-1B (base) - Baseline\n",
        "* Llama-3.2-1B-pruned-20% (220% expansion)\n",
        "* Llama-3.2-1B-pruned-40% (140% expansion) â­ Star model\n",
        "* Llama-3.2-1B-pruned-60% (60% expansion)\n",
        "\n",
        "**Benchmarks (10 total):**\n",
        "* WikiText-2 Perplexity (0-shot)\n",
        "* BoolQ (0-shot)\n",
        "* Lambada-OpenAI (0-shot)\n",
        "* MMLU (5-shot)\n",
        "* ARC-Challenge (0-shot)\n",
        "* HellaSwag (0-shot)\n",
        "* WinoGrande (0-shot)\n",
        "* PIQA (0-shot)\n",
        "* TruthfulQA MC1/MC2 (0-shot)\n",
        "* GSM8K (5-shot CoT)\n",
        "\n",
        "**Estimated Runtime:** ~4-5 hours total\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“‹ Notebook Objective\n",
        "\n",
        "This notebook conducts a comprehensive evaluation of the Llama-3.2-1B model family across three pruning levels (20%, 40%, 60%) to determine:\n",
        "\n",
        "1. **Performance degradation patterns** across different pruning intensities\n",
        "2. **Optimal expansion ratio** for GLU-MLP layers (hypothesis: 140%)\n",
        "3. **Task-specific resilience** to pruning (knowledge vs. algorithmic tasks)\n",
        "4. **Which models merit uploading to HuggingFace Hub** for Phase 2\n",
        "\n",
        "### Key Features:\n",
        "- âœ… **Checkpoint/Resume Support:** Survives Colab disconnections\n",
        "- âœ… **On-the-fly Pruning:** No need to pre-create models\n",
        "- âœ… **Robust Error Handling:** Continues if individual benchmarks fail\n",
        "- âœ… **Progress Tracking:** Live updates and detailed logging\n",
        "\n",
        "### Results will answer:\n",
        "- Does 40% pruning (140% expansion) truly outperform other levels?\n",
        "- Which benchmarks are most sensitive to pruning?\n",
        "- Should we upload non-star models to HF, or only the 40% version?\n",
        "\n",
        "---\n",
        "\n",
        "**Note:** This evaluation uses the MAW (Maximum Absolute Weight) neuron selection method, validated in Notebook 00 as the optimal approach for GLU architectures.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkVFbeCMIvXF"
      },
      "source": [
        "# 1. Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nAo67s0lIvXF",
        "outputId": "fcc0fec9-8e7a-4d45-d800-8b78d934d358",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m293.6/293.6 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install -q optipfair\n",
        "!pip install -q lm-eval\n",
        "!pip install -q langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWIHQuIGIvXG",
        "outputId": "60623ec2-4d82-4c25-c3ac-f9135787205f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive for checkpoint persistence\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG2nO7YpIvXG",
        "outputId": "2beedbd0-89ea-4141-dbb6-6a3cac0331d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… utils.py downloaded successfully\n"
          ]
        }
      ],
      "source": [
        "# Download utils.py from GitHub repository\n",
        "!wget -q https://raw.githubusercontent.com/peremartra/llama-glu-expansion-pruning/main/utils.py\n",
        "\n",
        "# Verify download\n",
        "import os\n",
        "if os.path.exists('utils.py'):\n",
        "    print(\"âœ… utils.py downloaded successfully\")\n",
        "else:\n",
        "    print(\"âŒ Failed to download utils.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHjkx6_QIvXG",
        "outputId": "c200e528-3fd0-47dc-ec52-cda5f382b062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All imports successful\n",
            "ğŸ“± Device: GPU\n",
            "   GPU: NVIDIA L4\n",
            "   Memory: 23.8 GB\n"
          ]
        }
      ],
      "source": [
        "# Import core libraries and utilities\n",
        "import torch\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# Import our utility functions\n",
        "from utils import (\n",
        "    EXPERIMENT_CONFIG,\n",
        "    BENCHMARKS_BASE,\n",
        "    load_or_create_model,\n",
        "    run_robust_evaluation,\n",
        "    clear_gpu_cache,\n",
        "    get_model_stats,\n",
        "    format_results_table\n",
        ")\n",
        "\n",
        "print(\"âœ… All imports successful\")\n",
        "print(f\"ğŸ“± Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LixoDuXJIvXG"
      },
      "source": [
        "# 2. Configuration & Planning\n",
        "\n",
        "This section filters the experiment configuration for 1B models and displays the evaluation plan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5fDt6IxIvXG",
        "outputId": "2186645b-6678-466a-a57c-716430e8f6d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ğŸ“Š EVALUATION PLAN: Llama-3.2-1B Family\n",
            "======================================================================\n",
            "\n",
            "Total models to evaluate: 7\n",
            "Benchmarks per model: 13\n",
            "Total evaluations: 91\n",
            "Estimated runtime: ~4-5 hours\n",
            "\n",
            "Models to evaluate:\n",
            "----------------------------------------------------------------------\n",
            "Model                          Pruning    Star  \n",
            "----------------------------------------------------------------------\n",
            "Llama-3.2-1B (baseline)        0%         300%         N/A   \n",
            "Llama-3.2-1B-pruned-10pct      10%        No    \n",
            "Llama-3.2-1B-pruned-20pct      20%        No    \n",
            "Llama-3.2-1B-pruned-30pct      30%        No    \n",
            "Llama-3.2-1B-pruned-40pct      40%        â­ Yes \n",
            "Llama-3.2-1B-pruned-50pct      50%        No    \n",
            "Llama-3.2-1B-pruned-60pct      60%        No    \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Benchmarks to run:\n",
            "----------------------------------------------------------------------\n",
            " 1. wikitext                  0-shot\n",
            " 2. boolq                     0-shot\n",
            " 3. lambada_openai            0-shot\n",
            " 4. mmlu                      5-shot\n",
            " 5. arc_challenge             0-shot\n",
            " 6. hellaswag                 0-shot\n",
            " 7. winogrande                0-shot\n",
            " 8. piqa                      0-shot\n",
            " 9. truthfulqa_mc1            0-shot\n",
            "10. truthfulqa_mc2            0-shot\n",
            "11. gsm8k                     5-shot\n",
            "12. ifeval                    0-shot\n",
            "13. musr                      0-shot\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "âš™ï¸  Configuration:\n",
            "   - Neuron selection method: MAW (Maximum Absolute Weight)\n",
            "   - Checkpointing: Enabled (per-task granularity)\n",
            "   - Model creation: On-the-fly pruning (no pre-creation needed)\n",
            "   - Error handling: Skip failed tasks and continue\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Filter configuration for 1B models only\n",
        "models_1b = [\n",
        "    config for config in EXPERIMENT_CONFIG\n",
        "    if \"1B\" in config[\"base_model\"] and \"3B\" not in config[\"base_model\"]\n",
        "]\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"ğŸ“Š EVALUATION PLAN: Llama-3.2-1B Family\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "print(f\"Total models to evaluate: {len(models_1b) + 1}\")  # +1 for base model\n",
        "print(f\"Benchmarks per model: {len(BENCHMARKS_BASE)}\")\n",
        "print(f\"Total evaluations: {(len(models_1b) + 1) * len(BENCHMARKS_BASE)}\")\n",
        "print(f\"Estimated runtime: ~4-5 hours\\n\")\n",
        "\n",
        "# Display models table\n",
        "print(\"Models to evaluate:\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Model':<30} {'Pruning':<10} {'Star':<6}\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Llama-3.2-1B (baseline)':<30} {'0%':<10} {'300%':<12} {'N/A':<6}\")\n",
        "for config in models_1b:\n",
        "    model_name = config['hf_repo_id'].split('/')[-1]\n",
        "    pruning = f\"{config['pruning_pct']}%\"\n",
        "    star = \"â­ Yes\" if config['is_star'] else \"No\"\n",
        "    print(f\"{model_name:<30} {pruning:<10} {star:<6}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# Display benchmarks\n",
        "print(\"\\nBenchmarks to run:\")\n",
        "print(\"-\" * 70)\n",
        "for i, task in enumerate(BENCHMARKS_BASE, 1):\n",
        "    task_name = task['name']\n",
        "    fewshot = f\"{task['num_fewshot']}-shot\"\n",
        "    print(f\"{i:2d}. {task_name:<25} {fewshot}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "print(\"\\nâš™ï¸  Configuration:\")\n",
        "print(f\"   - Neuron selection method: MAW (Maximum Absolute Weight)\")\n",
        "print(f\"   - Checkpointing: Enabled (per-task granularity)\")\n",
        "print(f\"   - Model creation: On-the-fly pruning (no pre-creation needed)\")\n",
        "print(f\"   - Error handling: Skip failed tasks and continue\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7U0stRUIvXG",
        "outputId": "b731cf61-e051-448a-d2fd-e3dcb0e00b69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Checkpoint directory: /content/drive/MyDrive/glu_pruning/checkpoints/1b\n",
            "âœ… Results directory: /content/drive/MyDrive/glu_pruning/results\n",
            "\n",
            "Checkpoint files:\n",
            "   baseline  : âœ… Exists\n",
            "   10pct     : âœ… Exists\n",
            "   20pct     : âœ… Exists\n",
            "   30pct     : âœ… Exists\n",
            "   40pct     : âœ… Exists\n",
            "   50pct     : âœ… Exists\n",
            "   60pct     : âœ… Exists\n"
          ]
        }
      ],
      "source": [
        "# Setup checkpoint paths\n",
        "CHECKPOINT_DIR = \"/content/drive/MyDrive/glu_pruning/checkpoints/1b\"\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/glu_pruning/results\"\n",
        "\n",
        "# Create directories if they don't exist\n",
        "Path(CHECKPOINT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "Path(RESULTS_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"âœ… Checkpoint directory: {CHECKPOINT_DIR}\")\n",
        "print(f\"âœ… Results directory: {RESULTS_DIR}\")\n",
        "\n",
        "# Define checkpoint paths for each model\n",
        "checkpoint_paths = {\n",
        "    \"baseline\": f\"{CHECKPOINT_DIR}/llama_3.2_1b_baseline.json\",\n",
        "    \"10pct\": f\"{CHECKPOINT_DIR}/llama_3.2_1b_pruned_10pct.json\",\n",
        "    \"20pct\": f\"{CHECKPOINT_DIR}/llama_3.2_1b_pruned_20pct.json\",\n",
        "    \"30pct\": f\"{CHECKPOINT_DIR}/llama_3.2_1b_pruned_30pct.json\",\n",
        "    \"40pct\": f\"{CHECKPOINT_DIR}/llama_3.2_1b_pruned_40pct.json\",\n",
        "    \"50pct\": f\"{CHECKPOINT_DIR}/llama_3.2_1b_pruned_50pct.json\",\n",
        "    \"60pct\": f\"{CHECKPOINT_DIR}/llama_3.2_1b_pruned_60pct.json\",\n",
        "}\n",
        "\n",
        "print(\"\\nCheckpoint files:\")\n",
        "for key, path in checkpoint_paths.items():\n",
        "    exists = \"âœ… Exists\" if Path(path).exists() else \"ğŸ†• New\"\n",
        "    print(f\"   {key:<10}: {exists}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5yTl5gTIvXH"
      },
      "source": [
        "# 3. Baseline Evaluation\n",
        "\n",
        "Evaluate the original Llama-3.2-1B model to establish performance baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjcHGNrsIvXH"
      },
      "outputs": [],
      "source": [
        "print(f\"\\n{'='*70}\")\n",
        "print(\"ğŸ“Š PHASE 1: BASELINE EVALUATION\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "BASE_MODEL_ID = \"meta-llama/Llama-3.2-1B\"\n",
        "\n",
        "# Load base model\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "print(f\"Loading base model: {BASE_MODEL_ID}...\")\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL_ID,\n",
        "    #dtype=torch.float16, #T4\n",
        "    dtype=torch.bfloat16, #A100 <- Used for experiments\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(\"âœ… Model loaded successfully\")\n",
        "\n",
        "# Display model statistics\n",
        "base_stats = get_model_stats(base_model)\n",
        "print(f\"\\nğŸ“ˆ Model Statistics:\")\n",
        "print(f\"   Parameters: {base_stats['total_parameters']:,}\")\n",
        "print(f\"   Size: {base_stats['size_gb']:.2f} GB\")\n",
        "\n",
        "# Run evaluation with checkpointing\n",
        "baseline_results = run_robust_evaluation(\n",
        "    model=base_model,\n",
        "    tokenizer=tokenizer,\n",
        "    tasks=BENCHMARKS_BASE,\n",
        "    checkpoint_path=checkpoint_paths[\"baseline\"],\n",
        "    model_name=\"Llama-3.2-1B-baseline\"\n",
        ")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"âœ… BASELINE EVALUATION COMPLETED\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "# Display results summary\n",
        "print(\"Results Preview:\")\n",
        "print(format_results_table(baseline_results))\n",
        "\n",
        "# Clear memory\n",
        "del base_model\n",
        "clear_gpu_cache()\n",
        "\n",
        "print(\"\\nğŸ§¹ Memory cleared, ready for pruned models\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtbaAsxIIvXH"
      },
      "source": [
        "# 4. Pruned Models Evaluation Loop\n",
        "\n",
        "Evaluate the three pruned variants (20%, 40%, 60%) using on-the-fly pruning with OptiPFair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FPoZiAfjIvXH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "051729ec-a62d-4dd4-b8db-0359c37de5f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ğŸ“Š PHASE 2: PRUNED MODELS EVALUATION\n",
            "======================================================================\n",
            "\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ”„ EVALUATING MODEL 1/6: Llama-3.2-1B-pruned-10pct10 \n",
            "   Pruning: 10% |  Star: No\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Loading model: peremartra/Llama-3.2-1B-pruned-10pct\n",
            "  Base: meta-llama/Llama-3.2-1B\n",
            "  Pruning: 10%\n",
            "  Star model: No (on-the-fly)\n",
            "======================================================================\n",
            "\n",
            "ğŸ”§ Creating model via on-the-fly pruning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ‚ï¸  Pruning with MAW method (10%)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Pruning layers: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:06<00:00,  2.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model created\n",
            "   Original params: 1,235,814,400\n",
            "   Pruned params: 1,155,303,424\n",
            "   Reduction: 6.51%\n",
            "\n",
            "ğŸ“ˆ Model Statistics:\n",
            "   Parameters: 1,155,303,424\n",
            "   Size: 2.15 GB\n",
            "   Reduction: 6.51%\n",
            "   Source: on_the_fly_pruning\n",
            "\n",
            "ğŸ“‚ Found existing checkpoint: /content/drive/MyDrive/glu_pruning/checkpoints/1b/llama_3.2_1b_pruned_10pct.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
            "WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded checkpoint. Completed: 12/13 tasks\n",
            "   Pending: []\n",
            "   âš ï¸  Previously failed: ['ifeval', 'musr']\n",
            "\n",
            "======================================================================\n",
            "ğŸš€ Starting evaluation: 1 tasks remaining\n",
            "======================================================================\n",
            "\n",
            "\n",
            "[1/1] Evaluating: musr\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "======================================================================\n",
            "Starting lm-eval on model 'meta-llama/Llama-3.2-1B'\n",
            "Tasks: ['musr'] (full dataset)\n",
            "Few-shot config: {'musr': 0}\n",
            "======================================================================\n",
            "\n",
            "âŒ musr FAILED: 'musr'\n",
            "âš ï¸  Continuing with next task...\n",
            "\n",
            "======================================================================\n",
            "ğŸ‰ ALL TASKS COMPLETED!\n",
            "âš ï¸  Some tasks failed: ['ifeval', 'musr']\n",
            "======================================================================\n",
            "\n",
            "\n",
            "âœ… Llama-3.2-1B-pruned-10pct10 evaluation completed\n",
            "\n",
            "Results Preview:\n",
            "          task word_perplexity,none byte_perplexity,none bits_per_byte,none accuracy acc_norm perplexity word_perplexity bits_per_byte exact_match,strict-match exact_match_stderr,strict-match exact_match,flexible-extract exact_match_stderr,flexible-extract prompt_level_strict_acc,none prompt_level_strict_acc_stderr,none inst_level_strict_acc,none prompt_level_loose_acc,none prompt_level_loose_acc_stderr,none inst_level_loose_acc,none\n",
            "      wikitext              17.5011               1.7079             0.7722      NaN      NaN        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "         boolq                  NaN                  NaN                NaN   0.6260      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "lambada_openai                  NaN                  NaN                NaN      NaN      NaN      20.59            0.00        0.0000                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "          mmlu                  NaN                  NaN                NaN   0.2511      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            " arc_challenge                  NaN                  NaN                NaN   0.3003   0.3328        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "     hellaswag                  NaN                  NaN                NaN   0.4285   0.5791        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "    winogrande                  NaN                  NaN                NaN   0.6093      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "          piqa                  NaN                  NaN                NaN   0.7214   0.7280        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "truthfulqa_mc1                  NaN                  NaN                NaN   0.2460      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "truthfulqa_mc2                  NaN                  NaN                NaN   0.4026      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "         gsm8k                  NaN                  NaN                NaN      NaN      NaN        NaN             NaN           NaN                   0.0318                          0.0048                       0.0394                              0.0054                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "        ifeval                  NaN                  NaN                NaN      NaN      NaN        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                       0.1423                              0.0150                     0.2254                      0.1479                             0.0153                    0.2374\n",
            "ğŸ§¹ GPU memory cleared. Available: 23.80 GB\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ”„ EVALUATING MODEL 2/6: Llama-3.2-1B-pruned-20pct20 \n",
            "   Pruning: 20% |  Star: No\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Loading model: peremartra/Llama-3.2-1B-pruned-20pct\n",
            "  Base: meta-llama/Llama-3.2-1B\n",
            "  Pruning: 20%\n",
            "  Star model: No (on-the-fly)\n",
            "======================================================================\n",
            "\n",
            "ğŸ”§ Creating model via on-the-fly pruning...\n",
            "âœ‚ï¸  Pruning with MAW method (20%)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Pruning layers: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:05<00:00,  3.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model created\n",
            "   Original params: 1,235,814,400\n",
            "   Pruned params: 1,074,792,448\n",
            "   Reduction: 13.03%\n",
            "\n",
            "ğŸ“ˆ Model Statistics:\n",
            "   Parameters: 1,074,792,448\n",
            "   Size: 2.00 GB\n",
            "   Reduction: 13.03%\n",
            "   Source: on_the_fly_pruning\n",
            "\n",
            "ğŸ“‚ Found existing checkpoint: /content/drive/MyDrive/glu_pruning/checkpoints/1b/llama_3.2_1b_pruned_20pct.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
            "WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded checkpoint. Completed: 12/13 tasks\n",
            "   Pending: []\n",
            "   âš ï¸  Previously failed: ['ifeval', 'musr']\n",
            "\n",
            "======================================================================\n",
            "ğŸš€ Starting evaluation: 1 tasks remaining\n",
            "======================================================================\n",
            "\n",
            "\n",
            "[1/1] Evaluating: musr\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "======================================================================\n",
            "Starting lm-eval on model 'meta-llama/Llama-3.2-1B'\n",
            "Tasks: ['musr'] (full dataset)\n",
            "Few-shot config: {'musr': 0}\n",
            "======================================================================\n",
            "\n",
            "âŒ musr FAILED: 'musr'\n",
            "âš ï¸  Continuing with next task...\n",
            "\n",
            "======================================================================\n",
            "ğŸ‰ ALL TASKS COMPLETED!\n",
            "âš ï¸  Some tasks failed: ['ifeval', 'musr']\n",
            "======================================================================\n",
            "\n",
            "\n",
            "âœ… Llama-3.2-1B-pruned-20pct20 evaluation completed\n",
            "\n",
            "Results Preview:\n",
            "          task word_perplexity,none byte_perplexity,none bits_per_byte,none accuracy acc_norm perplexity word_perplexity bits_per_byte exact_match,strict-match exact_match_stderr,strict-match exact_match,flexible-extract exact_match_stderr,flexible-extract prompt_level_strict_acc,none prompt_level_strict_acc_stderr,none inst_level_strict_acc,none prompt_level_loose_acc,none prompt_level_loose_acc_stderr,none inst_level_loose_acc,none\n",
            "      wikitext              25.0520               1.8264             0.8690      NaN      NaN        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "         boolq                  NaN                  NaN                NaN   0.6232      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "lambada_openai                  NaN                  NaN                NaN      NaN      NaN      33.07            0.00        0.0000                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "          mmlu                  NaN                  NaN                NaN   0.2661      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            " arc_challenge                  NaN                  NaN                NaN   0.2773   0.3080        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "     hellaswag                  NaN                  NaN                NaN   0.3875   0.5076        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "    winogrande                  NaN                  NaN                NaN   0.5935      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "          piqa                  NaN                  NaN                NaN   0.6850   0.6757        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "truthfulqa_mc1                  NaN                  NaN                NaN   0.2424      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "truthfulqa_mc2                  NaN                  NaN                NaN   0.4153      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "         gsm8k                  NaN                  NaN                NaN      NaN      NaN        NaN             NaN           NaN                   0.0212                          0.0040                       0.0227                              0.0041                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "        ifeval                  NaN                  NaN                NaN      NaN      NaN        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                       0.1275                              0.0144                     0.2530                      0.1386                             0.0149                    0.2662\n",
            "ğŸ§¹ GPU memory cleared. Available: 23.80 GB\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ”„ EVALUATING MODEL 3/6: Llama-3.2-1B-pruned-30pct30 \n",
            "   Pruning: 30% |  Star: No\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Loading model: peremartra/Llama-3.2-1B-pruned-30pct\n",
            "  Base: meta-llama/Llama-3.2-1B\n",
            "  Pruning: 30%\n",
            "  Star model: No (on-the-fly)\n",
            "======================================================================\n",
            "\n",
            "ğŸ”§ Creating model via on-the-fly pruning...\n",
            "âœ‚ï¸  Pruning with MAW method (30%)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Pruning layers: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:04<00:00,  3.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model created\n",
            "   Original params: 1,235,814,400\n",
            "   Pruned params: 994,281,472\n",
            "   Reduction: 19.54%\n",
            "\n",
            "ğŸ“ˆ Model Statistics:\n",
            "   Parameters: 994,281,472\n",
            "   Size: 1.85 GB\n",
            "   Reduction: 19.54%\n",
            "   Source: on_the_fly_pruning\n",
            "\n",
            "ğŸ“‚ Found existing checkpoint: /content/drive/MyDrive/glu_pruning/checkpoints/1b/llama_3.2_1b_pruned_30pct.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
            "WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded checkpoint. Completed: 12/13 tasks\n",
            "   Pending: []\n",
            "   âš ï¸  Previously failed: ['ifeval', 'musr']\n",
            "\n",
            "======================================================================\n",
            "ğŸš€ Starting evaluation: 1 tasks remaining\n",
            "======================================================================\n",
            "\n",
            "\n",
            "[1/1] Evaluating: musr\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "======================================================================\n",
            "Starting lm-eval on model 'meta-llama/Llama-3.2-1B'\n",
            "Tasks: ['musr'] (full dataset)\n",
            "Few-shot config: {'musr': 0}\n",
            "======================================================================\n",
            "\n",
            "âŒ musr FAILED: 'musr'\n",
            "âš ï¸  Continuing with next task...\n",
            "\n",
            "======================================================================\n",
            "ğŸ‰ ALL TASKS COMPLETED!\n",
            "âš ï¸  Some tasks failed: ['ifeval', 'musr']\n",
            "======================================================================\n",
            "\n",
            "\n",
            "âœ… Llama-3.2-1B-pruned-30pct30 evaluation completed\n",
            "\n",
            "Results Preview:\n",
            "          task word_perplexity,none byte_perplexity,none bits_per_byte,none accuracy acc_norm perplexity word_perplexity bits_per_byte exact_match,strict-match exact_match_stderr,strict-match exact_match,flexible-extract exact_match_stderr,flexible-extract prompt_level_strict_acc,none prompt_level_strict_acc_stderr,none inst_level_strict_acc,none prompt_level_loose_acc,none prompt_level_loose_acc_stderr,none inst_level_loose_acc,none\n",
            "      wikitext              38.5833               1.9800             0.9855      NaN      NaN        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "         boolq                  NaN                  NaN                NaN   0.6260      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "lambada_openai                  NaN                  NaN                NaN      NaN      NaN      55.74            0.00        0.0000                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "          mmlu                  NaN                  NaN                NaN   0.2610      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            " arc_challenge                  NaN                  NaN                NaN   0.2577   0.2637        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "     hellaswag                  NaN                  NaN                NaN   0.3495   0.4382        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "    winogrande                  NaN                  NaN                NaN   0.5722      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "          piqa                  NaN                  NaN                NaN   0.6643   0.6458        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "truthfulqa_mc1                  NaN                  NaN                NaN   0.2448      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "truthfulqa_mc2                  NaN                  NaN                NaN   0.4252      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "         gsm8k                  NaN                  NaN                NaN      NaN      NaN        NaN             NaN           NaN                   0.0129                          0.0031                       0.0159                              0.0034                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "        ifeval                  NaN                  NaN                NaN      NaN      NaN        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                       0.1811                              0.0166                     0.3034                      0.1904                             0.0169                    0.3141\n",
            "ğŸ§¹ GPU memory cleared. Available: 23.80 GB\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ”„ EVALUATING MODEL 4/6: Llama-3.2-1B-pruned-40pct40 \n",
            "   Pruning: 40% |  Star: â­\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Loading model: peremartra/Llama-3.2-1B-pruned-40pct\n",
            "  Base: meta-llama/Llama-3.2-1B\n",
            "  Pruning: 40%\n",
            "  Star model: â­ Yes\n",
            "======================================================================\n",
            "\n",
            "ğŸ“¥ Attempting to load from HF Hub: peremartra/Llama-3.2-1B-pruned-40pct\n",
            "âš ï¸  HF Hub load failed: peremartra/Llama-3.2-1B-pruned-40pct is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`\n",
            "   Falling back to on-the-fly pruning...\n",
            "ğŸ”§ Creating model via on-the-fly pruning...\n",
            "âœ‚ï¸  Pruning with MAW method (40%)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Pruning layers: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:03<00:00,  4.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model created\n",
            "   Original params: 1,235,814,400\n",
            "   Pruned params: 913,770,496\n",
            "   Reduction: 26.06%\n",
            "\n",
            "ğŸ“ˆ Model Statistics:\n",
            "   Parameters: 913,770,496\n",
            "   Size: 1.70 GB\n",
            "   Reduction: 26.06%\n",
            "   Source: on_the_fly_pruning\n",
            "\n",
            "ğŸ“‚ Found existing checkpoint: /content/drive/MyDrive/glu_pruning/checkpoints/1b/llama_3.2_1b_pruned_40pct.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
            "WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded checkpoint. Completed: 12/13 tasks\n",
            "   Pending: []\n",
            "   âš ï¸  Previously failed: ['ifeval', 'musr']\n",
            "\n",
            "======================================================================\n",
            "ğŸš€ Starting evaluation: 1 tasks remaining\n",
            "======================================================================\n",
            "\n",
            "\n",
            "[1/1] Evaluating: musr\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "======================================================================\n",
            "Starting lm-eval on model 'meta-llama/Llama-3.2-1B'\n",
            "Tasks: ['musr'] (full dataset)\n",
            "Few-shot config: {'musr': 0}\n",
            "======================================================================\n",
            "\n",
            "âŒ musr FAILED: 'musr'\n",
            "âš ï¸  Continuing with next task...\n",
            "\n",
            "======================================================================\n",
            "ğŸ‰ ALL TASKS COMPLETED!\n",
            "âš ï¸  Some tasks failed: ['ifeval', 'musr']\n",
            "======================================================================\n",
            "\n",
            "\n",
            "âœ… Llama-3.2-1B-pruned-40pct40 evaluation completed\n",
            "\n",
            "Results Preview:\n",
            "          task word_perplexity,none byte_perplexity,none bits_per_byte,none accuracy acc_norm perplexity word_perplexity bits_per_byte exact_match,strict-match exact_match_stderr,strict-match exact_match,flexible-extract exact_match_stderr,flexible-extract prompt_level_strict_acc,none prompt_level_strict_acc_stderr,none inst_level_strict_acc,none prompt_level_loose_acc,none prompt_level_loose_acc_stderr,none inst_level_loose_acc,none\n",
            "      wikitext              56.3332               2.1252             1.0876      NaN      NaN        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "         boolq                  NaN                  NaN                NaN   0.6220      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "lambada_openai                  NaN                  NaN                NaN      NaN      NaN      90.38            0.00        0.0000                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "          mmlu                  NaN                  NaN                NaN   0.2689      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            " arc_challenge                  NaN                  NaN                NaN   0.2287   0.2509        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "     hellaswag                  NaN                  NaN                NaN   0.3137   0.3737        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "    winogrande                  NaN                  NaN                NaN   0.5706      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "          piqa                  NaN                  NaN                NaN   0.6235   0.6115        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "truthfulqa_mc1                  NaN                  NaN                NaN   0.2485      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "truthfulqa_mc2                  NaN                  NaN                NaN   0.4298      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "         gsm8k                  NaN                  NaN                NaN      NaN      NaN        NaN             NaN           NaN                   0.0091                          0.0026                       0.0205                              0.0039                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "        ifeval                  NaN                  NaN                NaN      NaN      NaN        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                       0.1516                              0.0154                     0.2890                      0.1608                             0.0158                    0.3046\n",
            "ğŸ§¹ GPU memory cleared. Available: 23.80 GB\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ”„ EVALUATING MODEL 5/6: Llama-3.2-1B-pruned-50pct50 \n",
            "   Pruning: 50% |  Star: No\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Loading model: peremartra/Llama-3.2-1B-pruned-50pct\n",
            "  Base: meta-llama/Llama-3.2-1B\n",
            "  Pruning: 50%\n",
            "  Star model: No (on-the-fly)\n",
            "======================================================================\n",
            "\n",
            "ğŸ”§ Creating model via on-the-fly pruning...\n",
            "âœ‚ï¸  Pruning with MAW method (50%)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Pruning layers: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:03<00:00,  5.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model created\n",
            "   Original params: 1,235,814,400\n",
            "   Pruned params: 833,161,216\n",
            "   Reduction: 32.58%\n",
            "\n",
            "ğŸ“ˆ Model Statistics:\n",
            "   Parameters: 833,161,216\n",
            "   Size: 1.55 GB\n",
            "   Reduction: 32.58%\n",
            "   Source: on_the_fly_pruning\n",
            "\n",
            "ğŸ“‚ Found existing checkpoint: /content/drive/MyDrive/glu_pruning/checkpoints/1b/llama_3.2_1b_pruned_50pct.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
            "WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded checkpoint. Completed: 12/13 tasks\n",
            "   Pending: []\n",
            "   âš ï¸  Previously failed: ['ifeval', 'musr']\n",
            "\n",
            "======================================================================\n",
            "ğŸš€ Starting evaluation: 1 tasks remaining\n",
            "======================================================================\n",
            "\n",
            "\n",
            "[1/1] Evaluating: musr\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "======================================================================\n",
            "Starting lm-eval on model 'meta-llama/Llama-3.2-1B'\n",
            "Tasks: ['musr'] (full dataset)\n",
            "Few-shot config: {'musr': 0}\n",
            "======================================================================\n",
            "\n",
            "âŒ musr FAILED: 'musr'\n",
            "âš ï¸  Continuing with next task...\n",
            "\n",
            "======================================================================\n",
            "ğŸ‰ ALL TASKS COMPLETED!\n",
            "âš ï¸  Some tasks failed: ['ifeval', 'musr']\n",
            "======================================================================\n",
            "\n",
            "\n",
            "âœ… Llama-3.2-1B-pruned-50pct50 evaluation completed\n",
            "\n",
            "Results Preview:\n",
            "          task word_perplexity,none byte_perplexity,none bits_per_byte,none accuracy acc_norm perplexity word_perplexity bits_per_byte exact_match,strict-match exact_match_stderr,strict-match exact_match,flexible-extract exact_match_stderr,flexible-extract prompt_level_strict_acc,none prompt_level_strict_acc_stderr,none inst_level_strict_acc,none prompt_level_loose_acc,none prompt_level_loose_acc_stderr,none inst_level_loose_acc,none\n",
            "      wikitext             117.0430               2.4366             1.2849      NaN      NaN        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "         boolq                  NaN                  NaN                NaN   0.6141      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "lambada_openai                  NaN                  NaN                NaN      NaN      NaN     428.30            0.00        0.0000                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "          mmlu                  NaN                  NaN                NaN   0.2606      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            " arc_challenge                  NaN                  NaN                NaN   0.2031   0.2474        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "     hellaswag                  NaN                  NaN                NaN   0.2879   0.3251        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "    winogrande                  NaN                  NaN                NaN   0.5312      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "          piqa                  NaN                  NaN                NaN   0.6088   0.5903        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "truthfulqa_mc1                  NaN                  NaN                NaN   0.2460      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "truthfulqa_mc2                  NaN                  NaN                NaN   0.4314      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "         gsm8k                  NaN                  NaN                NaN      NaN      NaN        NaN             NaN           NaN                   0.0053                          0.0020                       0.0167                              0.0035                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "        ifeval                  NaN                  NaN                NaN      NaN      NaN        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                       0.1534                              0.0155                     0.2818                      0.1553                             0.0156                    0.2842\n",
            "ğŸ§¹ GPU memory cleared. Available: 23.80 GB\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ”„ EVALUATING MODEL 6/6: Llama-3.2-1B-pruned-60pct60 \n",
            "   Pruning: 60% |  Star: No\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Loading model: peremartra/Llama-3.2-1B-pruned-60pct\n",
            "  Base: meta-llama/Llama-3.2-1B\n",
            "  Pruning: 60%\n",
            "  Star model: No (on-the-fly)\n",
            "======================================================================\n",
            "\n",
            "ğŸ”§ Creating model via on-the-fly pruning...\n",
            "âœ‚ï¸  Pruning with MAW method (60%)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Pruning layers: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  6.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model created\n",
            "   Original params: 1,235,814,400\n",
            "   Pruned params: 752,650,240\n",
            "   Reduction: 39.10%\n",
            "\n",
            "ğŸ“ˆ Model Statistics:\n",
            "   Parameters: 752,650,240\n",
            "   Size: 1.40 GB\n",
            "   Reduction: 39.10%\n",
            "   Source: on_the_fly_pruning\n",
            "\n",
            "ğŸ“‚ Found existing checkpoint: /content/drive/MyDrive/glu_pruning/checkpoints/1b/llama_3.2_1b_pruned_60pct.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
            "WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded checkpoint. Completed: 12/13 tasks\n",
            "   Pending: []\n",
            "   âš ï¸  Previously failed: ['ifeval', 'musr']\n",
            "\n",
            "======================================================================\n",
            "ğŸš€ Starting evaluation: 1 tasks remaining\n",
            "======================================================================\n",
            "\n",
            "\n",
            "[1/1] Evaluating: musr\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "======================================================================\n",
            "Starting lm-eval on model 'meta-llama/Llama-3.2-1B'\n",
            "Tasks: ['musr'] (full dataset)\n",
            "Few-shot config: {'musr': 0}\n",
            "======================================================================\n",
            "\n",
            "âŒ musr FAILED: 'musr'\n",
            "âš ï¸  Continuing with next task...\n",
            "\n",
            "======================================================================\n",
            "ğŸ‰ ALL TASKS COMPLETED!\n",
            "âš ï¸  Some tasks failed: ['ifeval', 'musr']\n",
            "======================================================================\n",
            "\n",
            "\n",
            "âœ… Llama-3.2-1B-pruned-60pct60 evaluation completed\n",
            "\n",
            "Results Preview:\n",
            "          task word_perplexity,none byte_perplexity,none bits_per_byte,none accuracy acc_norm perplexity word_perplexity bits_per_byte exact_match,strict-match exact_match_stderr,strict-match exact_match,flexible-extract exact_match_stderr,flexible-extract prompt_level_strict_acc,none prompt_level_strict_acc_stderr,none inst_level_strict_acc,none prompt_level_loose_acc,none prompt_level_loose_acc_stderr,none inst_level_loose_acc,none\n",
            "      wikitext             322.9455               2.9459             1.5587      NaN      NaN        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "         boolq                  NaN                  NaN                NaN   0.5535      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "lambada_openai                  NaN                  NaN                NaN      NaN      NaN    2941.08            0.00        0.0000                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "          mmlu                  NaN                  NaN                NaN   0.2554      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            " arc_challenge                  NaN                  NaN                NaN   0.1869   0.2398        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "     hellaswag                  NaN                  NaN                NaN   0.2696   0.2909        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "    winogrande                  NaN                  NaN                NaN   0.4870      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "          piqa                  NaN                  NaN                NaN   0.5756   0.5637        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "truthfulqa_mc1                  NaN                  NaN                NaN   0.2375      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "truthfulqa_mc2                  NaN                  NaN                NaN   0.4661      N/A        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "         gsm8k                  NaN                  NaN                NaN      NaN      NaN        NaN             NaN           NaN                   0.0068                          0.0023                       0.0205                              0.0039                          NaN                                 NaN                        NaN                         NaN                                NaN                       NaN\n",
            "        ifeval                  NaN                  NaN                NaN      NaN      NaN        NaN             NaN           NaN                      NaN                             NaN                          NaN                                 NaN                       0.1368                              0.0148                     0.2446                      0.1386                             0.0149                    0.2542\n",
            "ğŸ§¹ GPU memory cleared. Available: 23.80 GB\n",
            "\n",
            "======================================================================\n",
            "âœ… ALL PRUNED MODELS EVALUATED\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\n{'='*70}\")\n",
        "print(\"ğŸ“Š PHASE 2: PRUNED MODELS EVALUATION\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "# Store all results for final comparison\n",
        "all_results = {\n",
        "    \"baseline\": baseline_results\n",
        "}\n",
        "\n",
        "# Evaluate each pruned model\n",
        "for i, config in enumerate(models_1b, 1):\n",
        "    model_name = config['hf_repo_id'].split('/')[-1]\n",
        "    pruning_pct = config['pruning_pct']\n",
        "    is_star = config['is_star']\n",
        "\n",
        "    print(f\"\\n{'â”€'*70}\")\n",
        "    print(f\"ğŸ”„ EVALUATING MODEL {i}/{len(models_1b)}: {model_name}{pruning_pct} \")\n",
        "    print(f\"   Pruning: {pruning_pct}% |  Star: {'â­' if is_star else 'No'}\")\n",
        "    print(f\"{'â”€'*70}\\n\")\n",
        "\n",
        "    try:\n",
        "        # Load or create model using utility function\n",
        "        model, tokenizer, stats = load_or_create_model(config, device=\"auto\")\n",
        "\n",
        "        # Display model statistics\n",
        "        print(f\"\\nğŸ“ˆ Model Statistics:\")\n",
        "        print(f\"   Parameters: {stats['total_parameters']:,}\")\n",
        "        print(f\"   Size: {stats['size_gb']:.2f} GB\")\n",
        "        if 'pruning_stats' in stats:\n",
        "            print(f\"   Reduction: {stats['pruning_stats']['percentage_reduction']:.2f}%\")\n",
        "        print(f\"   Source: {stats['source']}\\n\")\n",
        "\n",
        "        # Determine checkpoint key\n",
        "        checkpoint_key = f\"{pruning_pct}pct\"\n",
        "\n",
        "        # Run evaluation with checkpointing\n",
        "        results = run_robust_evaluation(\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            tasks=BENCHMARKS_BASE,\n",
        "            checkpoint_path=checkpoint_paths[checkpoint_key],\n",
        "            model_name=model_name\n",
        "        )\n",
        "\n",
        "        # Store results\n",
        "        all_results[checkpoint_key] = results\n",
        "\n",
        "        print(f\"\\nâœ… {model_name}{pruning_pct} evaluation completed\")\n",
        "        print(\"\\nResults Preview:\")\n",
        "        print(format_results_table(results))\n",
        "\n",
        "        # Clear memory before next model\n",
        "        del model\n",
        "        clear_gpu_cache()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ ERROR evaluating {model_name}: {str(e)}\")\n",
        "        print(\"   Continuing with next model...\\n\")\n",
        "        clear_gpu_cache()\n",
        "        continue\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"âœ… ALL PRUNED MODELS EVALUATED\")\n",
        "print(f\"{'='*70}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1MptG-dIvXH"
      },
      "source": [
        "# 5. Results Consolidation & Export\n",
        "\n",
        "Consolidate all evaluation results and export to CSV for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5RqknL6IvXH",
        "outputId": "baf7de39-1caf-46de-cac6-c2e87135d21a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ğŸ“Š CONSOLIDATING RESULTS (DYNAMIC FILE-BASED)\n",
            "======================================================================\n",
            "\n",
            "Searching for results in: /content/drive/MyDrive/glu_pruning/checkpoints/1b\n",
            "Found 7 individual result files to process:\n",
            "  -> Processing: llama_3.2_1b_baseline.json\n",
            "  -> Processing: llama_3.2_1b_pruned_10pct.json\n",
            "  -> Processing: llama_3.2_1b_pruned_20pct.json\n",
            "  -> Processing: llama_3.2_1b_pruned_30pct.json\n",
            "  -> Processing: llama_3.2_1b_pruned_40pct.json\n",
            "  -> Processing: llama_3.2_1b_pruned_50pct.json\n",
            "  -> Processing: llama_3.2_1b_pruned_60pct.json\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries for this cell\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "import re\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"ğŸ“Š CONSOLIDATING RESULTS (DYNAMIC FILE-BASED)\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "# --- Directory Setup ---\n",
        "# Ensure CHECKPOINT_DIR is defined (it should be defined in a previous cell)\n",
        "# This is where the individual JSON results are.\n",
        "# Example: CHECKPOINT_DIR = \"/content/drive/MyDrive/glu_pruning/checkpoints/1b\"\n",
        "if 'CHECKPOINT_DIR' not in globals():\n",
        "    print(\"âš ï¸ Warning: CHECKPOINT_DIR not set. Using default './checkpoints/1b'\")\n",
        "    CHECKPOINT_DIR = \"./checkpoints/1b\"\n",
        "\n",
        "# Ensure RESULTS_DIR is defined (it should be defined in a previous cell)\n",
        "# This is where the consolidated CSV will be saved.\n",
        "# Example: RESULTS_DIR = \"/content/drive/MyDrive/glu_pruning/results\"\n",
        "if 'RESULTS_DIR' not in globals():\n",
        "    print(\"âš ï¸ Warning: RESULTS_DIR not set. Using default './results'\")\n",
        "    RESULTS_DIR = \"./results\"\n",
        "# --- End Directory Setup ---\n",
        "\n",
        "\n",
        "# Prepare data for DataFrame\n",
        "consolidated_data = []\n",
        "\n",
        "# --- Dynamic Loading ---\n",
        "# 1. Find all individual 1B model result files\n",
        "# *** THIS IS THE CORRECTED LINE: Using CHECKPOINT_DIR ***\n",
        "json_files = glob.glob(f\"{CHECKPOINT_DIR}/llama_3.2_1b_*.json\")\n",
        "\n",
        "# 2. Exclude any aggregate/summary files\n",
        "json_files = [\n",
        "    f for f in json_files\n",
        "    if \"results\" not in os.path.basename(f) and \"complete\" not in os.path.basename(f)\n",
        "]\n",
        "\n",
        "print(f\"Searching for results in: {CHECKPOINT_DIR}\")\n",
        "print(f\"Found {len(json_files)} individual result files to process:\")\n",
        "\n",
        "# 3. Process each model's result file\n",
        "for json_path in sorted(json_files):\n",
        "    print(f\"  -> Processing: {os.path.basename(json_path)}\")\n",
        "    try:\n",
        "        with open(json_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "    except Exception as e:\n",
        "        print(f\"    âš ï¸ Warning: Could not read or parse file. Error: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Extract metadata and results\n",
        "    metadata = data.get(\"metadata\", {})\n",
        "    model_name_from_file = metadata.get(\"model_name\", \"Unknown Model\")\n",
        "\n",
        "    results = data.get(\"results\", {})\n",
        "    if not results:\n",
        "        print(f\"    âš ï¸ Warning: No 'results' found in file. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # --- Dynamically derive info from metadata ---\n",
        "    pruning_pct = 0\n",
        "    is_star = False\n",
        "\n",
        "    # Parse model name to get pruning percentage and display name\n",
        "    if \"baseline\" in model_name_from_file:\n",
        "        display_name = \"Llama-3.2-1B\"\n",
        "        pruning_pct = 0\n",
        "    else:\n",
        "        # Use regex to find pruning percentage\n",
        "        match = re.search(r'pruned-(\\d+)pct', model_name_from_file)\n",
        "        if match:\n",
        "            pruning_pct = int(match.group(1))\n",
        "            display_name = f\"Llama-3.2-1B-pruned-{pruning_pct}%\"\n",
        "        else:\n",
        "            display_name = model_name_from_file # Fallback\n",
        "\n",
        "    # Star logic (as per original project spec/hardcoded cell)\n",
        "    # 40% is the \"star\" model for the 1B variant\n",
        "    if pruning_pct == 40:\n",
        "        is_star = True\n",
        "    # --- End dynamic info derivation ---\n",
        "\n",
        "    # Process each task for this model\n",
        "    for task_name, metrics in results.items():\n",
        "        row = {\n",
        "            \"model\": display_name,\n",
        "            \"pruning_pct\": pruning_pct,\n",
        "            \"is_star\": is_star,\n",
        "            \"task\": task_name,\n",
        "        }\n",
        "\n",
        "        # Add all metrics from this task\n",
        "        for metric_name, value in metrics.items():\n",
        "            # Convert string values to float where possible\n",
        "            try:\n",
        "                row[metric_name] = float(value)\n",
        "            except (ValueError, TypeError):\n",
        "                row[metric_name] = value\n",
        "\n",
        "        consolidated_data.append(row)\n",
        "\n",
        "# --- End Dynamic Loading ---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame\n",
        "df = pd.DataFrame(consolidated_data)\n",
        "\n",
        "# Sort by pruning_pct and then task to ensure consistent order\n",
        "if not df.empty:\n",
        "    df = df.sort_values(by=[\"pruning_pct\", \"task\"]).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nâœ… Consolidated {len(df)} result rows\")\n",
        "print(f\"   Models: {df['model'].nunique()}\")\n",
        "print(f\"   Tasks: {df['task'].nunique()}\")\n",
        "if 'model' in df.columns:\n",
        "    print(f\"   Metrics per task: {len(df.columns) - 4}\")  # Exclude metadata columns\n",
        "else:\n",
        "    print(\"   No data consolidated.\")\n",
        "\n",
        "# Display summary\n",
        "print(\"\\nDataFrame Preview:\")\n",
        "print(df.head(10))\n",
        "\n",
        "# Save to CSV\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "csv_path = f\"{RESULTS_DIR}/llama_1b_results_{timestamp}.csv\"\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"\\nğŸ’¾ Results saved to: {csv_path}\")\n",
        "\n",
        "# Also save a \"latest\" version for easy access\n",
        "latest_path = f\"{RESULTS_DIR}/llama_1b_results_latest.csv\"\n",
        "df.to_csv(latest_path, index=False)\n",
        "print(f\"ğŸ’¾ Latest results: {latest_path}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"âœ… EVALUATION COMPLETE - ALL RESULTS SAVED\")\n",
        "print(f\"{'='*70}\\n\")"
      ],
      "metadata": {
        "id": "TBPO5o8oteVs",
        "outputId": "b390b8a6-821f-47b6-b7bd-30eb977ac374",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Consolidated 84 result rows\n",
            "   Models: 7\n",
            "   Tasks: 12\n",
            "   Metrics per task: 18\n",
            "\n",
            "DataFrame Preview:\n",
            "          model  pruning_pct  is_star            task  word_perplexity,none  \\\n",
            "0  Llama-3.2-1B            0    False   arc_challenge                   NaN   \n",
            "1  Llama-3.2-1B            0    False           boolq                   NaN   \n",
            "2  Llama-3.2-1B            0    False           gsm8k                   NaN   \n",
            "3  Llama-3.2-1B            0    False       hellaswag                   NaN   \n",
            "4  Llama-3.2-1B            0    False          ifeval                   NaN   \n",
            "5  Llama-3.2-1B            0    False  lambada_openai                   NaN   \n",
            "6  Llama-3.2-1B            0    False            mmlu                   NaN   \n",
            "7  Llama-3.2-1B            0    False            piqa                   NaN   \n",
            "8  Llama-3.2-1B            0    False  truthfulqa_mc1                   NaN   \n",
            "9  Llama-3.2-1B            0    False  truthfulqa_mc2                   NaN   \n",
            "\n",
            "   byte_perplexity,none  bits_per_byte,none  accuracy acc_norm  perplexity  \\\n",
            "0                   NaN                 NaN    0.3106   0.3626         NaN   \n",
            "1                   NaN                 NaN    0.6343      N/A         NaN   \n",
            "2                   NaN                 NaN       NaN      NaN         NaN   \n",
            "3                   NaN                 NaN    0.4771   0.6363         NaN   \n",
            "4                   NaN                 NaN       NaN      NaN         NaN   \n",
            "5                   NaN                 NaN       NaN      NaN        5.75   \n",
            "6                   NaN                 NaN    0.3111      N/A         NaN   \n",
            "7                   NaN                 NaN    0.7437   0.7454         NaN   \n",
            "8                   NaN                 NaN    0.2338      N/A         NaN   \n",
            "9                   NaN                 NaN    0.3772      N/A         NaN   \n",
            "\n",
            "   ...  exact_match,strict-match  exact_match_stderr,strict-match  \\\n",
            "0  ...                       NaN                              NaN   \n",
            "1  ...                       NaN                              NaN   \n",
            "2  ...                    0.0637                           0.0067   \n",
            "3  ...                       NaN                              NaN   \n",
            "4  ...                       NaN                              NaN   \n",
            "5  ...                       NaN                              NaN   \n",
            "6  ...                       NaN                              NaN   \n",
            "7  ...                       NaN                              NaN   \n",
            "8  ...                       NaN                              NaN   \n",
            "9  ...                       NaN                              NaN   \n",
            "\n",
            "   exact_match,flexible-extract  exact_match_stderr,flexible-extract  \\\n",
            "0                           NaN                                  NaN   \n",
            "1                           NaN                                  NaN   \n",
            "2                         0.066                               0.0068   \n",
            "3                           NaN                                  NaN   \n",
            "4                           NaN                                  NaN   \n",
            "5                           NaN                                  NaN   \n",
            "6                           NaN                                  NaN   \n",
            "7                           NaN                                  NaN   \n",
            "8                           NaN                                  NaN   \n",
            "9                           NaN                                  NaN   \n",
            "\n",
            "   prompt_level_strict_acc,none  prompt_level_strict_acc_stderr,none  \\\n",
            "0                           NaN                                  NaN   \n",
            "1                           NaN                                  NaN   \n",
            "2                           NaN                                  NaN   \n",
            "3                           NaN                                  NaN   \n",
            "4                        0.1035                               0.0131   \n",
            "5                           NaN                                  NaN   \n",
            "6                           NaN                                  NaN   \n",
            "7                           NaN                                  NaN   \n",
            "8                           NaN                                  NaN   \n",
            "9                           NaN                                  NaN   \n",
            "\n",
            "   inst_level_strict_acc,none  prompt_level_loose_acc,none  \\\n",
            "0                         NaN                          NaN   \n",
            "1                         NaN                          NaN   \n",
            "2                         NaN                          NaN   \n",
            "3                         NaN                          NaN   \n",
            "4                      0.1787                       0.1109   \n",
            "5                         NaN                          NaN   \n",
            "6                         NaN                          NaN   \n",
            "7                         NaN                          NaN   \n",
            "8                         NaN                          NaN   \n",
            "9                         NaN                          NaN   \n",
            "\n",
            "   prompt_level_loose_acc_stderr,none  inst_level_loose_acc,none  \n",
            "0                                 NaN                        NaN  \n",
            "1                                 NaN                        NaN  \n",
            "2                                 NaN                        NaN  \n",
            "3                                 NaN                        NaN  \n",
            "4                              0.0135                     0.1847  \n",
            "5                                 NaN                        NaN  \n",
            "6                                 NaN                        NaN  \n",
            "7                                 NaN                        NaN  \n",
            "8                                 NaN                        NaN  \n",
            "9                                 NaN                        NaN  \n",
            "\n",
            "[10 rows x 22 columns]\n",
            "\n",
            "ğŸ’¾ Results saved to: /content/drive/MyDrive/glu_pruning/results/llama_1b_results_20251023_091718.csv\n",
            "ğŸ’¾ Latest results: /content/drive/MyDrive/glu_pruning/results/llama_1b_results_latest.csv\n",
            "\n",
            "======================================================================\n",
            "âœ… EVALUATION COMPLETE - ALL RESULTS SAVED\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxHStHvMIvXH"
      },
      "source": [
        "# 6. Quick Analysis & Visualization\n",
        "\n",
        "Generate quick insights to decide which models merit uploading to HuggingFace Hub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Xo_bifVCIvXI",
        "outputId": "02fc2875-1dcd-477a-d900-5ab70031ecc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ğŸ“ˆ QUICK ANALYSIS: Performance vs. Pruning Level\n",
            "======================================================================\n",
            "\n",
            "Analyzing 7 unique models found in the DataFrame...\n",
            "\n",
            "Performance Summary:\n",
            "------------------------------------------------------------------------------------------\n",
            "                  model  pruning star  avg_accuracy  avg_perplexity  num_tasks\n",
            "           Llama-3.2-1B        0             0.4609          5.7500         12\n",
            "Llama-3.2-1B-pruned-10%       10             0.4482         20.5900         12\n",
            "Llama-3.2-1B-pruned-20%       20             0.4363         33.0700         12\n",
            "Llama-3.2-1B-pruned-30%       30             0.4251         55.7400         12\n",
            "Llama-3.2-1B-pruned-40%       40    â­        0.4132         90.3800         12\n",
            "Llama-3.2-1B-pruned-50%       50             0.3979        428.3000         12\n",
            "Llama-3.2-1B-pruned-60%       60             0.3790       2941.0800         12\n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "Degradation vs. Baseline (Acc: 0.4609, PPL: 5.75):\n",
            "------------------------------------------------------------------------------------------\n",
            "Llama-3.2-1B-pruned-10%               \n",
            "   Accuracy:   -2.76%\n",
            "   Perplexity: +258.09%\n",
            "\n",
            "Llama-3.2-1B-pruned-20%               \n",
            "   Accuracy:   -5.33%\n",
            "   Perplexity: +475.13%\n",
            "\n",
            "Llama-3.2-1B-pruned-30%               \n",
            "   Accuracy:   -7.76%\n",
            "   Perplexity: +869.39%\n",
            "\n",
            "Llama-3.2-1B-pruned-40%              â­\n",
            "   Accuracy:   -10.34%\n",
            "   Perplexity: +1471.83%\n",
            "\n",
            "Llama-3.2-1B-pruned-50%               \n",
            "   Accuracy:   -13.66%\n",
            "   Perplexity: +7348.70%\n",
            "\n",
            "Llama-3.2-1B-pruned-60%               \n",
            "   Accuracy:   -17.77%\n",
            "   Perplexity: +51049.22%\n",
            "\n",
            "------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\n{'='*70}\")\n",
        "print(\"ğŸ“ˆ QUICK ANALYSIS: Performance vs. Pruning Level\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "# This cell assumes the 'df' DataFrame was created in the previous cell.\n",
        "\n",
        "# Calculate average performance degradation per model\n",
        "# Focus on key metrics: accuracy for classification, perplexity for generation\n",
        "\n",
        "summary_metrics = []\n",
        "\n",
        "# --- Dynamic Analysis ---\n",
        "# Group by the model-level info we created in the previous cell\n",
        "# This replaces the hardcoded 'model_info' dictionary\n",
        "try:\n",
        "    grouped = df.groupby(['model', 'pruning_pct', 'is_star'])\n",
        "except KeyError:\n",
        "    print(\"âŒ Error: 'df' DataFrame not found or is missing required columns.\")\n",
        "    print(\"   Please ensure the previous consolidation cell was run successfully.\")\n",
        "    # Create an empty df to avoid crashing the rest of the cell\n",
        "    grouped = pd.DataFrame().groupby(['model', 'pruning_pct', 'is_star'])\n",
        "\n",
        "print(f\"Analyzing {len(grouped)} unique models found in the DataFrame...\")\n",
        "\n",
        "for (model_name, pruning, is_star_bool), model_df in grouped:\n",
        "    # 'model_df' is now the DataFrame for this specific model\n",
        "\n",
        "    # Extract key metrics\n",
        "    # We look for 'accuracy' (from boolq, mmlu, etc.)\n",
        "    accuracies = model_df['accuracy'].dropna()\n",
        "    # We look for 'perplexity' (from lambada_openai)\n",
        "    # Note: wikitext 'word_perplexity,none' is not used here for simplicity\n",
        "    perplexities = model_df['perplexity'].dropna()\n",
        "\n",
        "    summary = {\n",
        "        \"model\": model_name,\n",
        "        \"pruning\": pruning,\n",
        "        \"star\": \"â­\" if is_star_bool else \"\",\n",
        "        \"avg_accuracy\": accuracies.mean() if len(accuracies) > 0 else None,\n",
        "        \"avg_perplexity\": perplexities.mean() if len(perplexities) > 0 else None,\n",
        "        \"num_tasks\": len(model_df),\n",
        "    }\n",
        "\n",
        "    summary_metrics.append(summary)\n",
        "\n",
        "# --- End Dynamic Analysis ---\n",
        "\n",
        "if not summary_metrics:\n",
        "    print(\"\\nNo summary metrics to display. Skipping analysis.\")\n",
        "else:\n",
        "    summary_df = pd.DataFrame(summary_metrics)\n",
        "    # Sort by pruning percentage to ensure a logical order\n",
        "    summary_df = summary_df.sort_values(by=\"pruning\").reset_index(drop=True)\n",
        "\n",
        "    print(\"\\nPerformance Summary:\")\n",
        "    print(\"-\" * 90)\n",
        "    print(summary_df.to_string(index=False, float_format=\"%.4f\"))\n",
        "    print(\"-\" * 90)\n",
        "\n",
        "    # Calculate degradation vs baseline\n",
        "    # Find baseline row (pruning == 0)\n",
        "    baseline_row = summary_df.loc[summary_df['pruning'] == 0]\n",
        "\n",
        "    if baseline_row.empty:\n",
        "        print(\"\\nâš ï¸ Baseline model (pruning=0) not found. Cannot calculate degradation.\")\n",
        "    else:\n",
        "        baseline_acc = baseline_row['avg_accuracy'].values[0]\n",
        "        baseline_ppl = baseline_row['avg_perplexity'].values[0]\n",
        "\n",
        "        print(f\"\\nDegradation vs. Baseline (Acc: {baseline_acc:.4f}, PPL: {baseline_ppl:.2f}):\")\n",
        "        print(\"-\" * 90)\n",
        "\n",
        "        for _, row in summary_df.iterrows():\n",
        "            if row['pruning'] == 0:\n",
        "                continue\n",
        "\n",
        "            acc_delta_str = \"N/A\"\n",
        "            if row['avg_accuracy'] is not None and baseline_acc is not None and baseline_acc != 0:\n",
        "                acc_delta = ((row['avg_accuracy'] - baseline_acc) / baseline_acc * 100)\n",
        "                acc_delta_str = f\"{acc_delta:+.2f}%\"\n",
        "\n",
        "            ppl_delta_str = \"N/A\"\n",
        "            if row['avg_perplexity'] is not None and baseline_ppl is not None and baseline_ppl != 0:\n",
        "                ppl_delta = ((row['avg_perplexity'] - baseline_ppl) / baseline_ppl * 100)\n",
        "                ppl_delta_str = f\"{ppl_delta:+.2f}%\"\n",
        "\n",
        "            print(f\"{row['model']:<35} {row['star']:>2}\")\n",
        "            print(f\"   Accuracy:   {acc_delta_str}\")\n",
        "            print(f\"   Perplexity: {ppl_delta_str}\")\n",
        "            print()\n",
        "\n",
        "        print(\"-\" * 90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IcveKgykIvXI",
        "outputId": "1d66f244-92ce-43eb-db38-987960a58197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABW0AAAHqCAYAAAB/bWzAAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAA8aBJREFUeJzs3Xd4FNXbxvHvbioBAoR0amjSO1KkSglVEGx0EPEnggooKoIiNlREEEV8RYqFJioiRYp0pEqXppTQQhJqEiB95/0jsmQhgRCS3ZT7c12BszNnZp49KTv77JlnTIZhGIiIiIiIiIiIiIhItmB2dAAiIiIiIiIiIiIicpOStiIiIiIiIiIiIiLZiJK2IiIiIiIiIiIiItmIkrYiIiIiIiIiIiIi2YiStiIiIiIiIiIiIiLZiJK2IiIiIiIiIiIiItmIkrYiIiIiIiIiIiIi2YiStiIiIiIiIiIiIiLZiJK2IiIiIiIiIiIiItmIkrYiIpJjzJo1C5PJZP2SrKcxFxGRvCw7vA42b97cevx+/fo5JAaxr+zwc5fXaMwlO1LSViSHqVq1qs2LSUBAAImJiY4OS7KxlCf6Kb+cnZ3x9fWlTZs2fPfddxiG4ehQc4WQkBCbcX777bcdHZKIiIhdrVu3LtVzD5PJRIECBahcuTIvvPACx48fd3SoOZ4SujfpnNe+dM4rkvWcHR2AiKTfjh07OHDggM2ysLAwli9fTseOHR0UleRUSUlJnD9/nlWrVrFq1Sp+/PFHFi5ciIuLi6NDS1O9evUYP368o8MQERGRDLp27RqHDh3i0KFDzJgxg0WLFtGqVStHh5WtDRo0yHquX7VqVQdHk/PonFdEciolbUVykFmzZqW5PLckbaOiovD09HR0GLlWkSJFeOONNwAIDw/n+++/Jzw8HIClS5fy5Zdf8tJLL911P/Hx8RiGgZubW5bGe6sqVapQpUoVux5TRERE7s+TTz5J3bp1iY+PZ8uWLSxZsgSA69ev07t3b0JCQrLsnOLatWvky5cPsznnXmT65JNPOjqEHEfnvCKSG+TcVy6RPCYuLo65c+daH1eoUMHaXrx4MRcvXkxz28OHDzN48GAqV65MgQIF8PDwoEyZMjz11FP89ddfNn0Nw+Cnn37ikUceoVixYri5ueHl5UWtWrUYPnw48fHxwO2Xw6xbt85mP2ldqpXadtOnT6d27drky5ePpk2bAnDixAmGDh1KkyZNKFGiBPnz58fNzY1ixYrRqVMnFi9enObz3bFjB/3796dcuXJ4eHhQoEABKlSoQP/+/Tl27BgWi4UyZcpYY7hxQpfSiBEjrOsrV66c5rEApk+fbu2bP39+rl27ZrP+ypUruLu7W/vMnj0bgMTERCZNmkTDhg0pXLgwzs7OFC1alCpVqtCnTx/mzZt3x+NmhKenJ6+88gqvvPIK48ePZ+PGjTY1m37++Wdr+9bv4d9//02XLl0oWrQobm5uHDp06LbLH0NCQmyOV7p06VQvmbp1u+PHj/Pll19SvXp13N3d8fX15ZlnnuHy5cs2+7tTralb4/3333/p3r073t7euLu7U7t2bRYtWpTquGzcuJHmzZuTP39+vLy8eOKJJzhx4gT9+vWz7rN58+YZG/R0ioqKYty4cdSvX59ChQrh6upKyZIl6dev320z7Hv37n3HuH7//XfreicnJ06fPm1dFxcXxxdffEHTpk3x8vLC1dWVgIAAHn/8cbZs2ZKlz1FERPKmtm3b8sorr/DGG2+wePFievbsaV0XFhbGn3/+adN/7969PP3005QtW5Z8+fJRoEABatWqxQcffHDbeRbcfr6xadMmWrVqRaFChShQoABRUVGpnntMmjSJypUr4+7uTrFixRg+fDjR0dH39Nzu5XV17969NueEn3/+uXVdfHw81apVs65r06aN9TL+1M6r3377bUwmE+vXr7fu49tvv73tOeqcV+e8KemcV+e8ksMYIpIjzJ8/3wCsX1u2bDFcXFysjydPnpzqdt98843h6upqs23Kr4kTJ1r7xsTEGB06dEizL2BcvnzZMAzDOHHihM3ytWvX2hy3WbNm1nV9+/a1Lr91uyZNmtg8rlGjhmEYhrF48eI7xgEYY8eOve35jh071jCZTGlus3DhQsMwDGP8+PHWZYGBgUZiYqLNfkqVKmVd//HHH9/xexMVFWV4eHhY+8+ZM8dm/fTp063rChUqZFy/ft0wDMPo27fvHZ9f/fr173jc9Er5vShVqtRt6729va3ry5cvn+p2tWrVMvLnz28T3+7du421a9faLDtx4oTNvlOO45gxY6zLb92ucePGqY5B06ZNbfY3c+ZMm/VpPc/q1asbBQsWvG1/JpPJ+OOPP2y2W7x4seHs7Hxb36JFixqNGjWyPm7WrFm6xvvWn/GUzzst//zzj1G6dOk0fxbc3NyMH3/80dp/9erV1nVms9k4c+aMzf569+5tXd+mTRvr8oiICKNmzZppHsdsNhuTJk1K95iLiIik5tbX+ZkzZ9qs/+KLL2zWz54927ruyy+/TPV1+cZX5cqVjXPnztnsL+X5RsOGDQ0nJ6fbzl9vjenhhx9Odf/16tUzYmJirPu+0+tgRl5XP/30U+t6Dw8P4+jRo4ZhGMbrr79uXe7t7W2EhoZat0ntvHrMmDF3PVc+ceKEznlT0Dmvznl1zis5jcojiOQQKUsj1K5dmwYNGtCqVSt+//136/oXXnjBZputW7fy7LPPYrFYAHB2dubxxx+nYsWKnDlzhuXLl9v0f/nll1m6dKn1cYkSJXj00UcpVKgQBw4csF7Klpk2btxIqVKl6NatGx4eHkRERFhjrVmzJnXr1sXHxwdPT0+uXbvGn3/+ydq1awF49913GTBgAMWKFQNgwYIFjBkzxrpvDw8PnnrqKUqVKsWJEydsZucOGDCAMWPGcP36dUJDQ1m6dCmPPPIIANu3b+fkyZPWOHr37n3H51CwYEEee+wxvvvuOwDmzJlD9+7drevnzJljbT/11FPky5ePq1ev8sMPP1iXd+vWjdq1axMZGcnJkydtZk1kpX/++cdmlra/v3+q/Xbv3m0di/Lly3P48GHc3d0zLY5NmzbRsmVLGjVqxK+//sr+/fsB2LBhA1u3bqVBgwb3tL99+/ZRpEgRhg0bRkxMDNOmTSMpKQnDMBg/fjwtW7YEki/LHDBggPVmfs7OzvTv3x8vLy++++47Nm/enGnPMS1JSUk8+uij1hkbPj4+9OjRAy8vL1asWMHmzZuJi4ujT58+1KlThzJlytCiRQtKly5NSEgIFouFefPm8fLLLwMQExPDr7/+at1///79re3evXuzZ88eIPnntkePHhQvXpw///yT5cuXY7FYGDZsGHXr1uWhhx7K8ucuIiJ5062z3G6cf2zevJkhQ4ZYz10bNGhA27ZtiY6O5ttvv+XChQscPHiQPn36sHLlyjT37eHhQa9evShWrBi7d+/Gycnptn5r1qyhc+fO1KhRg99//50dO3YAyVdsffzxx7z11lt3fR4ZeV0dOnQoK1asYMWKFVy/fp2nn36aDz/80KZ+6YwZMwgICLjjsdu0aUOBAgWYOnWq9YZudevWtSml4OXlpXPe/+icV+e8OueVHMnRWWMRubvQ0FCbGQPjx483DMMwvvvuO5tPA/ft22ezXdeuXW0+TdywYYPN+ri4OOP06dOGYRjGpUuXbD55rVWrlhEdHW3T/9SpU0Z8fLxhGJk30zYoKMg6ezc1R44cMebNm2d8/vnnxieffGKMHz/e5hP+7777ztq3du3a1uX58+c3jhw5YrOvq1evGuHh4dbHAwcOtPbv1KmTdfnLL7+c6vI7WbdunXUbFxcX4+LFi4ZhGMa5c+dsvnfbtm0zDCN5vG8s8/T0NOLi4mz2Z7FYjOPHj6fr2HeT8ntRpEgRY/z48cb48eONESNGGP7+/jbfj5Qzr1NuBxi//vrrbfvOrFkHjz76qGGxWAzDMIyLFy/ajFnKWeTpnXVgMpmMXbt2WdcNHTrUus7Ly8u6fO7cuTb7mzp1qnXdv//+a/M7kVWzDhYtWmTt6+TkZPzzzz/WdYmJiUa1atWs64cNG2Zd9/bbb1uX16lTx7r8xx9/tPl+x8bGGoZhGHv37rWJa82aNTZxtG/f3ub7cYNmHYiIyL269XX+ySefNMaPH2+8//77RqdOnWzW+fn5WWe2Pvroo9blzZs3N5KSkqz73L59u812e/futa5Leb7h5ORk7Ny5864xDRw40LouPj7eqFKlinVd8eLFrevSeh3M6OuqYSSfH/r4+FjXFyhQwNp+/vnnb4s9rfPqu627Qee8OufVOe9NOueVnEQzbUVygO+//56kpCQATCaT9RP0Ll264O7uTmxsLAAzZ87k008/tW63adMmazs4OJgmTZrY7NfV1ZXixYsDybNyb3zyCvD6669ToEABm/4lSpTIxGeVbPDgwRQuXPi25SEhIfTs2fOun/qeOXMGSP70ePfu3dblffr0san7C5A/f37y589vffzCCy8wbdo0AJYtW0ZoaCiBgYH89NNP1j4pP7G9k6ZNm1K2bFmOHTtGQkICP//8MwMHDuTHH3+0fu+qVKnCgw8+CCTfHKFKlSocOHCAqKgogoKCqFevHuXLl6datWq0bNmSoKCgdB37Xly+fJkRI0akui44OJjBgwenuq5q1ap07tw50+O5YdCgQdZ6XV5eXnh7e1tvFnFrja/0aNiwIbVq1bI+fuCBB6ztlPu7taZzyhkm5cqVo3HjxrfVa85sKev4JSUl3fZzm1LK34d+/foxduxYDMNg586d/Pvvv5QvX96m9nX37t2tN864tV7gww8/nK7jiIiI3K/58+czf/7825a7u7vz7bffWmcypnytWrduXaozZG/YvHkz1atXv215u3btqF279l1jSvma7+LiwhNPPGG9YuvMmTOEh4fj5+eX5vb387rq7+/PrFmz6NChAwBXr14Fks8VJ0yYcNfY75XOeW3pnFfnvKkdRyQ70o3IRHKAlKURGjVqZE2eFixY0HqyBzB79mybxOulS5es7budDKXsm57+tzL+u1HCDXFxcenarmLFiqku79KlS7peRG8c5/LlyzYxpCf+atWqWQvaJyUlMXPmTLZt22a9TMzHx4eOHTvedT/AbTdcu3F5WMrLxG49GZ4zZ471hg+hoaEsWrSITz75hL59+1KyZEmGDx+ermNnlJOTE97e3rRs2ZIZM2awbNkyXFxcUu2b1vfpVhn9OShdurTN45R36L1xieS9uNP+UsZ45coVa7tgwYI2SX1I+9K5zHTr796dnD9/3touVaqUzUnonDlziIyMZNmyZdZlTz/99H0fR0REJDPly5ePihUr8vzzz7N//36Cg4Ot6zLjtSq95yy+vr42j29N0KY8R0jN/cYaHBxM+fLlbZYNGDAgUy/Fv0HnvDrn1Tnv3Y8jkh1ppq1INrdt2zYOHTpkffznn3/edgfRGyIiIli2bJm1TpWXl5e1RuyJEyfueBwvLy+bxydOnKBevXpp9jebbT/ziYmJsbYtFgvHjh274/FuuPWEAeDIkSPs3bvX+rhHjx58/PHHBAYGYjKZ8PX1ve0FtkiRIphMJuvJyd2e7w0vvPCC9VPlGTNm2NS66tWrV5ondKnp27cvY8aMwWKxsGHDBjZt2sS2bduA5LpRvXr1sulfvXp1Dhw4wP79+9m1axf//vsvu3bt4vfff8disTBx4kQ6depEixYt0h3D3ZQqVeq2u92mR2rfJ7jzz0FUVJR15sDd3DrOaf2Mp1d695dylnd0dDQxMTHky5fPuiwsLOy+4kiPlL977u7uvPvuu2n2LVSokM3j/v37s3r1agDmzp1LyZIlrW8aqlevTp06dVI9DsA777xj81xFRESyysyZM20SfWlJee7auHHjO854bNSoUarL0zpnuVVERITNrMRbz1lSuxLs1lhTutfX1Q8++IB///3XZtnYsWPp2rUrpUqVSvd+0kvnvOmjc96so3NekXunpK1INpdylm16+99I2jZu3JhffvkFgJUrV/Lnn3/aFFpPTEwkPDycYsWK0aBBA5ydna0zdT/66CM6duyIh4eHtX9oaCg+Pj64uLjcdiK7detW2rdvD8C0adPu61PLlCeRAI899pj1ZmPr1q1Ldd8eHh7UqlWLXbt2AcklJYYPH065cuWsfWJiYoiOjraZWdG5c2dKlizJqVOnOH78OFOnTrWuS/mJbXqUKFGCVq1asXLlSiwWC3369LGu69Chw20zOPbs2UPNmjWpVq0a1apVsy6vUaMG+/btA2DXrl3WE9h+/frx7bffAtCsWbMsv4QpPVL7Obgxk2LcuHG3zULIburWrWvzeN68edbZIUePHrUpMZJVUr7pjI2NpUqVKrRr1+62ftu2bbOZPQHQtWtXChUqRGRkJEeOHLE5+b11lsutb269vb0ZNGjQbcc5cOBAhi7PExERuV83bs4EyUmkZ599Fk9PT5s+MTExLFiwIM2kbXp9//331tJhCQkJ/Pjjj9Z1xYoVu2NphBuxpnQvr6tbt27lnXfesT6uWLEihw8fJjIykl69et21NERKKZN2169fT7Ofznnvj85575/OeUXunZK2ItlYbGws8+bNsz4OCgqy1odKaf/+/Rw8eBCAJUuWcOHCBby9vRkxYgS//vorFouFpKQkWrRowRNPPMEDDzxAWFgYK1asYMiQIQwdOpQiRYrw7LPP8uWXXwLJJ06VK1emS5cuFC5cmH/++YeFCxdy7tw5ChcujKenJxUqVOCff/4B4P3332f37t3ExMSwZs2a+3re5cqVw2w2Wy8Reumll9izZw8XL15k5syZaW73+uuv88QTTwDJtcFq1qzJU089RalSpTh9+jRLlizhyy+/pEuXLtZtnJycGDRoECNHjgSw1geuW7cuVatWvefY+/fvb72bccrZvqnVCWvQoAGBgYE0adKEwMBAPD092bt3r/XkFe4+y8PRKlasSMGCBYmOjgbg+eefZ8mSJYSFhd12Z+jsqHPnzvj6+lpn9Tz33HNs376dQoUK8d1339mUG8mor7/+miVLlqS67q+//qJDhw5UqlTJOqO+S5cudO3alcqVK1tnrW/YsIGTJ08yc+ZMatasad0+X758PPXUU/zf//0fcPNnzsXFhZ49e9ocq0aNGrRu3ZpVq1YBMGTIEH7//Xfq1KmD2Wzm5MmTbN68mUOHDjFmzBgaN258389dRETkXrz88sssWrQIwzA4evQoVatWpWvXrvj5+REZGcn+/ftZv349165ds0kUZsSNSQbVq1fn999/58CBA9Z1AwcOvOv2GX1djY6OpmfPntZzjGeeeYYxY8ZQrVo1rly5wqZNm3j//fd566230vU8bkxsAFi6dCmvv/463t7eeHt728xu1jnv/dE5793pnFckCzjm/mcikh633uXzhx9+SLXf6tWrbfpNmjTJuu6bb74xXF1dbdan/Ep559SYmBibu2mm9nX58mWbfafWp0yZMkbFihVTvZPtrXcZXbt2barP6bnnnkt13y1btjSKFSuW5l1K3377bcNkMqUZ/8KFC2871oULFwx3d3ebflOmTLnbtydVsbGxRpEiRWz25efnZyQkJNzW183N7Y5jHRQUZFy5csXav2/fvvd8V1fDsL3DbKlSpTK0XVp3IzYMwxg9enSq8detW9fw9fVN9XuV0TvwpvdOurfGe6ftFi9ebHPH3BtfRYoUMRo0aGB93KJFi3SN260/43f6uuHIkSNG6dKl79p/5syZtx1v27Ztt/Xr2rVrqrGFh4cbNWvWvOtx0jvmIiIiqbn1dT6116+0TJkyJdXX5bReQw0j7fOGO8XUoUOHVPdbp04d4/r169bt7vQ6mJHX1d69e1uXly5d2oiKijIMwzC+//5763JnZ2dj8+bN1m3udI6zaNGiVI9ZpUqV28ZA57x3307nvDrn1TmvZCe6EZlINpayNEKhQoXo2rVrqv1atGhhU4Q+5XYDBgxgz549DBo0iIoVK+Lh4YGbmxslSpTgscces/lk0d3dnSVLlvDjjz/SsWNH/P39cXFxwdPTk2rVqvHSSy/ZlEsYMGAA06ZNo1KlSri6uuLv78+gQYPYvn37XS8pu5vPP/+cd955h1KlSuHi4kLJkiUZMWIEixcvxtk57YsExowZw9atW+nbty9lypTB3d0dDw8PypQpQ+/evVOdSVC0aFF69OhhMw4pH98LNzc3unfvbrOsV69eqcY8depU+vfvT/Xq1fHx8cHZ2ZkCBQpQvXp1Xn31VbZt23ZbPafs6J133uGDDz4gKCgIFxcXSpUqxciRI1m/fn2OqB/VsWNHVq9eTbNmzciXLx+FCxemc+fObN261Wb8s3IGSIUKFdi3bx8ff/wxjRo1okiRIjg5OVGwYEGqV6/OM888w8KFC1P9uXzwwQepUqWKzbK07gDt6+vLtm3bmDp1Kg8//DDe3t44OTmRP39+KlasSK9evZg9e3aad1sWERHJas8//zy7d+/m2WefpUKFCnh4eODs7Iyfnx/NmjXjzTfftLn3QUZ9/vnnfPHFF1SuXBk3NzcCAgJ46aWXWLNmTbrPX+71dXXevHl8//33QHLt0ZkzZ1KwYEEg+XyxW7duQHIJs549exIVFXXXGB555BG++OIL6/n4neic9/7onPf+6ZxX5N6YDCObF18REbGDDz/80Hq52FNPPcXcuXMdHJHYS2xsbKp3aj579iyVK1e2vmF6//33eeONN+wdnoiIiGSCdevW2dzo6sSJEzaTHvIKnfPmXTrnFcl5VNNWRPKssLAwDh06xMmTJ/nkk0+sy4cMGeLAqMTeli9fzuuvv0737t2pUKEC+fPn559//uHzzz+3nrwWKFDgnm/SISIiIpId6JxXQOe8IjmRkrYikmctX778tktqHn/8cR566CEHRSSOcuTIEd5+++1U1xUsWJD58+fj7+9v36BEREREMoHOeeUGnfOK5CxK2opInmc2mylevDjdu3dnzJgxjg5H7KxGjRoMGjSIDRs2EBoaSlRUFPnz56d8+fK0bt2awYMHU7x4cUeHKSIiInJfdM6bt+mcVyTnUU1bERERERERERERkWzE7OgAREREREREREREROQmJW1FREREREREREREshHVtE0Hi8VCaGgoBQsWxGQyOTocERERkTzFMAyio6MJDAzEbNacg/ulc1sRERERx0nvua2StukQGhpKiRIlHB2GiIiISJ52+vRp3SQlE+jcVkRERMTx7nZuq6RtOhQsWBBIHkxPT88sP57FYuH8+fP4+PhoNokdaLztT2Nufxpz+9J425/G3P7sOeZRUVGUKFHCek4m90fntrmbxtv+NOb2pfG2P425/WnM7cve453ec1slbdPhxmVjnp6edjuxjY2NxdPTU7+cdqDxtj+Nuf1pzO1L421/GnP7c8SY61L+zKFz29xN421/GnP70njbn8bc/jTm9uWo8b7bua2+8yIiIiIiIiIiIiLZiJK2IiIiIiIiIiIiItmIkrYiIiIiIiIiIiIi2Yhq2oqIiIiIiA2LxUJ8fHym7SshIYHY2FjV5ctkLi4uODk5OToMERERyQJK2oqIiIiI3KepU6cydepUQkJCAKhSpQpvvfUW7dq1AyA2NpaXX36ZefPmERcXR3BwMF9++SV+fn7WfZw6dYpBgwaxdu1aChQoQN++fRk3bhzOzjdP2detW8fw4cM5cOAAJUqUYPTo0fTr1y9Tn0t8fDwnTpzAYrFkyv4Mw8BisRAdHa2byWWBwoUL4+/vr7EVERHJZZS0FRERERG5T8WLF+fDDz+kfPnyGIbBt99+S+fOndm9ezdVqlRh2LBhLF26lAULFlCoUCGGDBlC165d+fPPPwFISkqiQ4cO+Pv7s3nzZs6dO0efPn1wcXHhgw8+AODEiRN06NCB5557jtmzZ7N69WqeeeYZAgICCA4OzpTnYRgG586dw8nJiRIlSmTKzFjDMEhMTMTZ2VmJxUxkGAbXr18nIiICgICAAAdHJCIiIplJSVsRERERkfvUqVMnm8fvv/8+U6dOZevWrRQvXpzp06czZ84cHn74YQBmzpxJpUqV2Lp1Kw0aNGDlypUcPHiQP/74Az8/P2rWrMm7777La6+9xttvv42rqytfffUVQUFBTJgwAYBKlSqxadMmJk6cmGlJ28TERK5fv05gYCAeHh6Zsk8lbbNOvnz5AIiIiMDX11elEkRERHIRJW1FRERERDJRUlISCxYs4Nq1azRs2JCdO3eSkJBAq1atrH0qVqxIyZIl2bJlCw0aNGDLli1Uq1bNplxCcHAwgwYN4sCBA9SqVYstW7bY7ONGn6FDh94xnri4OOLi4qyPo6KigORas7eWQEhISMAwDFxcXDAMI6NDcJsb+8rMfUqyfPnyYRgGcXFxuLu7Y7FYrCUpxD405val8bY/jbn9aczty97jnd7jKGkrIiIiIpIJ9u/fT8OGDYmNjaVAgQIsXLiQypUrs2fPHlxdXSlcuLBNfz8/P8LCwgAICwuzSdjeWH9j3Z36REVFERMTY511eatx48YxduzY25afP3+e2NhYm2UJCQlYLBaSkpJITExM/5O/A8MwSEpKAtBM2yyQlJSExWLh4sWLuLi4YLFYiIyMxDAM3fjNTjTm9qXxtj+Nuf1pzO3L3uMdHR2drn5K2mYjsQlJLNt/jhUHwjh/5Ro+hc8QXMWf9tUCcHfRpU4iIiIi2dkDDzzAnj17iIyM5KeffqJv376sX7/e0WExcuRIhg8fbn0cFRVFiRIl8PHxwdPT06ZvbGws0dHRODs729wALTO4uLhk6v4kmbOzM2azmaJFi1pn2ppMJnx8fPRG30405val8bY/jbn9acztJCkWTi2AM4soei0Ml/z+ULwzlHwcnNyz7LDu7unbt5K22cSqg+G8vGAPUTGJmE1gMcAcepUVB8J5e/EBPn28Jq0q+919RyIiIiLiEK6urpQrVw6AOnXqsGPHDj777DOefPJJ4uPjuXLlis1s2/DwcPz9/QHw9/dn+/btNvsLDw+3rrvx/41lKft4enqmOcsWwM3NDTc3t9uWm83m294Ims1mTCaT9SszGIZh3VdunmlbunRphg4dai1XYTKZWLhwIV26dMnS4974XqX8ft76WLKexty+NN72pzG3P415FjvzG2zpBwmXMTDjhgXjihnT2YWwaxg0/BaKd7rrbjIivd9TfeezgVUHw3n2+7+Ijkm+BM3yX6mvG/9HxyQy8Pu/WHUwPI09iIiIiEh2Y7FYiIuLo06dOri4uLB69WrruiNHjnDq1CkaNmwIQMOGDdm/fz8RERHWPqtWrcLT05PKlStb+6Tcx40+N/aRl/Xr188m2Vy0aFHatm3Lvn37HBbTuXPnaNeuncOOLyIiImk48xts6AIJVwAwYbH5n4QrsKFzcj8HUtLWwWITknh5wR4wIK3bMhj//fPKgj3EJiTZLzgRERERSZeRI0eyYcMGQkJC2L9/PyNHjmTdunX07NmTQoUKMWDAAIYPH87atWvZuXMn/fv3p2HDhjRo0ACANm3aULlyZXr37s3evXtZsWIFo0ePZvDgwdZZss899xzHjx/n1Vdf5fDhw3z55Zf8+OOPDBs2zJFPPdto27Yt586d49y5c6xevRpnZ2c6duzosHj8/f1TneEsIiIiDpQUmzzDFrhLJg629kvu7yAqj3Av4uOTv25lNkPKml+p9bnBZIIU9bx+33WSmKsxqX4jDEwkOjn/14ZrV2NZvvskXWoWv+t+SUiAtO7Oey99AVxdM9Y3MRHudEe8e+nr4pIcd1b0vSEpKbl/evablJT8lRZn5+Sfi+zS12K583Nzckr+sldfi+Xm79ONGFP2NYzkn7X07PdufVP+fmZVX7jz7/19/I24p753+v28dbn+Rtx737v9zt3a99af8ZT0N+L++qb2+5ny74qLi/5GpNY3s37vU+t7p0veM+NvxJ2eZzYRERFBnz59OHfuHIUKFaJ69eqsWLGC1q1bAzBx4kTMZjPdunUjLi6O4OBgvvzyS+v2Tk5OLFmyhEGDBtGwYUPy589P3759eeedd6x9goKCWLp0KcOGDeOzzz6jePHifPPNNwQHB9v9+WZHbm5uNqUkXn/9dZo0acL58+fx8fHhtddeY+HChZw5cwZ/f3969uzJW2+9Za21u3fvXoYOHcpff/2FyWSifPny/N///R9169YFYNOmTYwcOZK//voLb29vHn30UcaNG0f+/PlTjSdleYSQkBCCgoL4+eef+fzzz9m2bRvly5fnq6++spkpfa/HEBERkXt0agEkXE5HRwPiL8OpnyCoV5aHlRolbe/FhAmQ2qfl5ctDz543H48fn/YbudKloV8/60Nj4iSGnLmQam4/vEBR5tZsa33cd/dSnI8uhRqBt3f28YHBg28+/vprOH8+9RgKF4b/am0BMHMmhIam3tfDA1599ebj2bMhJCT1vi4uMGrUzcfz58O//6beF+Dtt2+2f/kFDh5Mu+8bb9x8I7dkCezZk3bfESPgxontihWwY0fafYcOhRs34Fi9GrZuTbvv88+Dr29ye+NGWLcu7b4DB0KxYsntrVth1aq0+/brl/xzAbBzJyxblnbfHj2gQoXk9v798Ouvafd9/HGoUiW5fegQLFiQdt8uXaBmzeT20aMwZ07afdu3hwcfTG6fOgWzZqXdt3VreOih5Pa5czBtGgAmw6DAtWuY8ue/+Ua/efPkL0j+2U3xRvY2jRpBmzbJ7chImDQp7b716kGHDsnt69eTfz/TUrNm8lhA8u/wBx+k3bdyZXjiiZuP79T3Pv5GMGlSctypCQyEZ5+9+XjKFLhyJfW+3t7w2GM3H+tvRHI7PX8jbtSfXL0aNm9Ou+8tfyMKLFtm+zOekv5GJEvjb0Sq7vI3wubvykMP6W8E3NvfiPs9jwgLS71vZv2NiItLfZtsZPr06Xdc7+7uzpQpU5gyZUqafUqVKsWyO/2OA82bN2f37t0ZivG+3M8HD4ZxMwlvNqfvg4eUCfwMuHr1Kj/88APlypWjaNGiABQsWJBZs2YRGBjI/v37GThwIAULFuTV/35Ge/bsSa1atZg6dSpOTk7s2bPHmtA9duwYbdu25b333mPGjBmcP3+eIUOGMGTIEGbOnJnuuEaNGsUnn3xC+fLlGTVqFN27d+fo0aM4Oztn2jFERETkDs78SnLhgTtM3rEyw5mFStreMGXKFMaPH09YWBg1atTg888/58Ebb/7uYN68eXTv3p3OnTvz6y1vUg8dOsRrr73G+vXrSUxMpHLlyvz888+ULFkyi55F+sXEJ6U5GftWhgGxiSqPICIiIiJ2dj8fPBgG5hsJ26Cg9H3wkPKDu3RasmQJBQoUAODatWsEBASwZMkS680+Ro8ebe1bunRpXnnlFebNm2dN2p46dYoRI0ZQsWLF/55WeWv/cePG0bNnT+tNxsqXL8/kyZNp1qwZU6dOTfddoF955RU6/PdB0dixY6lSpQpHjx6lYsWKmXYMERERuYO4i6QvYUtyv7hLWRnNHZkM407XqNnX/Pnz6dOnD1999RX169dn0qRJLFiwgCNHjuB7Y/ZSKkJCQmjcuDFlypTBy8vLJml77NgxHnzwQQYMGED37t3x9PTkwIEDNGjQ4I77TCkqKopChQoRef48njdmZaZ0H5c1Dp65lT8OhVlvOpZSyvIIAK6WRFpX8mNKz9p33a8ufU5/X4thEBERgW/Ropjv9NxUHiHT+losluQx9/W9eddElUdIlkWXPlsMg4jLl2+Ouf5G3HvfeyiPYElIIOLcOduf8ZT0N+L++qby+2nzd0XlEVLvm8nlEaxjXqQI5iwujxAVFUUhHx8iIyNTPxeTe2I9t01lPGNjYzlx4gRBQUG2ScI7JVFvTdq+/77N74dhGFgsFsxmM6Zbk7Yff5wpSdt+/fpx9uxZpk6dCsDly5f58ssvWbZsGdu3b6dUqVLMnz+fyZMnc+zYMa5evUpiYiKenp7Wm7+9/fbbvP/++zRr1oxWrVrx+OOPU7ZsWQDq1avHvn37rDNvbzyv69evc/DgQSpVqkTp0qUZOnSoNemaWnmE7du3U69ePWuMXl5erF+/nqZNm6brGKm59XuW6nmWZCmNuX1pvO1PY25/GvMstLEbnP6VdM+0LdEFmvycqSHc6VwspWw10/bTTz9l4MCB9O/fH4CvvvqKpUuXMmPGDF5//fVUt0lKSqJnz56MHTuWjRs3cuWWy/5GjRpF+/bt+fjjj63Lbpx83TNX1/RdqnUPl3O1rFGcpUcupqtvvNmZOuX90rf/lG+8HNXX+R5+vBzZ98abRyen1GtPpiZl8iAn9DWb0/9zaY++FsvN36fUxtxkSv9+s0NfyB597/T7eWtiUn8j7r3vvf5+3uln/H72mxf+RtxNar+faf1d0d+Im7Ly9z69r58Z/Rtxn5fKSyZ444201936/R8xwvaxYWBJTMSc8sOiG1KW2rhP+fPnp1y5ctbH33zzDYUKFWLatGl06NDB+p4hODiYQoUKMW/ePCZMmGDt//bbb9OjRw+WLl3K77//zpgxY5g3bx6PPvooV69e5X//+x8vvvjibce9l6v3UiZkTTc+6PvvNTqzjiEiIiJ3ULwLnP4lnZ0tUPzRrIzmjrJN0jY+Pp6dO3cycuRI6zKz2UyrVq3YsmVLmtu98847+Pr6MmDAADZu3GizzmKxsHTpUl599VWCg4PZvXs3QUFBjBw5ki43atKlIi4ujrgUtdOioqKs+7PcaUZWBrSr4sfb7s5Exyamq0zCx8sPE5uQyNMPBeHqrE9bMoPFYrHOABH70Jjbn8bcvjTe9qcxtz97jrm+r9nA/XyYYBg3Z5TfOis7CxPyJpMJs9lMTEwMmzdvplSpUoxKUTf55MmTt21ToUIFKlSowLBhw+jevTszZ87k0UcfpXbt2hw8eNAmKZzZ7HEMERGRPK/k4/DXS5BwBe6YiTOBa2Eo+dgd+mStbJO0vXDhAklJSfj5+dks9/Pz4/Dhw6lus2nTJqZPn86eNG44ExERwdWrV/nwww957733+Oijj1i+fDldu3Zl7dq1NGvWLNXtxo0bx9ixY29bfv78eWJjY+/tiaXDm21K8epvxzBx5x8XgNhECx+v+Icfd5xiRIuS1ClRMNPjyWssFguRkZEYhqHLDuxEY25/GnP70njbn8bc/uw55tHR0Vm6f8kd4uLiCPvvpniXL1/miy++4OrVq3Tq1ImoqChOnTrFvHnzqFevHkuXLmXhwoXWbWNiYhgxYgSPPfYYQUFBnDlzhh07dtCtWzcAXnvtNRo0aMCQIUN45plnyJ8/PwcPHmTVqlV88cUXmRK/PY4hIiKS5zm5Q8NvYUPnO3T670PmBt8m93eQbJO0vVfR0dH07t2badOm4e3tnWqfG7MyOnfuzLBhwwCoWbMmmzdv5quvvkozaTty5EiGDx9ufRwVFUWJEiXw8fHJkjpq3Xx9KVSoEK8s2EdUbCJmE1gMrP97ujvzbucq7Dx5hR+2ncRiQMilWAb//A+dawbyRruK+BR0y/S48gqLxYLJZMLHx0dv9O1EY25/GnP70njbn8bc/uw55roBk6TH8uXLCQgIAKBgwYJUrFiRBQsW0Lx5cwCGDRvGkCFDiIuLo0OHDrz55pu8/V/tXCcnJy5evEifPn0IDw/H29ubrl27WidyVK9enfXr1zNq1CiaNGmCYRiULVuWJ598MtPit8cxREREBCjeCZr+mlzf1rh5Xw0DMyYsyTNsG3yb3M+Bsk3S1tvbGycnJ8LDw22Wh4eH4+/vf1v/Y8eOERISQqdONwfwRpLW2dmZI0eOUKJECZydnalcubLNtpUqVWLTpk1pxuLm5oab2+1JULPZnGVvStpUCWB7BV9+//scy/8O43zkNXwK5adtVX/aVQ3A3cWJzrWK80S9Eoz69W/2nr4CwKI9oaw5FMErwQ/Qq0EpnMx3uBGIpOnG5XN6o28/GnP705jbl8bb/jTm9mevMdf3VO5m1qxZzJo16459Pv74Y5v7XADWm4a5uroyd+7cO25fr149Vq5cmeb6kJAQm8cp7/dcunRpbr3/c+HChW9bdrdjiIiISCbxa25tGk4exBesgWsBfyjRNbkkggNn2N6QbZK2rq6u1KlTh9WrV1vrzVosFlavXs2QIUNu61+xYkX2799vs2z06NFER0fz2WefUaJECVxdXalXrx5Hjhyx6ffPP/9QqlSpLHsuGeXu4sSjtYrTuUZgmncJrFqsEAsHNWLejtN8tPwwkTEJRMclMua3AyzYeZp3O1elVskiDnoGIiIiIiIiIiIi2dy5lTdn2Zbpz+USo/H19cWUjSYLZJukLcDw4cPp27cvdevW5cEHH2TSpElcu3aN/v37A9CnTx+KFSvGuHHjcHd3p2rVqjbbFy5cGMBm+YgRI3jyySdp2rQpLVq0YPny5SxevJh169bZ62llOrPZRI/6JQmu4sdHyw/z419nAPj7bBRdp27mqXolea3tAxT20J2WRUREREREREREbJxdYm0agR0dGEjaslXS9sknn+T8+fO89dZbhIWFUbNmTZYvX269OdmpU6fu+fK4Rx99lK+++opx48bx4osv8sADD/Dzzz/TuHHjrHgKdlW0gBsfP1aDJ+qWYPSvf3M4LBrDgLnbT7HiQBivt6vIY7WLY1bJBBEREREREREREbAkQeiy5LZzfvBtBhcjHRtTKrJV0hZgyJAhqZZDAO46OzatOlZPP/00Tz/99H1Gln3VLe3FkhcaM2tzCBNX/cO1+CQuXYvn1Z/2MX/Had7rUpVKAZl/AzUREREREREREZEc5dIOiDuf3PZvA06339cqO8g+hRrkvjg7mXmmSRlWv9ycjtUDrMt3nrxMx8838e6Sg1yNS7zDHkRERERERERERHK5s4tvtot1clwcd6GkbS7jX8idL3rU5vsBDxLknR+AJIvB9E0naDlhHUv2hd52l1oRERERkZR0vphzWCwWR4cgIiKSs6SoZ0tge8fFcRfZrjyCZI4m5X1YPrQJX68/zhdrjxKXaCE8Ko4hc3Yzr9xp3ulchTI+BRwdpoiIiIhkIy4uLphMJs6fP4+Pjw8m0/3fG8EwDBITE3F2ds6U/UkywzCIj4/n/PnzmM1mXF11E2IREZG7unYKruxLbhd9EPL5QTb9AFRJ21zMzdmJF1qWp0utYoz57QBrDkcAsOnoBdpO2sj/mpXh+eblyOfq5OBIRURERCQ7cHJyonjx4pw5c4aQkJBM2adhGFgsFsxms5K2WcDDw4OSJUve8w2bRURE8iSbWbYdHRdHOihpmweU8PJget+6rDoYztjFBzl7JYb4JAufrznKwt1nGftIFVpW8nN0mCIiIiKSDRQoUIDy5cuTkJCQKfuzWCxcvHiRokWLKrGYyZycnDSDWURE5F6kTNoWz771bEFJ2zzDZDLRpoo/jct788Wao0zbeJyEJIMzl2MY8O1ftK7sx5hOlSlexMPRoYqIiIiIgzk5OeHklDlXY1ksFlxcXHB3d1fSVkRERBwn8RqEr0lu5ysGhWs4Np670FlTHuPh6syrbSvy+0tNaFimqHX5qoPhtPp0PV+uO0p8Yvas5SEiIiIiIiIiIpIhYavBEpfcLtYRsvmVKkra5lHlfAsyZ2B9PnuqJj4F3QCITbDw8fIjtPtsA5uPXnBwhCIiIiIiIiIiIpnk7OKb7WLZuzQCKGmbp5lMJjrXLMbql5vRr1FpzP99wHDs/DV6fLONl+btJiIq1rFBioiIiIiIiIiI3A/DAqFLk9tO+cDvYcfGkw5K2gqe7i68/UgVfhvSmJolCluXL9oTSssJ65n55wkSk1QyQUREREREREREcqDLuyHmXHLbryU453NsPOmgpK1YVS1WiF8GNWJc12oU9nABIDoukbGLD/LIF3+y69RlB0coIiIiIiIiIiJyj86kLI3Q0XFx3AMlbcWG2Wyi+4MlWfNyc56sW8K6/OC5KLp+uZnXf97H5WvxDoxQRERERERERETkHoQuudlW0lZyMq/8rnz0WHV+HtSQSgGe1uXzdpzm4QnrmL/jFBaL4cAIRURERERERERE7uJ6KFzamdwuUgs8ijk2nnRS0lbuqE4pLxYPeYi3OlamgJszAJevJ/Daz/t57KvNHAiNdHCEIiIiIiIiIiIiaQhddrOdQ2bZgpK2kg7OTmaebhzE6peb0alGoHX5rlNX6PT5JsYuPkB0bIIDIxQREREREREREUnF2ZT1bDs5Lo57pKStpJufpzufd6/F7GfqU8YnPwAWA2b+GULLCev5bW8ohqGSCSIiIiIiIiIikg0kxkDYH8ltdz/wquPYeO6BkrZyzx4q583vLzVhRPADuLsk/whFRMfx4tzd9PxmG0cjrjo4QhERERERERERyfMi1kHS9eR2YAcw5ZxUaM6JVLIVN2cnBrcox6phzWhVyc+6fPOxi7T7bAPjVxwmJj7JgRGKiIiIiIiIiEieZlMaIefUswUlbeU+lfDy4Ju+dZnWpy7FCucDICHJYMraY7T6dD2rDoY7OEIREREREREREclzDAPOLklum13Bv7Vj47lHStpKpmhd2Y8/hjdjcIuyuDiZADh7JYaB3/3FM9/u4PSl6w6OUERERERERERE8owr++H66eS2XwtwKeDYeO6RkraSafK5OjEiuCK/v9SUh8oVtS7/41AErSeuZ8rao8QlqmSCiIiIiIiIiIhksdAlN9uBOas0AihpK1mgnG8BfhhQn8nda+Fb0A2A2AQL41ccod2kjWz694KDIxQRERERERERkVztTM6tZwtK2koWMZlMPFIjkNUvN+Pph4IwJ1dM4PiFa/Savo0X5u4mPCrWsUGKiIiIiIiIiEjuExsBF7cltwtVhQKlHRpORihpK1mqoLsLb3WqzOIXGlO7ZGHr8sV7Q2k5YT3TN50gMcniuABFRERERERERCR3Cf0dMJLbOXCWLShpK3ZSJbAQPz3XiI+6VaOIhwsAV+MSeXfJQTp+vomdJy85OEIREREREREREckVzubs0gigpK3Ykdls4sl6JVnzcnO6P1jCuvxwWDTdpm7htZ/2celavAMjFBERERERERGRHC0pHs6tSG67FYWiDRwbTwYpaSt2VyS/K+O6VueX5xtROcDTunz+X6d5eMI65m4/hcViODBCERERERERERHJkc5vgMSrye2A9mB2cmw8GaSkrThM7ZJF+G3IQ4zpVJmCbs4AXLmewMhf9tN16mb+Phvp4AhFRERERERERCRHObvkZjuHlkYAJW3FwZydzPR/KIjVLzejc81A6/I9p6/wyBebePu3A0TFJjgwQhERERERERERyREM42Y9W5MzBAQ7Np77oKStZAu+nu589lQt5jxTn7I++QGwGDBrcwgPf7KeRXvOYhgqmSAiIiIiIiIiImmIOgxXjye3fZuCayHHxnMflLSVbKVROW9+f6kpr7Z9AHeX5B/PC1fjeGneHnpM28bRiGgHRygiIiIiIiIiItlSLimNAEraSjbk6mzm+ebl+GN4M1pX9rMu33L8Iu0+28hHyw9zPT7RgRGKiIiIiIiIiEi2c6M0AkCgkrYiWaJ4EQ+m9anL9L51KV4kHwAJSQZT1x2j9acbWHEgTCUTREREREREREQE4i7BhT+T254PgGd5x8Zzn5S0lWyvZSU/Vg1rxgsPl8PVKflH9uyVGP73/U4GfPsXpy5ed3CEIiIiIiIiIiLiUOeWg2FJbufwWbagpK3kEPlcnXi5zQMsH9qExuW8rcvXHI6g9cT1fL76X+ISkxwYoYiIiIiIiIiIOEwuqmcLStpKDlPGpwDfD3iQL3rUwregGwBxiRYmrPqHtpM2svHf8w6OUERERERERERE7MqSAKG/J7ddCoPPQw4NJzMoaSs5jslkomP1QFa/3IwBjYNwMpsAOHHhGr2nb2fwnF2ERcY6OEoREREREREREbGL85sh4UpyO7AtmF0cGk5mUNJWcqyC7i682bEyS15oTJ1SRazLl+47R8sJ6/hm43ESkiwOjFBERERERERERLJcaIrSCLmgni0oaSu5QKUATxb8ryEfP1Ydr/yuAFyLT+K9pYfo9PkmdoRccnCEIiIiIiIiIiKSZc4uTv7fZE6eaZsLKGkruYLZbOKJuiVY83Izuj9YElNyxQQOh0Xz+FdbGLFgLxevxjk2SBERERERERERyVxR/0LUkeS290PgVtSx8WQSJW0lVyns4cq4rtX4ZVAjqgR6Wpcv2HmGhyesZ/a2k1gsBgCxCUn8susMg2bv4vkFRxg0exe/7DpDbEKSo8IXERGRHGrcuHHUq1ePggUL4uvrS5cuXThy5IhNn+bNm2MymWy+nnvuOZs+p06dokOHDnh4eODr68uIESNITEy06bNu3Tpq166Nm5sb5cqVY9asWVn99ERERESyr9ClN9vFckdpBABnRwcgkhVqlSzCb0Ma88PWk3yy4gjRcYlExiQwauHf/PjXGTpVD2Dymn+JiknEbAKLAebQq6w4EM7biw/w6eM1aVXZz9FPQ0RERHKI9evXM3jwYOrVq0diYiJvvPEGbdq04eDBg+TPn9/ab+DAgbzzzjvWxx4eHtZ2UlISHTp0wN/fn82bN3Pu3Dn69OmDi4sLH3zwAQAnTpygQ4cOPPfcc8yePZvVq1fzzDPPEBAQQHBwsP2esIiIiEh2cTZFPVslbUWyPyezib6NStOumj/jlh1m4e6zAOw9fYW9p69Y+/038db6f3RMIgO//4uve9eltRK3IiIikg7Lly+3eTxr1ix8fX3ZuXMnTZs2tS738PDA398/1X2sXLmSgwcP8scff+Dn50fNmjV59913ee2113j77bdxdXXlq6++IigoiAkTJgBQqVIlNm3axMSJE5W0FRERkbwnPhIi1ie3C5QBz0qOjScTKWkruZ5vQXcmPlmTJ+qWYNSv+zl+/tod+xuAyYBXFuxh2xutcHdxsk+gIiIikmtERkYC4OXlZbN89uzZ/PDDD/j7+9OpUyfefPNN62zbLVu2UK1aNfz8bn5oHBwczKBBgzhw4AC1atViy5YttGrVymafwcHBDB06NM1Y4uLiiIu7Wds/KioKAIvFgsViua/nmR4WiwXDMOxyLNF4O4LG3L403vanMbc/jfk9CF2O2UguJWUEdsAwDDCMe9qFvcc7vcdR0lbyjIZli/Jc07K8+vO+u/Y1gMiYRH7/+xyP1iqe9cGJiIhIrmGxWBg6dCgPPfQQVatWtS7v0aMHpUqVIjAwkH379vHaa69x5MgRfvnlFwDCwsJsEraA9XFYWNgd+0RFRRETE0O+fPlui2fcuHGMHTv2tuXnz58nNjb2/p5sOlgsFiIjIzEMA7NZt9TIahpv+9OY25fG2/405vanMU+/Qsd/5sbZz2WPh4iPiLjnfdh7vKOjo9PVT0lbyVPWHI6w1rC9G7MJVvwdrqStiIiI3JPBgwfz999/s2nTJpvlzz77rLVdrVo1AgICaNmyJceOHaNs2bJZFs/IkSMZPny49XFUVBQlSpTAx8cHT0/PO2yZOSwWCyaTCR8fH73xtAONt/1pzO1L421/GnP705inkyUJ0+W1ABjOBShc/hFwcrv33dh5vN3d3dPVT0lbyVOuXI9PV8IWkhO7V2LiszYgERERyVWGDBnCkiVL2LBhA8WL3/mD3/r16wNw9OhRypYti7+/P9u3b7fpEx4eDmCtg+vv729dlrKPp6dnqrNsAdzc3HBzu/0NjNlsttsbQZPJZNfj5XUab/vTmNuXxtv+NOb2pzFPh4tbIe4CAKaAYEwuqZ8LpYc9xzu9x9B3XvKUwh6umE3p7x+XkFzXRERERORODMNgyJAhLFy4kDVr1hAUFHTXbfbs2QNAQEAAAA0bNmT//v1EpLisb9WqVXh6elK5cmVrn9WrV9vsZ9WqVTRs2DCTnomIiIhIDnF2yc12sY6OiyOLKGkreUqbKn7pnmkLsPv0FZ76eit/n43MuqBEREQkxxs8eDA//PADc+bMoWDBgoSFhREWFkZMTAwAx44d491332Xnzp2EhITw22+/0adPH5o2bUr16tUBaNOmDZUrV6Z3797s3buXFStWMHr0aAYPHmydKfvcc89x/PhxXn31VQ4fPsyXX37Jjz/+yLBhwxz23EVEREQcIvRG0tYEge0dGkpWUNJW8pT21QLwzOfMPUy2ZduJS3T6YhMjFuwlIirrb9YhIiIiOc/UqVOJjIykefPmBAQEWL/mz58PgKurK3/88Qdt2rShYsWKvPzyy3Tr1o3Fixdb9+Hk5MSSJUtwcnKiYcOG9OrViz59+vDOO+9Y+wQFBbF06VJWrVpFjRo1mDBhAt988w3BwcF2f84iIiIiDnPtJFzZn9wuWh/cfR0bTxZQTVvJU9xdnPj08ZoM/P4vTAakNunW9N8/g5qVZen+c5y8eB3DgAU7z7B0/zmeb16WZ5qUwd3Fyc7Ri4iISHZ1t3JKJUqUYP369XfdT6lSpVi2bNkd+zRv3pzdu3ffU3wiIiIiuUouL40AmmkreVCryn583bsunvmSP7O4UeP2xv+e+ZyZ1rsur7atyMphTRnVvhIF3ZP7Xo9P4pOV/9BywnoW7TmrerciIiIiIiIiIvaWB5K2mmkreVLryn5se6MVv/99juV/h3E+8ho+hfLTtqo/7aoGWGfRujk7MbBpGbrWLsbEP/5hzrZTWAw4eyWGl+btYdbmEN7sWJnaJYs4+BmJiIiIiIiIiOQBCVchfE1y26MEFK7u2HiyiJK2kme5uzjxaK3idK4RSEREBL6+vpjNqU8+L1rAjfe6VKNPw9K8u+QgG/+9AMDuU1fo+uVmOtcM5LW2FQksnM+eT0FEREREREREJG8J+wMs8cntYh3BdC93Lso5VB5B5B5U8CvId08/yMx+9Sjrk9+6fNGeUFp8so5PVx7hWlyiAyMUEREREREREcnFQlOURgjMnaURQElbkXtmMploUdGX5UObMvaRKhT2cAEgLtHC5DVHafHJOhb8dRqLRfVuRUREREREREQyjWGBs0uT2075wK+FY+PJQkraimSQi5OZvo1Ks/6VFjz9UBDO/93JLCI6jhE/7aPzlD/ZfuKSg6MUEREREREREcklLu2E2LDktn9rcM69ZSqVtBW5T4U8XHirU2VWDmtKq0q+1uX7z0byxP9t4fnZOzl96boDIxQRERERERERyQXOpiiNUCz3lkYAJW1FMk0ZnwJ807ces5+pT0X/gtbly/aH0XLCesb9fojo2AQHRigiIiIiIiIikoOlTNoGtndcHHagpK1IJnuonDdLX2zCuK7V8C7gCkB8koX/W3+cFp+sY862UySp3q2IiIiIiIiISPpdPwuXdyW3i9QGj2KOjSeLKWkrkgWczCa6P1iSta8057lmZXF1Sv5Vu3A1njcW7qfD5I38efSCg6MUEREREREREckhQpfebBfr5Lg47ERJW5EsVNDdhdfbVeSP4c1oX83fuvxwWDQ9v9nGM9/u4Pj5qw6MUEREREREREQkB8hD9WxBSVsRuyhZ1IMve9bhx/81pFqxQtblfxyKoM3EDbyz+CCR11XvVkRERERERETkNokxEPZHctvdH7xqOzYeO1DSVsSOHgzyYtHgh/jk8Rr4eboBkGgxmPHnCZp9spZZf54gIcni4ChFRERERERERLKR8DWQFJPcLtYRTLk/pZn7n6FINmM2m3isTnHWvtKcF1uWx90l+dfwyvUE3l58kLaTNrD2cASGoZuViYiIiIiIiIjktdIIoKStiMN4uDozvHUF1rzcnC41A63Lj52/Rv9ZO+gzYzv/hEc7MEIREREREREREQczDAj9L2lrdgO/lo6Nx06UtBVxsMDC+Zj0VC0WPt+I2iULW5dv/PcCbSdtYPSv+7l4Nc5xAYqIiIiIiIiIOMqVvXD9THLbrwW4FHBsPHaipK1INlGrZBF+HtSIyd1rUaxwPgAsBvyw9RTNP1nH1xuOEZeY5OAoRURERERERETsyKY0QifHxWFnStqKZCMmk4lHagSy+uVmjAh+AA9XJwCiYxP5YNlh2kzcwPK/w1TvVkRERERERETyBpukbQfHxWFnStqKZEPuLk4MblGOda8054m6xTGZkpefvHid537YSfdpW/n7bKRjgxQRERERERERyUox4XBxe3K7cDXIX8qx8diRkrYi2ZivpzsfP1aDxUMaUz/Iy7p86/FLdPpiE6/+tJeI6FgHRigiIiIiIiIikkVClwH/XW2ch0ojgJK2IjlC1WKFmPdsA77qVZuSXh5A8s0Tf/zrDC3Gr2PK2qPEJqjerYiIiIiIiIjkIqEpSiMEdnRcHA6gpK1IDmEymWhbNYBVw5vyRvuKFHRzBuBafBLjVxyh5YT1LN4bqnq3IiIiIiIiIpLzJcXBuZXJbTdvKPqgY+OxMyVtRXIYN2cnnm1alrUjmtOzfknM/9W7PXslhhfm7uaxr7aw5/QVh8YoIiIiIiIiInJfItZD4tXkdmB7MDs5Nh47U9JWJIfyLuDG+49W4/eXmtKkvLd1+c6Tl+ky5U+Gzd/DucgYB0YoIiIiIiIiIpJBZ1OURshj9WxBSVuRHO8B/4J89/SDzOhXlzI++a3LF+4+S4tP1vHpqn+4Hp/owAhFRERERERERO6BYdxM2pqcIaCNY+NxACVtRXIBk8nEwxX9WDG0KW93qkyhfC4AxCZYmLz6X1p8so6fd57BYlG9WxERERERERHJ5qIOwbUTyW3fZuDi6dh4HCBbJm2nTJlC6dKlcXd3p379+mzfvj1d282bNw+TyUSXLl3S7PPcc89hMpmYNGlS5gQrko24OJnp91AQ60c0p/9DpXH+r+BteFQcLy/YS5cv/2RHyCUHRykiIiIiIiIicgdnF99s58HSCJANk7bz589n+PDhjBkzhl27dlGjRg2Cg4OJiIi443YhISG88sorNGnSJM0+CxcuZOvWrQQGBmZ22CLZSmEPV8Z0qsKKYU1pWdHXunzfmUge/2oLg2fv4vSl6w6MUEREREREREQkDTb1bDs6Lg4HynZJ208//ZSBAwfSv39/KleuzFdffYWHhwczZsxIc5ukpCR69uzJ2LFjKVOmTKp9zp49ywsvvMDs2bNxcXHJqvBFspWyPgWY3q8ePwyozwN+Ba3Ll+4/R8tP1/PR8sNExyY4MEIRERERERERkRTiLsKFzcltz4pQsKxj43GQbJW0jY+PZ+fOnbRq1cq6zGw206pVK7Zs2ZLmdu+88w6+vr4MGDAg1fUWi4XevXszYsQIqlSpkulxi2R3jct7s/TFxrz/aFWK5ncFID7RwtR1x2jxyTrmbj9FkurdioiIiIiIiIijhf4OhiW5nUdn2QI4OzqAlC5cuEBSUhJ+fn42y/38/Dh8+HCq22zatInp06ezZ8+eNPf70Ucf4ezszIsvvpiuOOLi4oiLi7M+joqKApKTvxaLJV37uB8WiwXDMOxyLMk74202Qfd6JehQzZ8v1x1j1p8hxCcZXLgaz8hf9vPt5hBGd6hEo7JFszyWvDLm2YnG3L403vanMbc/e465vq8iIiIieYhNaYS8Wc8WslnS9l5FR0fTu3dvpk2bhre3d6p9du7cyWeffcauXbswmUzp2u+4ceMYO3bsbcvPnz9PbGzsfcWcHhaLhcjISAzDwGzOVpOhc6W8ON5P1/YiuGx+vth4hrVHrwBwOCyaXtO306RMIV5oUpySRdyz7Ph5ccwdTWNuXxpv+9OY2589xzw6OjpL9y8iIiIi2YQlAc4tT267FAbvRg4Nx5GyVdLW29sbJycnwsPDbZaHh4fj7+9/W/9jx44REhJCp043s+43ZmI4Oztz5MgRNm7cSEREBCVLlrT2SUpK4uWXX2bSpEmEhITctt+RI0cyfPhw6+OoqChKlCiBj48Pnp6e9/s078pisWAymfDx8dEbTzvIq+Pt6wvTy5dg+4lLvLf0EH+HJs8o33g8kq0no+jdoBQvPFyOQvkyvwZ0Xh1zR9KY25fG2/405vZnzzF3d8+6DxJFREREJBs5/yckRCa3A9uBOVulLu0qWz1zV1dX6tSpw+rVq+nSpQuQ/IZg9erVDBky5Lb+FStWZP/+/TbLRo8eTXR0NJ999hklSpSgd+/eNjVyAYKDg+nduzf9+/dPNQ43Nzfc3NxuW242m+32RtBkMtn1eHldXh7vBmW9+W1IY37edYbxK44QER1HQpLBjD9DWLj7LENbVaBH/ZK4OGXu2OTlMXcUjbl9abztT2Nuf/Yac31PRURERPKIs4tvtvNwaQTIZklbgOHDh9O3b1/q1q3Lgw8+yKRJk7h27Zo1wdqnTx+KFSvGuHHjcHd3p2rVqjbbFy5cGMC6vGjRohQtaluj08XFBX9/fx544IGsf0IiOYDZbOLxuiVoXy2A/1t/jP/bcJy4RAuXrycw5rcDfL/1JKM7VKL5A76ODlVEREREREREcqsb9WxNThAQ7NhYHCzbJW2ffPJJzp8/z1tvvUVYWBg1a9Zk+fLl1puTnTp1SrMtRLJIfjdnhrd5gCcfLMnHyw+zaE8oAEcjrtJv5g6aVfBhdIdKlPcr6OBIRURERERERCRXifoHov9Jbvs8BG5ejo3HwbJd0hZgyJAhqZZDAFi3bt0dt501a9Zd959aHVsRualY4Xx89lQt+jYqzbtLDrL71BUA1v9znk1HL9CzfkmGtqqAV35XxwYqIiIiIiIiIrnDjVm2AIEdHRdHNqEpqyKSptoli/DLoEZ89lRNAgsl3wQmyWLw3ZaTNBu/lm82Hic+0eLgKEVEREREREQkxwtNkbTN4/VsQUlbEbkLk8lE55rFWPNKc15uXQEPVycAomMTeW/pIdpMXM/KA2EYhuHgSEVEREREREQkR4q/AhEbk9sFyoKn7kOlpK2IpIu7ixMvtCzP2lea83id4phMyctDLl7n2e930mPaNg6GRjk2SBERERERERHJec6tBCMxuV2sI9akQx6mpK2I3BM/T3fGP16DxUMa82DQzaLgW45fpMPnG3n9531ERMc6MEIRERERERERyVHOLr7ZVmkEIJveiExEsr+qxQox/9kGLP87jA9+P8TpSzEYBszbcZrFe0N5vkU5BjQOwt3FybpNbEISy/afY8WBMM5fuYZP4TMEV/GnfbUAm34iIiIiIiIikkdYkiB0WXLbuSD4NHFsPNmEkrYikmEmk4l21QJ4uJIvs/4M4fM1R7kal8i1+CTGrzjC3O2neL1dRTpUC+CPQxG8vGAPUTGJmE1gMcAcepUVB8J5e/EBPn28Jq0q+zn6KYmIiIiIiIiIPV3cCvGXktsBweDk6th4sgmVRxCR++bm7MT/mpVl3Yjm9KhfEvN/pWfOXI5hyJzdtP50Pc9+9xfRMcn1aSz/3bPsxv/RMYkM/P4vVh0Md0D0IiKSl3z00UecPXvW0WGIiIiIyA02pRE6Oi6ObEZJWxHJNN4F3Pjg0Wose6kJjct5W5cfPX8NAzDS2M74759XFuwhNiHJDpGKiEheNWrUKEqVKsXDDz/MzJkziY6OdnRIIiIiInnb2SX/NUwQ2N6hoWQnStqKSKar6O/J9wMeZHrfuvgUSN9lDQYQGZPI73+fy9rgREQkTzt58iTjxo3j0qVLDBgwAH9/f5566imWLl1KUpI+OBQRERGxq6snIPJActu7Abj7ODaebERJWxHJEiaTiZaV/KhVqgimdG5jNsGKv1UiQUREsk6xYsUYMWIEe/bsYd++fbz44ots3bqVTp06ERAQwAsvvMC2bdscHaaIiIhI3nB26c22SiPYyFDStl27dsyZM4eYmJjMjkdEcpmo6wlplkW4lcWAKzHxWRqPiIjIDVWrVmXcuHGEhISwfv16mjRpwpdffkmjRo2oUKEC7733HhEREY4OU0RERCT3sqln28lxcWRDGUraHj9+nF69euHn50ffvn35448/MIz0pmVEJC8p7OFqvTHZ3ZiAwvl0l0gREbGf2NhY5s2bx8cff8zixYtxcnKiXbt2VK1alXfffZeyZcuycOFCR4cpIiIikvskREPEuuS2R0koVNWh4WQ3GUraHjlyhG3bttG/f39WrlxJcHAwxYsXt15qJiJyQ5sqfljS+ZmOAZy8eI1D56KyNCYREcnbDMNg5cqV9O3bFz8/P3r06EFoaCgff/wxZ86cYcmSJfzyyy+EhIRQp04dXn75ZUeHLCIiIpL7hP0Blv+uti3WEUzpLa6YN2S4pm29evX47LPPOHv2LMuWLePhhx/m//7v/6hTpw5Vq1a1nvSKSN7WvloAnvmc013X9lBYNO0nb2T4/D2cvnQ9S2MTEZG8Z9iwYRQrVox27dqxevVqnnvuOfbv38/OnTsZOnQovr6+1r4BAQE888wzhISE3HW/48aNo169ehQsWBBfX1+6dOnCkSNHbPrExsYyePBgihYtSoECBejWrRvh4ba13E+dOkWHDh3w8PDA19eXESNGkJiYaNNn3bp11K5dGzc3N8qVK8esWbMyPB4iIiIiDmNTGkH1bG913zciM5vNBAcH8/3333Pq1Ckee+wxDh48yOuvv07p0qVp1aoVS5cuvfuORCRXcndx4tPHa4KJNBO3pv++vDxcADAM+GX3WVpOWM/YxQe4eDXOTtGKiEhuN23aNFq2bMny5cs5ffo0H330EVWqVEmzf+PGjZk5c+Zd97t+/XoGDx7M1q1bWbVqFQkJCbRp04Zr165Z+wwbNozFixezYMEC1q9fT2hoKF27drWuT0pKokOHDsTHx7N582a+/fZbZs2axVtvvWXtc+LECTp06ECLFi3Ys2cPQ4cO5ZlnnmHFihUZHBERERERBzAsEPpfvtDJA/xaODaebMg5M3ayadMmfvjhB3766ScuXbpE1apV6dOnDy4uLsyYMYNHHnmEUaNG8c4772TG4UQkh2lV2Y+ve9fllQV7iIxJxGxKvunYjf898zkz4fGaNC7vzfdbTvLF2qNExiQQn2Rh5p8hLPjrDAOblOGZJkHkd8uUP1siIpJHhYeHkz9//nT3L126NKVLl75rv+XLl9s8njVrFr6+vuzcuZOmTZsSGRnJ9OnTmTNnDg8//DAAM2fOpFKlSmzdupUGDRqwcuVKDh48yB9//IGfnx81a9bk3Xff5bXXXuPtt9/G1dWVr776iqCgICZMmABApUqV2LRpExMnTiQ4ODj9AyEiIiLiSBf/gtj/bvga0Bqc3B0bTzaU4Zm2Bw8e5I033iAoKIhmzZqxaNEi+vbty65du9i3bx+vvPIKL730Env37mXAgAFMmTIlM+MWkRymdWU/tr3RiolP1qB1ZT9qFy9A68p+THyyBtveaEWryn64uzgxsGkZNrzaguebl8XdJflP1NW4RCb+8Q/Nxq/luy0hxCdaHPxsREQkp6pWrRq//fZbmuuXLFlCmTJl7vs4kZGRAHh5eQGwc+dOEhISaNWqlbVPxYoVKVmyJFu2bAFgy5YtVKtWDT8/P2uf4OBgoqKiOHDggLVPyn3c6HNjHyIiIiI5QuiSm+1AlUZITYamrNWsWZP9+/fj5uZG586d+fLLLwkODsZsTj0H3KJFC7755pv7ClREcj53FycerVWczjUCiYiIwNfXN9W/G4XyufBq24r0bVSaz1b/y/wdp0myGFy4Gs9biw7wzcYTvNymAp2qB2I2q1C5iIikX0hICFevXk1z/dWrVzl58uR9HcNisTB06FAeeughqlZNvgtyWFgYrq6uFC5c2Kavn58fYWFh1j4pE7Y31t9Yd6c+UVFRxMTEkC9fvtviiYuLIy7uZqmhqKgoa5wWS9Z/EGqxWDAMwy7HEo23I2jM7UvjbX8ac/vLC2NuOrPYWkLREtAOHPhc7T3e6T1OhpK2hQsX5uuvv+bxxx/H09Pzrv07d+7MiRMnMnIoEcnD/Dzd+eDRajzTOIgJK/9h6f5zAJy6dJ2X5u3h6w3Hea1tRZqU98aku0yKiEg63ek1Y8eOHbclVu/V4MGD+fvvv9m0adN97SezjBs3jrFjx962/Pz588TGxmb58S0WC5GRkRiGkeYkD8k8Gm/705jbl8bb/jTm9pfbx9wcG4rvlT0AJBSswcVoJ4iOcFg89h7v6OjodPXLUNJ23bp199Tfw8ODUqVKZeRQIiKU8SnAlJ61efb0FT5afpjNxy4CcCA0ij4zttOobFFea1uRGiUKOzZQERHJlj777DM+++wzIDlhO3ToUEaNGnVbv8jISK5cuUKPHj0yfKwhQ4awZMkSNmzYQPHixa3L/f39iY+P58qVKzZJ4fDwcPz9/a19tm/fbrO/8PBw67ob/99YlrKPp6dnqrNsAUaOHMnw4cOtj6OioihRogQ+Pj7pmoBxvywWCyaTCR8fn1z5xjO70Xjbn8bcvjTe9qcxt79cP+ZHF1qbTqW64Ovr68Bg7D/e7u7pq9+boaTtrl272Lp1K88//3yq67/88ksaNWpEzZo1M7J7EZFU1ShRmNnP1Gfjvxf48PfDHDyXfHnn5mMX6TzlTzpUC+DlNhUo41PAwZGKiEh24uvrS5UqVYDk8gjFihWjWLFiNn1MJhP58+enTp06aZ7j3olhGLzwwgssXLiQdevWERQUZLO+Tp06uLi4sHr1arp16wbAkSNHOHXqFA0bNgSgYcOGvP/++9YSQgCrVq3C09OTypUrW/ssW7bMZt+rVq2y7iM1bm5uuLm53bbcbDbb7Y2gyWSy6/HyOo23/WnM7UvjbX8ac/vL1WMeutTaNBfvBNngOdpzvNN7jAwlbUeNGkW+fPnSPKFds2YNy5YtY8mSJamuFxHJKJPJRNMKPjQu583ifaFMWPkPpy5dB2Dp/nMsPxDGk/VKMLRleXw9dfdJERGB7t270717dyD5XgujR4+mZcuWmXqMwYMHM2fOHBYtWkTBggWtNWgLFSpEvnz5KFSoEAMGDGD48OF4eXnh6enJCy+8QMOGDWnQoAEAbdq0oXLlyvTu3ZuPP/6YsLAwRo8ezeDBg61J1+eee44vvviCV199laeffpo1a9bw448/snTp0jRjExEREck2Eq9D+Orkdr5AKFLbsfFkYxlKH+/cuZMmTZqkub5Jkyb89ddfGQ5KRORuzGYTnWsW44/hzXincxW8C7gCkGQxmLPtFE3Hr+Xj5YeJjElwcKQiIpKdrF27NtMTtgBTp04lMjKS5s2bExAQYP2aP3++tc/EiRPp2LEj3bp1o2nTpvj7+/PLL79Y1zs5ObFkyRKcnJxo2LAhvXr1ok+fPrzzzjvWPkFBQSxdupRVq1ZRo0YNJkyYwDfffENwcHCmPycRERGRTBe+BpL+q6kf2AF0f5o0ZWimbXR0NM7OaW9qNpuJjIzMcFAiIunl6mymT8PSdKtdnOmbTvB/649xLT6J2AQLX647xpztpxjcvBy9G5bC3cXJ0eGKiIidbdiwAYCmTZvaPL6bG/3TyzCMu/Zxd3dnypQpTJkyJc0+pUqVuq38wa2aN2/O7t277yk+ERERkWzhbIqr8ot1dFwcOUCGkrbly5dn5cqVvPDCC6muX758OWXKlLmvwERE7kV+N2debFmenvVL8sXao/yw9SQJSQZXrifw/rJDzPzzBENbV6Bb7eI4mfVJnohIXtG8eXNMJhMxMTG4urpaH6fFMAxMJhNJSUl2jFJEREQkDzCMm0lbJ3fwb+XYeLK5DCVtBwwYwLBhwxg+fDhvvfWW9Q64V65cYezYsSxfvpzx48dnZpwiIulStIAbYzpV4emHgpi46h8W7jmLYUBoZCyv/rSPbzYeZ0RwRVpV8r3jm3YREckd1q5dC4Crq6vNYxERERGxs8t7IOZsctvvYXD2cGg42V2GkrYvvvgie/bsYdKkSUyePJnAwEAAQkNDsVgs9O7dm2HDhmVqoCIi96KElwefPlmTgU3L8PHyw6w9ch6Af8KvMvC7v6hbqgivtatIvdJeDo5URESyUrNmze74WERERETsRKUR7kmGbkRmMpmYOXMmq1ev5rnnnqNq1apUrVqVQYMGsWbNGr799lvNYBORbKFSgCcz+z/I/GcbUKtkYevyv05e5vGvtjBg1g6OhEU7LkAREbGrsLCwu/bZvn27HSIRERERyWPOLr7ZDuzguDhyiAzNtL2hRYsWtGjRIrNiERHJMvXLFOWXQY1YeTCcj5cf5tj5awCsPhzBmiMRdK1VnGGty1O8iC7PEBHJzapUqcIXX3xB9+7db1uXkJDA6NGj+fTTT0lISHBAdCIiIiK5VEwYXNqR3C5cA/KXdGw8OUCGZtqKiOREJpOJ4Cr+rBjalI+6VcPf0x1IroX+864zPPzJet5dcpBL1+IdHKmIiGSVunXr0qtXLx577DEuXLhgXb5z505q1arFhAkTePHFFx0YoYiIiEguFLrsZlulEdIlwzNt9+3bx+eff86uXbuIjIzEYrHYrDeZTBw7duy+AxQRyWzOTmaerFeSzjWL8e3mEL5cd4zImATikyxM33SCH3ec5n/NyvB04yA8XO/rggQREclmVqxYwf/93/8xYsQIqlSpwuTJk9m/fz8fffQRpUuXZt26dTRu3NjRYYqIiIjkLqpne88yNNN23bp1PPjggyxZsoTAwECOHz9OmTJlCAwM5OTJkxQoUICmTZtmdqwiIpnK3cWJ/zUry4YRLXiuWVncnJP/JEbHJfLJyn9oNn4d3289SUKS5S57EhGRnOR///sf+/bto1ixYvTo0YNx48bxzDPPsHfvXiVsRURERDJbUiyErUxuu/lA0QcdG08OkaGk7VtvvUWZMmU4cuQIM2fOBOCNN95g06ZNbN68mTNnzvDEE09kaqAiIlmlkIcLr7eryPoRLej+YAmczMk3UjwfHcebv/5N60/Xs3hvKBaL4eBIRUQkMxiGwdy5czl48CB+fn6YTCY2b97Mv//+6+jQRERERHKf8PWQmHxfGYp1AJOqtaZHhkZp165dDBgwAE9PT5ycnABISkoCoH79+vzvf//jzTffzLwoRUTswL+QO+O6VmfF0Ka0reJvXR5y8TovzN1N5yl/sunfC3fYg4iIZHdHjhyhYcOGjBo1iv79+/Pvv/+ydu1arl27Rv369XnvvfduK/slIiIiIvchNEVphECVRkivDCVtnZ2dKViwIACFCxfGxcWFiIgI6/oyZcpw8ODBzIlQRMTOyvkW4KvedVj4fCMalPGyLt9/NpJe07fR65tt7D8T6cAIRUQko2rWrEloaCgrVqxg6tSp5M+fnyZNmrBv3z6eeeYZxowZQ4MGDRwdpoiIiEjuYBhwdnFy2+wCAa0dG08OkqGkbbly5ayXj5lMJipWrMjChQut65cuXYq/v39am4uI5Ai1ShZh7sAGzOpfj0oBntblm45eoNMXmxgyZxchF645MEIREblXTz75JPv376d1a9s3DB4eHnzxxResWrWK8+fPOyg6ERERkVwm8gBcO5nc9m0OLp537C43ZShp2759e+bOnUtiYiIAw4cP55dffqF8+fKUL1+e3377jf/973+ZGqiIiCOYTCaaP+DL0hcaM+nJmpTwymddt2TfOVp9up7Rv+4nIjrWgVGKiEh6zZo1i0KFCqW5/uGHH2b//v12jEhEREQkFzubojRCMZVGuBfOGdnozTff5KWXXrLWs+3bty9OTk78/PPPODk5MWrUKPr165eZcYqIOJTZbKJLrWK0rxbAnG0n+XzNUS5eiyfRYvDD1lP8vPMsAxoH8WyzMni6uzg6XBERuYutW7eydu1aIiIieP755ylfvjzXr1/n8OHDVKhQwdHhiYiIiOQOoUraZtQ9J20TEhI4dOgQXl5emEwm6/JevXrRq1evTA1ORCS7cXU20++hIB6rW4JpG47zzcbjXItPIiYhiS/WHmX2tpMMblGO3g1L4ebs5OhwRUTkFvHx8Tz11FMsWrQIwzAwmUx06tSJ8uXLYzabadOmDcOGDWPUqFGODlVEREQkZ4u9ABe2JLcLVYYCZRwbTw5zz+URzGYzderU4ZdffsmKeEREcoQCbs4Ma12B9a+2oF+j0rg4JX+Idfl6Au8tPcTDn6znp51nSLIYDo5URERSevPNN1myZAlTp07lyJEjGMbNv9Pu7u48/vjjLFq0yIERioiIiOQS534Hw5LcDtQs23t1z0lbJycnSpUqRVxcXFbEIyKSo3gXcOPtR6qwenhzutQM5MYFCGevxPDKgr20/2wjqw+F2yQFRETEcebOncugQYN49tln8fLyum19pUqVOH78uAMiExEREcllVM/2vmToRmQvvPACX3/9NZcuXcrseEREcqSSRT2Y9FQtlrzQmGYVfKzLj4RHM+Dbv3ji/7aw86T+ZoqIOFpERATVqlVLc72TkxPXr1+3Y0QiIiIiuVBSPJxbntx2LQLeDR0bTw6UoRuRJSUl4ebmRtmyZXnssccoXbo0+fLls+ljMpkYNmxYpgQpIpJTVAksxLdPP8iWYxf5cPlh9p6+AsCOkMt0m7qFVpX8eLXtA1TwK+jYQEVE8qgSJUpw+PDhNNf/+eeflCtXzo4RiYiIiORC5zdBQlRyO7A9mDOUgszTMjRir7zyirU9ffr0VPsoaSsieVnDskX59flGrDgQxscrjnD8/DUA/jgUzprD4XSrXZxhrSsQWDjfXfYkIiKZqUePHnz66ad069aNChUqAFhvrjtt2jR+/PFHPvzwQ0eGKCIiIpLzpSyNoHq2GZKhpO2JEycyOw4RkVzHZDLRtmoArSr5sWDnGSb98Q/hUXFYDFiw8wyL9obSt2Epnm9ejiL5XR0drohInjBq1Ci2bt1K06ZNqVSpknWiwaVLlzhz5gzt27fXxAMRERGR+xX6X9LW5ASBwY6NJYfKUNK2VKlSmR2HiEiu5exkpvuDJelSsxizNocwdd1RomITiU+0MG3jCebtOM1zzcry9ENB5HN1cnS4IiK5mqurK8uXL2f27Nn89NNPJCUlERcXR/Xq1Xnvvffo3bu3deatiIiIiGRA1BGI/je57dMkuaat3DMVlBARsZN8rk4Mal6W7g+WYOq6Y8zcHEJ8ooXo2ETGrzjCt5tDeKlVeZ6oWwIXpwzdJ1JERNLBZDLRq1cvevXq5ehQRERERHKflKURiqk0QkZlKGkbFBR01xkIJpOJY8eOZSgoEZHcrLCHKyPbV6LfQ6WZtOpfFuw8jcWAiOg4Ri38m+kbT/BK8AO0q+qv2V4iIiIiIiKSsyhpmykylLRt1qzZbYmEpKQkTp48yZ9//knVqlWpVatWpgQoIpJbBRTKx0ePVWdg0yA+Xn6ElQfDATh+4RrPz95FjeKFeK1tRRqV83ZwpCIiOdfDDz98z9uYTCZWr16dBdGIiIiI5HLxl+H8xuR2gXJQsIJj48nBMpS0nTVrVprr9u7dS3BwMD179sxoTCIieUo534J83acuO09e5qPlh9l+4hIAe89E0uObbTQp781rbStStVghB0cqIpLzWCyWe75qwTCMLIpGREREJJcLXQFGUnK7WCfQ1aMZluk1bWvUqMH//vc/XnvtNXbu3JnZuxcRybXqlCrC/GcbsO7IeT5afpjDYdEAbPz3Ahv/3cQjNQJ5uU0FShXN7+BIRURyjnXr1jk6BBEREZG8I1SlETJLltzpxs/Pj4MHD2bFrkVEcjWTyUSLir4sfbEJnz5Rg2KF81nX/bY3lJYT1vPWor85Hx3nwChFREREREREbmFJhNDfk9sunuDT2LHx5HCZPtP24sWLTJ8+neLFi2f2rkVE8gwns4mutYvToXoAs7ee4ou1R7l0LZ5Ei8F3W07y084zPNOkDAObBFHQ3cXR4YqI5DhLlixh2bJlhISEAFC6dGnat29Px46aESIiIiKSIRe2QHxyuT8C2oKTq2PjyeEylLRN64YOV65c4fDhw8THx/P999/fV2AiIgJuzk483TiIx+sWZ9qG43yz6QTX45O4Hp/E5NX/8sPWkwxpUY6eDUri5uzk6HBFRLK9K1eu8Oijj7JhwwacnJwICAgA4I8//uD//u//aNKkCb/++iuFCxd2bKAiIiIiOc1ZlUbITBkqj2CxWDAMw+YLICgoiCFDhvD333/TvXv3TA1URCQvK+juwvA2D7B+RAv6NCyFszm5mPula/G8s+QgLSes55ddZ0iy2N48JzYhiV92nWHQ7F08v+AIg2bv4pddZ4hNSHLE0xARcbiXXnqJjRs38tFHH3H58mVOnjzJyZMnuXz5Mh9++CGbNm3ipZdecnSYIiIiIjmPtZ6tCQLaOTSU3CBDM211QwcREcfwKejGO52r8vRDQUxY9Q+L94YCcOZyDMN/3MvXG47zWtuKNH/Ahz8ORfDygj1ExSRiNoHFAHPoVVYcCOftxQf49PGatKrs5+BnJCJiX7/++ivPP/88r7zyis3y/PnzM2LECE6dOsV3333noOhEREREcqirxyHyv/tbeTcEd2/HxpMLZMmNyEREJGuV9s7P591rseSFxjQpf/PF8HBYNP1n7aDNxA08+91fRMckAskJ25T/R8ckMvD7v1h1MNzeoYuIOJSLiwsPPPBAmusrVqyIi4tqhYuIiIjcE5vSCJ0cF0cukqGk7eTJkwkODk5zfbt27Zg6dWqGgxIRkfSpWqwQ3w+oz5xn6lO9eCHr8n8jrmIARhrbGf/988qCPSqVICJ5Srdu3ViwYAFJSbf/7UtMTOTHH3/k8ccfd0BkIiIiIjmY6tlmugwlbadPn07lypXTXF+5cmW+/vrrDAclIiL3plE5bxYNfogpPWrjXSB9d+g0gMiYRH7/+1zWBiciko306tWLy5cv06hRI6ZPn8769etZv34933zzDY0aNSIyMpKePXuya9cumy8RERERSUNCNESsS27nLwWFqjg0nNwiQzVtjx07xuDBg9NcX7FiRaZNm5bhoERE5N6ZTCY6VA9g0d6zrDoQnuYs25TMJljxdziP1iqe5fGJiGQHzZo1s7Z37NiByZR8Y8cbN9a9tY9hGJhMplRn5oqIiIgIcG4lWBKS28U6wX/nV3J/MpS0dXV1JSwsLM31586dw2xWuVwREUeIup6QroQtJNe4vRITn6XxiIhkJzNmzLAmakVEREQkE4SmKI0QqNIImSVDSdsGDRowa9Yshg0bRsGCBW3WRUZGMnPmTBo0aJApAYqIyL0p7OGK2XTzpmN3YgIK50tfOQURkZzOMAy6du2Kq6sr7u7ujg5HREREJOczLHB2aXLbOT/4Nbtzf0m3DE2HHTNmDKGhodSsWZPPP/+cNWvWsGbNGiZPnkytWrU4d+4cY8aMyexYRUQkHdpU8UtXwhaS69qGRcVw5vL1LI1JRCQ7iI+Px8vLi8mTJzs6FBEREZHc4eJ2iDuf3PZvDU76YDyzZChpW79+fRYvXoxhGLz00ku0bt2a1q1bM3ToUEwmE7/99hsNGzbM7FhFRCQd2lcLwDOfM+m9+HfP6UgenrCe8SsOczUuMUtjExFxJDc3N/z9/XFzc3N0KCIiIiK5w9kUpRGKdXJcHLlQhgvPtm7dmqNHj7Jjxw7mzp3L3Llz2bFjB0ePHqVNmzaZGaOIiNwDdxcnPn28JphIM3Fr+u+rgFtylZz4RAtT1h6jxSfr+HHHaZLSO1VXRCSH6devH9999x3x8arnLSIiInLfUiZtA9s7Lo5cKEM1bW8wm83UqVOHOnXqZFY8IiKSCVpV9uPr3nV5ZcEeImMSrTVub/zvmc+ZCY/X5MEyXkxZc5QZf54gIcngfHQcr/68j1mbQ3izY2Uali3q6KciIpKpqlWrxq+//kqVKlXo168fpUuXJl++fLf169q1qwOiExEREclBrp2GK3uT2171IJ+/Y+PJZTKUtJ07dy4rVqxg1qxZqa7v378/7dq144knnrif2ERE5D60ruzHtjda8fvf51j+dxjnI6/hUyg/bav6065qAO4uTgCMbF+JHvVLMm7ZYZYfCAPg4Lkouk/bSnAVP95oX4lSRfM78qmIiGSa7t27W9tvvvlmqn1MJhNJSUn2CklEREQkZwpVaYSslKGk7cSJE6lVq1aa6/Ply8fEiROVtBURcTB3FycerVWczjUCiYiIwNfXF7P59so4pYrm56veddhy7CLvLT3IgdAoAFYcCGft4fP0e6g0Qx4uh6e7i72fgohIplq7dq2jQxARERHJHWzq2XZ0XBy5VIaStkeOHOHpp59Oc32NGjWYO3duhoMSERHHaFi2KL8NaczPO88wfuURzkfHEZ9k4esNx/l55xmGta7AU/VK4OyU4ZLoIiIO1axZM0eHICIiIpLzJV6DsNXJ7XyBUKSmQ8PJjTL0rtswDK5cuZLm+suXL5OQkJDRmERExIGczCaeqFeCta80Z3CLsrg6J79UXLwWz+hf/6bD5E1s/Pe8g6MUEbk/cXFxbNmyhUWLFnHhwgVHhyMiIiKSs4StBktccrtYRzCldRtsyagMJW1r1arF3LlzU73rblxcHHPmzLlj+QQREcn+Crg5MyK4IquHN6Nj9QDr8iPh0fSevp0Bs3Zw7PxVB0YoIpIxkydPJiAggMaNG9O1a1f27dsHwIULF/D29mbGjBkOjlBEREQkmzurerZZLUNJ29dff52///6bFi1asHjxYo4fP87x48f57bffaN68OQcOHOD111/P7FhFRMQBSnh58EWP2vz0XENqFC9kXb76cATBEzcwdvEBrly//UM8EZHsaObMmQwdOpS2bdsyffp0DMOwrvP29ubhhx9m3rx5DoxQREREJJszjJs3IXNyB7+HHRtPLpWhmrbt2rVj+vTpvPTSS3Tp0sW63DAMChYsyLRp0+jQoUNmxSgiItlA3dJeLHz+IRbtPctHvx8hLCqWRIvBzD9D+GXXWYa1Kk/PBqVwUb1bEcnGJkyYQOfOnZkzZw4XL168bX2dOnWYPHmyAyITERERySEu74aYc8ltv5bg7OHYeHKpDCVtAfr160fXrl1ZtWoVx44dA6Bs2bK0adOGggULZlqAIiKSfZjNJh6tVZzgKv58veE4X60/RmyChciYBN5efJDvt55kdIfKNH/AB5NqGolINnT06FFefPHFNNd7eXmlmswVERERkf+cXXyzrdIIWSbDSVsAT09PunXrdtvyPXv28MMPP/DJJ5/cz+5FRCSb8nB1ZmirCjxZrwTjlx/hl91nATh2/hr9Z+2gSXlv3uxYmQp++hBPRLKXwoUL3/HGYwcPHsTf39+OEYmIiIjkMDb1bHWlfVbJtGtYQ0JC+OCDD6hSpQq1a9dm4sSJmbVrERHJpgIK5ePTJ2vy6+CHqFOqiHX5xn8v0HbSBkb/up+LV+McGKGIiK327dvz9ddfc+XKldvWHThwgGnTpvHII4/c8343bNhAp06dCAwMxGQy8euvv9qs79evHyaTyearbdu2Nn0uXbpEz5498fT0pHDhwgwYMICrV21v+Lhv3z6aNGmCu7s7JUqU4OOPP77nWEVEREQyLOYcXPoruV2kJngUd2g4udl9JW0vXrzI1KlTady4MWXLluWdd96hePHifP7555w4cSKzYhQRkWyuZonC/PRcQz7vXotihfMBYDHgh62naP7JOqZtOE58osXBUYqIwHvvvUdSUhJVq1Zl9OjRmEwmvv32W3r16kXdunXx9fXlrbfeuuf9Xrt2jRo1ajBlypQ0+7Rt25Zz585Zv+bOnWuzvmfPnhw4cIBVq1axZMkSNmzYwLPPPmtdHxUVRZs2bShVqhQ7d+5k/PjxvP3223z99df3HK+IiIhIhpxderMd2NFxceQB91weISYmhkWLFjF79mxWrlwJQP369QH44YcfeOyxxzI3QhERyRFMJhOdagTSurIf0zed4Mu1R7kWn0R0bCLvLzvE7G0nGdm+Em0q+6nerYg4TGBgIH/99RejRo1i/vz5GIbB999/T8GCBenevTsffvgh3t7e97zfdu3a0a5duzv2cXNzS7P0wqFDh1i+fDk7duygbt26AHz++ee0b9+eTz75hMDAQGbPnk18fDwzZszA1dWVKlWqsGfPHj799FOb5K6IiIhIlglNWRpB9WyzUrpn2q5YsYI+ffrg5+dHr169iImJYcqUKYSFhTFjxgwMw8BszpxqC1OmTKF06dK4u7tTv359tm/fnq7t5s2bh8lkokuXLtZlCQkJvPbaa1SrVo38+fMTGBhInz59CA0NzZRYRUTElruLE4NblGPtK815om5xbuRnQy5e53/f76THtG0cCI10bJAikqf5+fnxzTffcOnSJcLDwzl37hyXL19mxowZ+Pr6Ztlx161bh6+vLw888ACDBg2yueHZli1bKFy4sDVhC9CqVSvMZjPbtm2z9mnatCmurq7WPsHBwRw5coTLly9nWdwiIiIiACTFwrlVyW13Xyha98795b6ke6Ztu3btCAoK4oMPPuDxxx/Hz8/Puu7SpUuZFtD8+fMZPnw4X331FfXr12fSpEnWk9E7nUSHhITwyiuv0KRJE5vl169fZ9euXbz55pvUqFGDy5cv89JLL/HII4/w119/ZVrcIiJiy9fTnY8fq0GfhqV5d8lBtp1Ifq3YcvwiHT/fxJN1SzC8TQV8C7o7OFIRyQu+/vprJk6cyIkTJyhatChPPPEEH374IT4+PnY5ftu2benatStBQUEcO3aMN954g3bt2rFlyxacnJwICwu77VzX2dkZLy8vwsLCAAgLCyMoKMimz41z8rCwMIoUKUJq4uLiiIu7WV88KioKAIvFgsWS9aVrLBYLhmHY5Vii8XYEjbl9abztT2Nuf9l2zMPWYE66DoAR0B7DAIxsFmMG2Hu803ucdCdt/f39OXHiBN9++y3x8fE89dRTBAYGZjjAtHz66acMHDiQ/v37A/DVV1+xdOlSZsyYweuvv57qNklJSfTs2ZOxY8eyceNGmxtLFCpUiFWrVtn0/+KLL3jwwQc5deoUJUuWzPTnICIiN1UtVoh5zzZgxYFwPlh2iFOXrmMYMG/HaRbvDeX5FuUY0DgIdxcnR4cqIrnUr7/+ynPPPUf+/PmpXr06p0+fZvLkyVy5coWZM2faJYannnrK2q5WrRrVq1enbNmyrFu3jpYtW2bpsceNG8fYsWNvW37+/HliY2Oz9NiQ/MYkMjIyU6/Mk7RpvO1PY25fGm/705jbX3Yd84JHF5D/v/aVAk2Ii4hwaDyZxd7jHR0dna5+6U7anjlzhjVr1vDDDz8wduxYXn31VRo1akSPHj2oWbNmRuO0ER8fz86dOxk5cqR1mdlsplWrVmzZsiXN7d555x18fX0ZMGAAGzduvOtxIiMjMZlMFC5cODPCFhGRuzCZTLSt6k+Lij58uzmEz1cfJToukWvxSYxfcYS5208xsl0l2lfzV71bEcl0n376KWXLlmXTpk34+fmRmJhI7969mT17Np999hmenp52j6lMmTJ4e3tz9OhRWrZsib+/PxG3vPFJTEzk0qVL1jq4/v7+hIeH2/S58TitWrkAI0eOZPjw4dbHUVFRlChRAh8fH7s8d4vFgslkwsfHJ1u98cytNN72pzG3L423/WnM7S9bjrlhYNq6JrlpdqVQhW7gUtDBQWUOe4+3u3v6rjZNd9L2RvK0VatWfPXVV9abkb300kskJiZiMpnYsGED9evXp1ixYhkK+sKFCyQlJdmUXoDky74OHz6c6jabNm1i+vTp7NmzJ13HiI2N5bXXXqN79+5pnqTqErK8ReNtfxpz+8suY+5iNvFM4yC61Axk0h//Mm/HaSwGnLkcw+A5u6hbqgijO1SievFCDo3zfmWX8c5LNOb2Z88xv99jHDlyhBEjRljPMZ2dnRk5ciTz58/n0KFD1pvq2tOZM2e4ePEiAQEBADRs2JArV66wc+dO6tSpA8CaNWuwWCzW+Bo2bMioUaNISEjAxcUFgFWrVvHAAw+kWRoBkm+A5ubmdttys9lstzeCJpPJrsfL6zTe9qcxty+Nt/1pzO0v2435lf1w/RQAJt/mmNxy9nu2W9lzvNN7jHQnbVNyd3fnySef5Mknn+TSpUvMmzePOXPmMHnyZD7//HNq1qzJI488wpgxYzKy+3SLjo6md+/eTJs2LV13+U1ISOCJJ57AMAymTp2aZj9dQpa3aLztT2Nuf9lxzF9s5Ev7CgX5bMNpdpxKvjzkr5OX6fLlZtpX8uK5h4rhW8D1LnvJnrLjeOd2GnP7s+eYp/cSsrScP3/+trJeNyYZXL9+/b72fcPVq1c5evSo9fGJEyfYs2cPXl5eeHl5MXbsWLp164a/vz/Hjh3j1VdfpVy5cgQHBwNQqVIl2rZty8CBA/nqq69ISEhgyJAhNiXJevTowdixYxkwYACvvfYaf//9N5999hkTJ07MlOcgIiIikqazi2+2i3V0XBx5SIaStil5eXnx/PPP8/zzzxMSEsIPP/zA7Nmzeeedd+45aevt7Y2Tk1Oql32ldsnXsWPHCAkJoVOnTtZlN2ZiODs7c+TIEcqWLQvcTNiePHmSNWvW3PFSMF1ClrdovO1PY25/2XXMfX2hYaWSrDlyng+WHebEhWsALDt0ibVHI/lf0yAGNilDPtecVe82u453bqYxtz97jnl6LyG7k6wuvfLXX3/RokUL6+Mb55J9+/Zl6tSp7Nu3j2+//ZYrV64QGBhImzZtePfdd21mwM6ePZshQ4bQsmVLzGYz3bp1Y/Lkydb1hQoVYuXKlQwePJg6derg7e3NW2+9xbPPPpulz01ERESEs0tutpW0tYv7TtqmVLp0aUaPHs3o0aPZvXv3PW/v6upKnTp1WL16NV26dAGS3xCsXr2aIUOG3Na/YsWK7N+/32bZ6NGjiY6O5rPPPqNEiRLAzYTtv//+y9q1aylatOgd49AlZHmPxtv+NOb2l53HvHVlf5o/4Mv3W07y2ep/iYxJICYhiUmrjzL/rzO81rYij9QIxGzOOfVus/N451Yac/uz15hnxv4/+eQT5s6da32ckJAAwKhRo267YstkMrFo0aJ72n/z5s0xDCPN9StWrLjrPry8vJgzZ84d+1SvXj1d93AQERERyTSx5+HC1uR2oSpQIMix8eQRmZq0TalWrVoZ2m748OH07duXunXr8uCDDzJp0iSuXbtG//79AejTpw/FihVj3LhxuLu7U7VqVZvtb9xc7MbyhIQEHnvsMXbt2sWSJUtISkoiLCwMSD4xdnXNmZfeiojkNi5OZp5uHMSjtYrx2ep/+X7rSZIsBuciYxk6fw+zNofwZsfK1CmVdt1GEZHUlCxZkkuXLnHp0iWb5aVKleLcuXOcO3fOZrluiCgiIiKSQujvwH8fTmuWrd1kWdI2o5588knOnz/PW2+9RVhYGDVr1mT58uXWG0ecOnXqnmZbnD17lt9++w2AmjVr2qxbu3YtzZs3z6zQRUQkExTJ78rbj1ShV4OSvL/0EGuPnAdgz+krdJu6mU41Anmt7QMUL+Lh4EhFJKcICQlxdAgiIiIiOZdNPdtOafeTTJXtkrYAQ4YMSbUcAsC6devuuO2sWbNsHpcuXfqOl6qJiEj2VM63IDP7P8j6f87z3pKD/BtxFYDFe0NZeSCMgU3KMKh5WfK7ZcuXMhERERERkZwvKR7O/VfmydULijZwbDx5iIq+iYhIttasgg+/v9SEd7tUpYiHCwBxiRa+WHuUFp+s48e/TmOx6MM5ERERERGRTHd+IyRGJ7cD24M5Z90kOidT0lZERLI9ZyczvRuUYt2IFgxsEoSLU3K9yYjoOF79aR+PTNnEtuMXHRyliIiIiIhILmNTGkH1bO3pvpK2cXFxbNmyhUWLFnHhwoXMiklERCRVhfK5MKpDZVYOa0abyn7W5X+fjeLJr7cy6IednLp43YERioiIiIiI5BKGcTNpa3KGgGDHxpPHZDhpO3nyZAICAmjcuDFdu3Zl3759AFy4cAFvb29mzJiRaUGKiIikFOSdn6/71GXOwPpUCvC0Lv/97zBafbqecb8fIjo2wYERioiIiIiI5HBRR+Dq8eS2bxNwLezQcPKaDCVtZ86cydChQ2nbti3Tp0+3udGXt7c3Dz/8MPPmzcu0IEVERFLTqKw3S15ozIddq+FdwA2A+CQL/7f+OM3Hr2POtlMkqd6tiIiIiIjIvQtdcrMdqNII9pahpO2ECRPo3Lkzc+bMoVOnTretr1OnDgcOHLjv4ERERO7GyWziqQdLsvaVZgxqXhZX5+SXtovX4nlj4X46TN7In0dVwkdEbKnMl4iIiMhd2NSzvT3/J1krQ0nbo0eP0q5duzTXe3l5cfGibggjIiL2U9DdhdfaVmT18GZ0qBZgXX44LJqe32zjmW93cPz8VQdGKCLZhcp8iYiIiNxF3CU4/2dyu2AF8Czv2HjyoAwlbQsXLnzHGQkHDx7E398/w0GJiIhkVAkvD6b0rM2C5xpSvXgh6/I/DkXQZuIG3ll8kMjrqncrklepzJeIiIhIOpxbAUZScruYSiM4QoaStu3bt+frr7/mypUrt607cOAA06ZN45FHHrnf2ERERDKsXmkvfn3+ISY8XgM/z+R6t4kWgxl/nqDZJ2v5dnMICUkWB0cpIvamMl8iIiIi6WBTGkFJW0fIUNL2vffeIykpiapVqzJ69GhMJhPffvstvXr1om7duvj6+vLWW29ldqwiIiL3xGw20a1Ocda+0pwXW5bH3SX5Ze/K9QTG/HaAdp9tZO2RiEw9ZmJiIosXL2blypUkJiZm6r5F5P6pzJeIiIjIXVgSIfT35LZLIfBp7Nh48qgMJW0DAwPZuXMnbdu2Zf78+RiGwffff8/ixYvp3r07W7duxdvbO7NjFRERyRAPV2eGt67Ampeb06VmoHX50Yir9J+5g74ztvNveHSmHGvLli106dKFvn37snXr1kzZp4hkHpX5EhEREbmLC5sh4UpyO6AtmF0cGk5elaGkLYCvry/ffPMNly5dIjw8nHPnznH58mVmzJiBr69vZsYoIiKSKQIL52PSU7VY+HwjapUsbF2+/p/ztP1sI28t+ptL1+Lv6xiLF9+8jGjJkiX3tS8RyXwq8yUiIiJyF2dTvI9RaQSHyXDSNiUfHx/8/PwwmzNldyIiIlmqVski/DKoEZO71yKwkDsASRaD77acpPn4tXyz8TjxiRmrd6ukrUj2pjJfIiIi/9/efYdHUXVxHP/uppJACCUkhBo6SK8CUlQEAUEE6QoiglJERfQFUeyiqCiCgg2xIFU6giJSpUnvSO9JaKmQuvP+sWRJSAIhZHdTfp/nCZlyZ+bsTeHuyZ0zIreRVM/WZIbA9MtKiX25Zuagd95555b7TSYTnp6elCxZkubNm1OiRIlMBSciImIvJpOJjrUCaV3Nn2/XHmPymqNcjUskIiaB95YeYPrmU7zWriqtqhbDZDJl6JxHjhzh4MGDuF7/3/XAgQMcPXqU8uXL2/GViMidSCrz9dprr6Uo81WgQAF69uzJhx9+qDJfIiIikndFHoGIg9blok3Ao4hz48nDMpW0feutt2xvYA3DSLHv5u0uLi4MGDCASZMmaSauiIhkO55uLjz/YEW6NSjFJ38cYu72MxgGHL8YzYCfttKkfBHeeKQaVYv73PZcSbNsm9cHw4BVm63bXnzxRTu/ChG5E0llvr777jsuXLiAxWLBz89PY1URERGRs0tvLKs0glNlamR65swZatasSd++fdm2bRvh4eGEh4ezdetW+vTpQ+3atfnvv//Yvn07vXv35uuvv+aDDz7I6thFRESyjL+PJx93rcWiIffRsGxh2/YNRy/R/ot1jJq3mwuRsbc8R1I5hA4trR/Jt4lI9qQyXyIiIiLJnL1R7o1AJW2dKVMzbQcPHkyVKlWYOnVqiu1169blhx9+oEePHowcOZK5c+cybdo0QkND+emnn3j99dezJGgRERF7qVGyILOevZfle4P5YNkBTl++hsWAGVtOs3jXeYbcX4F+Tcvi6eaS4rjw8HDWrl0LQIf7rTNth38Ea9asITw8nIIFCzrj5YjITVTmS0RERCQd8REQusa67B0EBas5N548LlNJ27///ptx48alu79FixaMHDnStt6uXTtGjBiRmUuJiIg4nMlkom2N4txfpRjTNpxg0t9HiIpNICo2gY+WH+TXLScZ1bYqbasH2MoCLV++nISEBKqWh/KlreepUg4OHkvgjz/+oFu3bk58RSKSRGW+RERERNJx/k8wEqzLJR6BDD7bQ+wjU6NPDw8PNm/enO7+TZs24e7ubltPSEggf/78mbmUiIiI03i6ufBs83IsGdSALjWLQnwMlrgYTgZf4bkfNtDli1Vs/u8c0dHRLFy4ELhRFiH58m/z5hMdHX3bj5sTSCKS9VTmS0RERCQdZ5OVdlM9W6fL1Ezbnj178uWXX1KkSBEGDRpEUFAQAMePH+err77il19+YciQIbb2q1atolo1TakWEZGcZ/fu3dSuXTvNfaeB+S+m3Nbh/pTLH0+F2bNmMnvWzNtea9euXdSsWTPTsYrI7anMl4iIiEgaLIlw7vpDyFzzQ7EWzo1HMjfTdty4cTz++OOMHz+eSpUq4eHhgYeHB5UqVeKzzz6jc+fOtvIJMTEx1KtXjzFjxmRp4CIiIo6QNIM2I7q0hntr3VhvXNu6LaMWLFiQ8cYikil///03LVqk/yakRYsWrFixwrberl07Tp065YjQRERERJzn0haIvWhdLt4aXDycG49kbqatp6cns2bNYuTIkSxfvpyTJ08CUKZMGdq0aUPdunVTtFXCVkREcqphw4axa9cu5s2bB8DDzeC7d8G3QOq2XvlSln1ydYU5n8PVa6nbhkXCM2/A8nXW9S5dujBs2LCsfwEikkJSma/nnnsuzf0q8yUiIiJ50rlkpRECVRohO8hU0jZJnTp1qFOnTlbFIiIiku34+voyd+5cJk2axMsvv8zydfE0ewJmfwb1q9/+eJMJvL1Sbvt3D3QfDsfPgJubG+PHj2fIkCG2hyCJiP2ozJeIiIhIGs4uvr5ggsB2Tg1FrO4qaSsiIpIXmEwmnn/+ee699166d+/O8ePHadILPn0VhvbO+ENVDQMm/gIjPob4eAgKCmL27NnUr1/fvi9ARGzGjRtHSEgI48eP57PPPsNstlYLs1gsGIZBly5dUpX5atKkiTNDFhEREbGv6JMQtse6XKQh5PN3bjwC3EXSdtmyZYwfP57t27cTHh6e5hOvExMT7yo4ERGR7KRBgwZs376d/v37M2/ePIa9D6u3wPfvga/PrY8Ni4CnR8P8v6zrnTt35vvvv8fX19fucYvIDSrzJSIiInKTs0tvLJdQaYTsIlNJ299++41u3bpxzz330KNHDyZPnkyvXr0wDIOFCxdSsWJFOnXqlMWhioiION/N5RLmrYjnagws++bWx/V4Gf5YD2YXVyZ8/pnKIYg4mcp8iYiIiFx3Nlk9WyVtsw1zZg4aO3YsDRs2ZMeOHbz99tsAPP3000yfPp29e/dy/vx5W30wERGR3CapXMJXX30FwK6Dtz9m9yHr5+ZPj2TwYCVsRUREREQkG0iIhpC/rcteJcG3lnPjEZtMJW33799Pjx49cHFxwdXVOlk3Pj4egLJlyzJ48GA++uijrItSREQkG9qyZQsAHe6/fdtHWlo/b92ylT5TtxAaGWO/wETklpYtW8ZDDz1EkSJFcHV1xcXFJdWHiIiISJ4Q/BdYYq3LgY9k/IEdYneZStp6eXnh7u4OWG8T9fDw4Pz587b9/v7+HD9+PGsiFBERyYYSEhKYN28eAF3b3Nj+7x64t7v1Y+veG9u7PWz9fPW/Daz7L4R2E9ax5r8LDoxYRMBa5uuRRx4hJCSEHj16YLFY6NmzJz169CBfvnzUrFlTdWxFREQk71BphGwrU0nbypUrs3//ftt67dq1+fnnn0lISCAmJoZff/2V0qVLZ1mQIiIi2c2qVau4dOkSRQtBy4ZgGPDFz9C0F2zebf1o0hMm/mLd17IhFC0ElmsRxJzaw8WoOPpO3cLYZQeIT7Q4++WI5Bkq8yUiIiJynWG5kbR1yQf+Dzg3HkkhU0nbxx57jIULFxIba50+PXr0aFavXo2vry9+fn6sW7eOkSNHZmmgIiIi2cmcOXMA6PwQRF2FLsPghQ8gPgHK1r+fwFrNiU+AYe/D4y9Y2zzWynqsb/BW23m+XnOMrlM2cvryVWe8DJE8R2W+RERERK67vB1igq3LAa3ANZ9z45EUMpW0HTFiBKdOncLDwwOARx55hNWrVzNgwACeffZZVq5cyVNPPZWVcYqIiGQbyUsjBJWEOp1h/l/g5ubGxIkTObJpBVuXzWTChAm4ubkxbwXU7WJtC3B533pGtamIm4u1XtTO02G0m7COJbvPOeslieQZKvMlIiIicp1KI2Rrd5y0jY2NZdGiRezevTvF9mbNmvHZZ5/xySefcP/9GXgii4iISA6VVBoBYPTncOIsBAUFsWHDBoYOHYrJZMJkMjF06FA2bNhAUFAQx8/A6xOsx1+8eJHyiaeY+1wTShf2AiAyNoGhv+5g1LzdXItLdNIrE8n9VOZLRERE5LpzyZK2ge2dF4ek6Y6Ttu7u7nTt2pUNGzbYIx4REZFsL6k0AoDFAl26dGH79u3Ur18/Vdv69euzfft2OnfujMWS8hy1SvmydNh9dKwVaNs+Y8tpOk5az6HgSLu+BpG8SmW+RERERICr5+DyNutyoTrgVcK58Ugqd5y0NZlMVKxYkYsXL9ojHhERkWxv3bp1wI1yCHPmzMHX1zfd9r6+vsydO5cvvvgCNzc3ANauXQtAAU83JvSozbjHa5LPzQWAw6FRdJy0numbT2IYhn1fjEgeozJfIiIiIsC5pTeWS3RwXhySrkzVtH3ttdeYNGkShw4dyup4REREsr2//vqL3r17pyiHcDsmk4nnn3+eDRs20Lt3b1auXJliX7f6pVj8fFOqBBQAIDbBwuj5exny63bCr8Xb7bWI5CUq8yUiIiJynerZZnuumTlo06ZNFClShOrVq9OyZUvKli1LvnwpnzBnMpmYMGFClgQpIiKSnZQoUYJffvklU8fWr18/3WMrFCvAgiFN+eD3A/y08SQAv+8JZtfpcCb2qkPd0oUyHbOI3CjzNWHCBGrWrOnscEREREScI+EaBK+wLnsGQOF6zo1H0pSppO2kSZNsy8lnCiWnpK2IiMid83Rz4Z1Hq9OkfFH+99tuwq/FczbsGl2nbOTl1pV4rnl5zObbz+wVkdRU5ktEREQECFkFidesyyXagylTN+KLnWXqq2KxWG77kZioJ1+LiIhk1sPVA/j9hWbUL2OdXZtoMRi3/BB9pm4hNDLGydGJ5Fwq8yUiIiJ53rlkpRECVRohu8rUTFsRERGxvxK++Zg58F4mrDzMpFVHMAxYf+Qi7Sas49NutWlRyc/ZIYrkOCrzJSIiInmaYdyoZ2t2h4BWzo1H0nVXSdtNmzaxatUqQkNDGTx4MBUrVuTq1ascPHiQSpUqkT9//qyKU0REJE9ydTHzcuvKNC5XhBdn7SQ0MpaLUXH0nbqFZ1uUY0Tryri56HYmkYxSmS8RERHJ08J2w9XT1mX/+8FNubvsKlPv8uLi4ujcuTNNmzZl9OjRfPHFF5w+bf2Cm81mWrdurYGuiIhIFmpSoSjLXmhGy8o3Ztd+veYYXads5PTlq06MTCRnUZkvERERydPOJiuNUKKD8+KQ28pU0vaNN95gyZIlTJ48mUOHDmEYhm2fp6cnXbt2ZeHChVkWpIiIiECR/B5M7duA19tXxc3F+jCynafDaDdhHUt2n3NydCIiIiIiku0lT9oGtndeHHJbmUrazpgxg0GDBjFw4EAKFy6can/VqlU5duzYXQcnIiIiKZnNJp5pVo65zzWhdGEvACJjExj66w5GzdvNtTjNEBTJiE2bNjF27FheeuklDh8+DMDVq1fZvn07UVFRTo5ORERExA5iQuHSZutyweqQv6xTw5Fby1TSNjQ0lBo1aqS738XFhatXdaumiIiIvdQq5cvSYffRsVagbduMLafpOGk9h4IjnRiZSPamMl8iIiKSZ537Hbh+t7xKI2R7mUralipVioMHD6a7/59//qFChQqZDkpERERur4CnGxN61Gbc4zXJ5+YCwOHQKDpOWs/0zSdTlC8SESuV+RIREZE8K0U920ecF4dkSKaStr169eLrr79m48aNtm0mk7W23rfffsvs2bPp06dP1kQoIiIi6TKZTHSrX4rFzzelSkABAGITLIyev5chv24n/Fq8kyMUyV5U5ktERETypMQ4OP+HddmjCBRp5Nx45LZcM3PQ6NGj2bRpE82bN6dq1aqYTCZeeuklLl++zJkzZ2jXrh0vvfRSVscqIiIi6ahQrAALhjTl/aUH+HnTSQB+3xPMrtPhTOxVh7qlCzk5QpHsQWW+REREJE8KXQMJ1+v2F28HZhfnxiO3lamZtu7u7ixfvpwffviBcuXKUaVKFWJjY6lZsybTpk1j8eLFuLjoiy8iIuJInm4uvNupOlOeqIePp/XvsmfDrtF1ykYmrz6KxaJyCSL2KvO1du1aOnToQGBgICaTiQULFqTYbxgGY8aMoXjx4uTLl49WrVrZHoCW5PLly/Tu3RsfHx98fX3p379/qoei7d69m2bNmuHp6UmpUqUYN27cHccqIiIieVDy0gglVc82J8hU0hast2M+8cQTLFiwgH379nHgwAGWLFlCnz59bKUSRERExPEerh7A7y80o14Z6+zaRIvBR8sP0veHLYRGxjg5OhHnsleZr+joaGrVqsWXX36Z5v5x48bxxRdfMGXKFDZv3oy3tzdt2rQhJubGz2Tv3r3Zt28fK1asYMmSJaxdu5aBAwfa9kdERNC6dWvKlCnDtm3b+Pjjj3nrrbf45ptv7jheERERyUMMA84uti6bXCGgtXPjkQzJVHmEV199lZ49e1KnTp2sjkdERESyQMlCXswaeC+f/3WYL1cfwTBg3eGLtJuwjvHdatO8kp+zQxRxCnuV+Wrbti1t27ZNc59hGHz++ee8/vrrPProowD89NNP+Pv7s2DBAnr06MGBAwdYvnw5//77L/Xr1wdg4sSJtGvXjk8++YTAwECmT59OXFwcU6dOxd3dnXvuuYedO3cyfvz4FMldERERkRQiDkD0cetysebgXtC58UiGZGqm7cSJE6lfvz4VK1bkjTfeYM+ePVkdl4iIiNwlVxczI9pUZnr/RhQr4AHAxag4+kzdwofLDhKfaHFyhCKO54wyX8ePHyc4OJhWrVrZthUsWJBGjRrZZvxu3LgRX19fW8IWoFWrVpjNZjZv3mxr07x5c9zd3W1t2rRpw6FDh7hy5UqWxiwiIiK5SPLSCCVUGiGnyNRM29DQUObPn8+sWbMYN24cH3zwAVWqVKFHjx5069aNypUrZ3WcIiIikklNKhRl2QvNeHnOLlYfugDAlDVH2XTsEhN71qFUYS8nRyjiWEllvp544gmHXC84OBgAf3//FNv9/f1t+4KDgylWrFiK/a6urhQuXDhFm6CgoFTnSNpXqFDaDxyMjY0lNjbWth4REQGAxWLBYrH/H28sFguGYTjkWqL+dgb1uWOpvx1Pfe54Wd3nprNLSCpkaineDvS1TMHR3+MZvU6mkrYFChSgT58+9OnTh7CwMH777Tdmz57Nu+++y1tvvUWNGjXo0aMHI0eOzMzpRUREJIsVye/B1L4NmPrPcT5afpD4RIOdp8NoN2EdH3apSfuaxZ0doohD5MUyX2PHjuXtt99Otf3ChQspaurai8ViITw8HMMwMJsz/UgNySD1t+Opzx1L/e146nPHy8o+N8VfodiFfwBI8CrPxWs+cC00K8LMNRz9PR4ZGZmhdplK2iaX9GTb/v37c+nSJX7++WfefPNNRo8eraStiIhINmI2m3imWTkalC3M8zN2cOryVSJjExjy63bWHynNmEeqkc89a28LF8luJk6cyKeffkq5cuVsd4nVqFHDrtcMCAgAICQkhOLFb/yBJCQkhNq1a9vahIamfAOVkJDA5cuXbccHBAQQEhKSok3SelKbtIwaNYrhw4fb1iMiIihVqhR+fn74+Phk/oVlkMViwWQy4efnpzf7DqD+djz1uWOpvx1Pfe54WdrnJ1Zgwjqz06XUo6nu7BHHf497enpmqN1dJ20B4uPjWbZsGbNmzWLx4sVERUVRqlSprDi1iIiIZLFapXxZOuw+Rs/fy6Jd5wCYseUU205eZlKvulTyL+DkCEXsxxllvoKCgggICGDlypW2JG1ERASbN29m0KBBADRu3JiwsDC2bdtGvXr1APj777+xWCw0atTI1mb06NHEx8fj5uYGwIoVK6hcuXK6pREAPDw88PDwSLXdbDY77M23yWRy6PXyOvW346nPHUv97Xjqc8fLsj4///uNc5bsiElfwzQ58ns8o9fIdCQJCQn8/vvv9O3bFz8/Pzp16sTq1avp168f69ev5+TJk5k9tYiIiNhZAU83JvSozbjHa5LPzTq79r+QKDpMXM/0zScxDMPJEYrYR1KZr6VLlxISEsI333xDyZIleffdd6lWrRq1a9fmww8/vOPzRkVFsXPnTnbu3AlYHz62c+dOTp06hclk4sUXX+S9995j0aJF7Nmzhz59+hAYGEinTp0AqFq1Kg8//DADBgxgy5Yt/PPPPwwdOpQePXoQGBgIQK9evXB3d6d///7s27ePWbNmMWHChBSzaEVERERsLPFwbrl12c0X/Jo4NRy5M5lK2vbv3x9/f38eeeQRli1bRs+ePVm1ahVnzpxhwoQJNGmibwIREZHszmQy0a1+KRY/35QqAdbZtbEJFkbP38uQX7cTfi3eyRGK2FdSma8//viD8+fP8+mnn3L8+HFGjx59x+faunUrderUsdXKHT58OHXq1GHMmDGAtZbu888/z8CBA2nQoAFRUVEsX748xe1x06dPp0qVKjz44IO0a9eO++67j2+++ca2v2DBgvz5558cP36cevXq8fLLLzNmzBgGDhx4lz0hIiIiudKFfyA+zLoc+DCY3ZwajtyZTJVHWLBgAY899hjdu3fngQcewMUldf27K1eu3PI2LREREckeKhQrwIIhTXl/6QF+3mS9U+b3PcHsOh3OxF51qFta/59L7pVVZb5atmx5yxnqJpOJd955h3feeSfdNoULF+bXX3+95XVq1qzJunXr7jg+ERERyYPOLrmxXKKD8+KQTMlU0jYkJARX19SHxsbGsmjRIqZPn87y5csd8jRaERERuXuebi6826k6TSsU5dW5u4iISeBs2DW6TtnIiNaVebZ5Ocxmk7PDFMkSCQkJ/Pnnn8yaNYuFCxcSERFB8eLF6devH927d9ddYyIiIpI7nLuetDWZofjDzo1F7limkrbJE7aGYbBy5UqmT5/O/PnziYiIwM/Pj169emVZkCIiIuIYD1cPoHoJH16YuZNtJ6+QaDH4aPlBNhy9yKfdalGsQMaedCqSXfXv358FCxZw5coVihYtSs+ePenRowfNmzfHZNIfJkRERCSXiDgMEYesy0Wbgkdh58YjdyxTSVuAbdu2MX36dGbOnElwcDAmk4kePXowdOhQ7r33Xg16RUREcqiShbyYNfBePv/rMF+uPoJhwLrDF2k3YR3ju9WmeSU/Z4cokmkq8yUiIiJ5wrnkpREecV4ckml3lLQ9duwY06dPZ/r06Rw+fJgSJUrQu3dvGjZsSPfu3enSpQuNGze2V6wiIiLiIK4uZka0qUyT8kV4YdZOLkTGcjEqjj5Tt/Bci/K83LoSbi6Zep6piFOpzJeIiIjkCapnm+NlOGnbuHFjtmzZQtGiRXn88cf57rvvuO+++wA4evSo3QIUERER52lSoSjLXmjGiDm7WH3oAgBT1hxl07FLTOxZh1KFvZwcocidUZkvERERyfXiwiF0rXU5fznwqeLceCRTMpy03bx5M0FBQYwfP5727dunOUNBREREcp+i+T2Y2rcB368/zkfLD5JgMdh5Oox2E9bxYZeatK9Z3NkhitwRlfkSERGRXO38H2AkWJcDHwGNbXKkDN/XOGnSJIoXL85jjz1GQEAAzz77LKtWrcIwDHvGJyIiItmA2WxiQPNy/DaoCaWvz66NjE1gyK/bGTVvD9fiEp0cocitHTt2jHfffZcqVarQsGFD5s6dS+/evZk1axaGYdjKfClhKyIiIjle8tIIJVUaIafKcNJ28ODBrF+/nqNHj/Liiy+ybt06HnzwQUqUKMGYMWMwmUwa5IqIiORytUr5snTYfXSoFWjbNmPLKR79cj3/hUQ6MTKR9DVu3JiKFSsyadIkHnzwQdasWcOpU6f4+OOPqVu3rrPDExEREck6lkQ4/7t12TU/+DV3bjySaXf8BJGgoCBef/119u/fz7///kuPHj1YvXo1hmEwePBgBg4cyJIlS/TwBhERkVyqgKcbX/SozbguNcnn5gLAfyFRdJi4nl83n9JdOJLtbN68mbJly/LNN98wYcIE23MZRERERHKdS5sh9pJ1uXgbcHF3bjySaXf12Od69eoxfvx4Tp8+zZ9//kmbNm2YNWsWHTt2pGjRolkVo4iIiGQzJpOJbg1Ksfj5plQJKABAbIKF1+bvYeivOwi/Fu/kCEVuUJkvERERyTPOLr6xXOIR58Uhd+2ukra2k5jNtGrVimnTphESEsKMGTN48MEHs+LUIiIiko1VKFaABUOa8uS9ZWzblu45T/sv1rH91BUnRiZyg8p8iYiISJ5hq2drgsB2Tg1F7k6WJG2T8/T0pHv37ixcuDCrTy0iIiLZkKebC+92qs6UJ+rh4+kKwJkr1+g2ZSOTVx/FYtFsRskeVOZLREREcrWoExC+17pcpBF4FnNqOHJ3sjxpKyIiInnTw9UD+P2FZtQrUwiABIvBR8sP0veHLVyIjHVydCIpqcyXiIiI5Dq2WbaoNEIuoKStiIiIZJmShbyYNfBeht5fgaS7zdcdvkjbCetYd/iCc4MTSYPKfImIiEiucS550raD8+KQLKGkrYiIiGQpVxczI9pUZnr/RvgV8ADgYlQsT36/hQ+XHSQ+0eLkCEXSpjJfIiIikmPFR0HIKuuyVynwreHceOSuKWkrIiIidtGkQlGWvdCMlpX9bNumrDlKt683cvryVSdGJiIiIiKSywT/BZY463KJR0APWc3xlLQVERERuyma34OpfRswul1VXM3WgeOOU2G0+2IdS3efd3J0IiIiIiK5xNnFN5YDVc82N1DSVkREROzKbDYxoHk5fhvUhNKFvQCIjElgyK/bGTVvD9fiEp0coYiIiIhIDmZY4NxS67KLFwQ84Nx4JEsoaSsiIiIOUauUL0uH3UeHWoG2bTO2nOLRL9fzX0ikEyMTEREREcnBLm+DmBDrckArcPF0bjySJbJl0vbLL7+kbNmyeHp60qhRI7Zs2ZKh42bOnInJZKJTp04pthuGwZgxYyhevDj58uWjVatWHD582A6Ri4iIyK0U8HTjix61GdelJp5u1mHIfyFRdJi4nl83n8IwDCdHKCIiIiKSwyQvjVBCpRFyi2yXtJ01axbDhw/nzTffZPv27dSqVYs2bdoQGhp6y+NOnDjBiBEjaNasWap948aN44svvmDKlCls3rwZb29v2rRpQ0xMjL1ehoiIiKTDZDLRrUEpljx/H1UCCgAQm2Dhtfl7GPrrDsKvxTs5QhERERGRHOTskhvLge2dF4dkqWyXtB0/fjwDBgygX79+VKtWjSlTpuDl5cXUqVPTPSYxMZHevXvz9ttvU65cuRT7DMPg888/5/XXX+fRRx+lZs2a/PTTT5w7d44FCxbY+dWIiIhIeioUK8CCIU158t4ytm1L95yn/Rfr2H7qihMjExERERHJIa6ehSs7rMuF64FX4K3bS47h6uwAkouLi2Pbtm2MGjXKts1sNtOqVSs2btyY7nHvvPMOxYoVo3///qxbty7FvuPHjxMcHEyrVq1s2woWLEijRo3YuHEjPXr0SHW+2NhYYmNjbesREREAWCwWLBZLpl9fRlksFgzDcMi1RP3tDOpzx1OfO5b6O+PcXUy83bEajcsVZuS8PUTEJHDmyjW6TdnI8IcqMrBZOcxm023Poz53PEf2ub6uIiIiIulIegAZQKBKI+Qm2Sppe/HiRRITE/H390+x3d/fn4MHD6Z5zPr16/n+++/ZuXNnmvuDg4Nt57j5nEn7bjZ27FjefvvtVNsvXLjgkJIKFouF8PBwDMPAbM52k6FzHfW346nPHU997ljq7ztXt5iZH3tVYcyy4+w5H02CxWDcH/+x+sB53mwTRBFvt1serz53PEf2eWSkHlQnIiIikqYzqmebW2WrpO2dioyM5Mknn+Tbb7+laNGiWXbeUaNGMXz4cNt6REQEpUqVws/PDx8fnyy7TnosFgsmkwk/Pz+98XQA9bfjqc8dT33uWOrvzClWDH4bXIIJK4/w1ZqjGAZsORVJ3xkH+bRrLZpVTP//evW54zmyzz099QRkERERkVQSrkLIX9blfMWhcF3nxiNZKlslbYsWLYqLiwshISEptoeEhBAQEJCq/dGjRzlx4gQdOnSwbUu6fc7V1ZVDhw7ZjgsJCaF48eIpzlm7du004/Dw8MDDwyPVdrPZ7LA3giaTyaHXy+vU346nPnc89bljqb8zx91s5pWHq9C0QlFemLWTC5GxXIyKo+8P//Jci/K83LoSbi5p96n63PEc1ef6moqIiIikIWQVJF6/IzywPZg0ZspNstVX093dnXr16rFy5UrbNovFwsqVK2ncuHGq9lWqVGHPnj3s3LnT9tGxY0fuv/9+du7cSalSpQgKCiIgICDFOSMiIti8eXOa5xQRERHna1KhKMteaEbLyn62bVPWHKXb1xs5ffmqEyMTEREREckmzqo0Qm6WrWbaAgwfPpy+fftSv359GjZsyOeff050dDT9+vUDoE+fPpQoUYKxY8fi6elJ9erVUxzv6+sLkGL7iy++yHvvvUfFihUJCgrijTfeIDAwkE6dOjnqZYmIiMgdKprfg6l9G/D9+uN8tPwgCRaDHafCaPfFOj7sXJP2NYsTE5/I73vO88e+YC6ERePne4Y29wTQrkZxPN1cnP0SRERERETswzDg7BLrstkDAlo5Nx7Jctkuadu9e3cuXLjAmDFjCA4Opnbt2ixfvtz2ILFTp07d8S1yr776KtHR0QwcOJCwsDDuu+8+li9frvpoIiIi2ZzZbGJA83I0DCrM8zN2cOryVSJjEhjy63ZmbS3KzlNhRMQkYDaBxQDzuSj+2BfCW4v3Mb5rbVpV87/9RUREREREcpqwXXDtrHXZ/wFw9XZuPJLlsl3SFmDo0KEMHTo0zX2rV6++5bHTpk1Ltc1kMvHOO+/wzjvvZEF0IiIi4mi1SvmydNh9vDZ/L4t3nQNg7X8XbfstRsrPkdcSGPDzVr55sj4PKXErIiIiIrlN0ixbUGmEXCpb1bQVERERSU8BTze+6FGb9ztVv21b4/o/I+bsJCY+0e6xiYiIiIg4VIp6tu2dF4fYjZK2IiIikmOYTCbyuWesVq0BhF9LYNne8/YNSkRERETEka6FwKUt1mXfmuBdxrnxiF0oaSsiIiI5yp/7QjCbMtbWbII/9obYNyAREREREUc69/uNZZVGyLWUtBUREZEcJexqnK127e1YDAi7FmffgEREREREHCl5aYRAJW1zKyVtRUREJEfx9XK/o5m2vvnc7RuQiIiIiIijJMZC8J/WZQ8/KNLQufGI3ShpKyIiIjlK63v872imbZvq/vYNSERERETEUULXQEK0dTmwHZgz9rwHyXmUtBUREZEcpV2N4vjkcyWDk23xctNAVkRERERyibNLbiyrnm2upqStiIiI5Ciebi6M71obTGQocTv41x3M3XbG3mGJiIiIiNiXYdyoZ2t2g+KtnRuP2JWStiIiIpLjtKrmzzdP1scnnyuArcZt0mcfT1fqly0EQKLFYMScXUxZcxTDyGBdBRERERGR7CZ8P0SfsC4XawFuPk4NR+zL1dkBiIiIiGTGQ9X82fxaK5btPc/yvcFcCI/Gr6A3D1cPoG314ri7mHlnyX6mbTgBwIfLDnIhMpbR7apizuiTzEREREREsotzyUojBKo0Qm6npK2IiIjkWJ5uLjxWpySP1gokNDSUYsWKYTbfuJHozQ7V8Cvgwcd/HALg+/XHuRgVy8eP18LdVTcciYiIiEgOklQaAVTPNg/QuxURERHJtUwmE0Pur8BHXWrYSics3HmO/j/+S3RsgnODExERERHJqJiLcHGjddmnKhQo79x4xO6UtBUREZFcr3uD0nz9ZH08rs+uXXf4Ir2+3cSlqFgnRyYiIiIikgHnl4NhsS5rlm2eoKStiIiI5AkPVfPnl2ca4eNprQ6160w4j0/ZyOnLV50cmYiIiIjIbZxNVs9WSds8QUlbERERyTMalC3MnOea4O/jAcDxi9F0mbyBA+cjnByZiIiIiEg6LPHWmbYA7oWgaBPnxiMOoaStiIiI5CmVAwrw26AmlPPzBiA0MpZuX29k07FLTo5MRERERCQNF9ZDfLh1uXhbMLs6Nx5xCCVtRUREJM8pWciLuc81oXYpXwAiYxLoM3ULy/cGOzcwEREREZGbqTRCnqSkrYiIiORJhb3d+XVAI1pW9gMgLsHC4OnbmL75pJMjExERERFJ5uxi62eTCwQ+7NxYxGGUtBUREZE8y8vdlW/71KdznRIAWAwYPX8vE/46jGEYTo5ORERERPK8iP8g8rB12e8+a01byROUtBUREZE8zc3FzCdda/Fs83K2bZ/99R9jFu4j0aLErYiIiIg4kUoj5FlK2oqIiEieZzabGNWuKqPbVbVt+3nTSZ6fsZ2Y+EQnRiYiIiIiedq5ZEnbQCVt8xIlbUVERESuG9C8HJ91r4Wr2QTA73uCeeqHLUTExDs5MskN3nrrLUwmU4qPKlWq2PbHxMQwZMgQihQpQv78+enSpQshISEpznHq1Cnat2+Pl5cXxYoV45VXXiEhIcHRL0VEREQcIS4MQtdZl/OXB5/KTg1HHEtJWxEREZFkHqtTku/61iefmwsAm45dpsfXmwiNjHFyZJIb3HPPPZw/f972sX79etu+l156icWLFzNnzhzWrFnDuXPn6Ny5s21/YmIi7du3Jy4ujg0bNvDjjz8ybdo0xowZ44yXIiIiIvYW/AcY1/84W6IDmEzOjUccSklbERERkZu0rFyMXwc0opCXGwD7z0fQZfIGTlyMdnJkktO5uroSEBBg+yhatCgA4eHhfP/994wfP54HHniAevXq8cMPP7BhwwY2bdoEwJ9//sn+/fv55ZdfqF27Nm3btuXdd9/lyy+/JC4uzpkvS0REROzAdHbpjRXVs81zXJ0dgIiIiEh2VKd0IeYOakKf77dwNuwapy9fo8vkDUzr15AaJQs6OzzJoQ4fPkxgYCCenp40btyYsWPHUrp0abZt20Z8fDytWrWyta1SpQqlS5dm48aN3HvvvWzcuJEaNWrg7+9va9OmTRsGDRrEvn37qFOnTprXjI2NJTY21rYeEREBgMViwWKx2OmV3mCxWDAMwyHXEvW3M6jPHUv97Xjqc8ezWCwYifFwfhkAhpsPRpGmoK+BXTj6ezyj11HSVkRERCQd5f3y89ugJvSduoVDIZFcio6jxzcb+frJ+txXsaizw5McplGjRkybNo3KlStz/vx53n77bZo1a8bevXsJDg7G3d0dX1/fFMf4+/sTHBwMQHBwcIqEbdL+pH3pGTt2LG+//Xaq7RcuXCAmxv5lPywWC+Hh4RiGgdmsG/3sTf3teOpzx1J/O5763PEsFgtx59ZgirsMQEyhFoRfCnNuULmYo7/HIyMjM9ROSVsRERGRWwgo6Mns5xoz4MetbDlxmei4RPpN28Kn3WrTsVags8OTHKRt27a25Zo1a9KoUSPKlCnD7NmzyZcvn92uO2rUKIYPH25bj4iIoFSpUvj5+eHj42O36yaxWCyYTCb8/Pz0Zt8B1N+Opz53LPW346nPHc9isRBzbJNt3SOoM8WKFXNiRLmbo7/HPT09M9ROSVsRERGR2yiYz42f+jdk2Iwd/Lk/hPhEg2EzdnApKpZ+TYOcHZ7kUL6+vlSqVIkjR47w0EMPERcXR1hYWIrZtiEhIQQEBAAQEBDAli1bUpwjJCTEti89Hh4eeHh4pNpuNpsd9ubbZDI59Hp5nfrb8dTnjqX+djz1ueN5XPrr+pIJc4n2oL63K0d+j2f0GvqKi4iIiGSAp5sLX/WuS8+GpWzb3l68n3HLD2IYhhMjk5wqKiqKo0ePUrx4cerVq4ebmxsrV6607T906BCnTp2icePGADRu3Jg9e/YQGhpqa7NixQp8fHyoVq2aw+MXERGRLJYYA8d/xrS6HW7Rh6zb8pcHtwLOjUucQjNtRURERDLI1cXMB4/VwC+/B1/8fQSAr1Yf5WJULB88VgNXF/09XNI3YsQIOnToQJkyZTh37hxvvvkmLi4u9OzZk4IFC9K/f3+GDx9O4cKF8fHx4fnnn6dx48bce++9ALRu3Zpq1arx5JNPMm7cOIKDg3n99dcZMmRImjNpRUREJAc5swg2PgXxVwDTje1RR2BeIDT+EUp2cFZ04gRK2oqIiIjcAZPJxPDWlSlawIM3F+3DMGD21jNcjo5jYs+65HN3cXaIkk2dOXOGnj17cunSJfz8/LjvvvvYtGkTfn5+AHz22WeYzWa6dOlCbGwsbdq04auvvrId7+LiwpIlSxg0aBCNGzfG29ubvn378s477zjrJYmIiEhWOLMI1nayrZq46S6u+DBY+yg0XwAlOzoyMnEiJW1FREREMqFP47IU8fbgpVk7iUu08NeBUJ78fjPf9a2Pr5e7s8OTbGjmzJm33O/p6cmXX37Jl19+mW6bMmXK8Pvvv2d1aCIiIuIsiTHWGbYANydrbQzABJuegsfOgUvGHmQlOZvu4RMRERHJpPY1izOtXwPye1j/Dr715BW6fb2R8+HXnByZiIiIiOQIp+ZcL4lwu2ckGBB3BU7NdURUkg0oaSsiIiJyF5pUKMrMgfdSNL+1puh/IVF0+WoDR0IjnRyZiIiIiGR7ZxaQ8fScGc7Mt2Mwkp0oaSsiIiJyl6qXKMhvgxpTpogXAOfCY3h8yka2n7ri5MhEREREJFuLuQhYMtjYArGX7RmNZCNK2oqIiIhkgTJFvJn7XBPuCfQBIOxqPL2+3cSqg6FOjkxEREREsp3Yy7DvA7i0+Q4OMoNHYbuFJNmLkrYiIiIiWcSvgAczB95L0wpFAIiJt/DMT1v5bdsZJ0cmIiIiItlC1DHY+jwsKAW7RoMl9g4OtkDJx+wWmmQvStqKiIiIZKECnm5MfaoB7WsWByDRYvDynF18veYohnG7B0yIiIiISK50cROs6wqLK8J/kyDx6vUdJjC5WT/fkgncC0Hpx+0cqGQXStqKiIiIZDEPVxcm9qhD38ZlbNvGLjvI+0sPYLEocSsiIiKSJ1gS4fR8WHEf/NkYTs8F43r9WhcvqDQUOhyGZr9dPyC9xO317ff+CC6e9o5asglXZwcgIiIikhuZzSbe6ngPxXw8+fiPQwB8t/44F6NiGfd4Ldxd9bdzERERkVwp4SocmwYHP4OoIyn3efpD5WFQ4bkb9WkLlIfmC2DTUxB3BQMzJiy2z7j7WhO2JTs49nWIUylpKyIiImInJpOJIfdXoIi3O6/N34PFgAU7z3H5ajyTe9fF20NDMREREZFc41qItfTBkckQeynlvoL3QJWXoWwvcPFIfWzJjvDYOTg1F07PIzYqGPf8AVCqs7UkgmbY5jl6pyAiIiJiZz0alqZIfg+G/rqd2AQLa/+7QK9vNzH1qQYUyZ/GoF1EREREco7w/XBwPBz/JfWDxfwfhKojoHgbMN2mbq2LJwQ9gVGmF1dCQylWrBgms+7Oyqv0lRcRERFxgIeq+fPLM43w8bT+zXzXmXC6TtnI6ctXb3OkiIiIiGQ7hgEhq2D1I7D0Hjj6/Y2ErckVyj4BbXfAg39B4MO3T9iK3ERJWxEREREHaVC2MHOea4K/j3V27bGL0XSZvIED5yOcHJmIiIiIZIglHk78Csvrw8oH4NzSG/vcfKDqK/DocWjyMxSq7bQwJedT0lZERETEgSoHFOC3QU0o5+cNQGhkLN2+3sjmY5duc6SIiIiIOE18BBz4FBaVhw294cr2G/u8SkPd8dDpNNQZB14lnRen5BpK2oqIiIg4WMlCXsx9rgm1S/kCEBmTwJNTt/DHvmDnBiYiIiIiKUWfhu0jYEEp2DECrp6+sa9wPWgyAzoehSovWWfaimQRJW1FREREnKCwtzu/DmhEy8p+AMQlWBj0yzZ+3XzKyZGJiIiICJe3wz+9YVE5OPipdaZtksBH4MHV0OZfKNsDzK7OilJyMX1XiYiIiDiJl7sr3/apz//m7mbejrNYDHht/h4uRsXy/AMVMOmBFSIiIiKOY1jg3HJrkjbk75T7zB4Q1AeqDIeCVZwTn+QpStqKiIiIOJGbi5lPutaiaAEPvll7DIDxK/7jQmQsb3W8BxezErciIiIidpUYAyemw8HxEL4/5T6PolBxMFQaAp7FnBOf5ElK2oqIiIg4mdls4rV2VfHL78H7vx8A4OdNJ7kUHctn3Wvj4eri5AhFREREcqHYS3B4Mvw3EWJCU+4rUNE6qzaoD7h6OSc+ydOUtBURERHJJgY0L0fRAu68Mmc3CRaD3/cEcyX6X77uUw8fTzdnhyciIiKSO0QegYOfwbEfIPFayn1+zaDqy1CiA5j0KChxHiVtRURERLKRx+qUpJCXO4N+2c61+EQ2HrtEj683Me3pBhQr4Ons8ERERERyrgsb4MAncGYBYNzYbjJDqcehystQtKGzohNJQX8yEBEREclmWlYuxq8DGlHIyzq7dv/5CLpM3sCJi9FOjkxEREQkh7Ekwqnf4I/GsKIpnJmPLWHr6g2VX4AOR+C+WUrYSraipK2IiIhINlSndCHmDmpCCd98AJy+fI0ukzew50y4kyMTERERyQESouHQJFhSCdY/Dpc23diXrzjU/hA6nYZ6n0P+IKeFKZIeJW1FREREsqnyfvn5bVATKvsXAOBSdBw9vtnI+sMXnRyZiIiISDZ17TzsGg0LSsG25yHq2I19vjXg3mnQ8QRU+x+4F3JWlCK3paStiIiISDYWUNCT2c82pmHZwgBExyXSb9oWFu865+TIRERERLKRsH2w6WlYWBb2fQBxV27sC2gN9/8BbXdBub7g4u60MEUySg8iExEREcnmCnq58VP/hjw/Ywcr9ocQn2gwbOYOLkXF8lRT3c4nIiIieZRhQMhKOPApnF+ecp/ZDcr0girDoVBN58QncheUtBURERHJATzdXJjcuy6vL9jLzH9PYxjw1uL9XIiKZUTryphMJmeHKCIiIuIYlng4OQsOfAJhu1Luc/OFis9BpaHgVcIp4YlkBSVtRURERHIIVxczYzvXwK+ABxP/PgLAl6uOciEylg8eq4GriypfiYiISC4WFw5HvoFDE+Da2ZT7vMtClZeg3NPglt8p4YlkJSVtRURERHIQk8nEy60rUzS/B28t3odhwOytZ7gcHcfEnnXJ5+7i7BBFREREslb0STg4AY5+CwlRKfcVbgDVXoGSj4FZaS7JPfTdLCIiIpID9W1SliL53Rk+axdxiRb+OhDKk99v5vu+DSjo5ebs8ERERETu3qWtcPBTODUHjMRkO0xQsiNUeRn87gOViZJcSPfQiYiIiORQj9QMZFq/BuT3sP4dfuvJK3T9egPnw685OTIRERHJDRISEli8eDF//vknCQkJjrmoYYEzi+GvlvBHAzg580bC1sUTKjwHjxyE5gugWDMlbCXXUtJWREREJAdrUqEoMwfeS9H87gD8FxJFl682cCQ00smRiYiISE63ceNGOnXqRN++fdm0aZN9L5YYA0e+haXVYG1HCF1zY5+HH9R4Gx49BQ0ng08l+8Yikg0oaSsiIiKSw1UvUZDfBjWhdGEvAM6Fx/D4lI1sP3XFyZGJiIhITrZ48WLb8pIlS+xzkZiLsOcdWFAatgyEiEM39vlUhobfwKMnocYY8PSzTwwi2ZCStiIiIiK5QJki3vw2qAn3BPoAEHY1nl7fbmLVwVAnRyYiIiI5lV2TthH/wZZBsLAU7HkTYi/c2FesBbRYDO33Q4UB4Jova68tkgMoaSsiIiKSS/gV8GDmwHtpUr4IADHxFp75aSu/bTvj5MhEREQkpzly5AgHDx7E1RVcXeHAgQMcPXr07k5qGBC6DtZ2giVV4MgUa1kEAJMLlOkBbf6FVquhxCNgUtpK8i5994uIiIjkIgU83fihXwPa1ywOQKLF4OU5u/h6zV2+yRIREZE8JWmWbfP60Kxeym13zJIAJ2fDn/fCX83hzELAsO5zzQ+VX4KOR6HpDChS/+6DF8kFlLQVERERyWU8XF2Y2KMOfRuXsW0bu+wg7y3Zj8ViODEyERERySmSyiF0aGn9SL4tw+Kj4NAXsLgi/NMdLm25sS9fCag9DjqdhnrjwbtM+ucRyYNcnR2AiIiIiGQ9s9nEWx3vwa+AB5/8+R8A360/zsWoWMY9Xgt3V/3tXkRERNIWHh7O2rVrAehwv7WqwfCPYM2aNYSHh1OwYMFbn+DqOfhvIhyeAvFhKff51oKqI6B0N3Bxt88LEMkFNFoXERERyaVMJhNDH6jIh51rYDZZty3YeY5nftpKdGyCc4MTERGRbGv58uUkJCRQtTyULw0VykCVcpCQkMAff/yR/oFhe2DjU7CoLOz/MGXCtvjD8MBf0HYHBD2hhK3IbWimrYiIiEgu16NhaQp7u/P8jB3EJlhY+98Fen27ialPNaBIfg9nhyciIiIOYhgGV69evW27hQsXAjfKIiQtHzwGC+b/Rvv27ZOfFEL+hoMTrJ+v8/IAk4s7lO0NVYaDb/UsehUieYOStiIiIiJ5QOt7Avi5fyOe+fFfImIS2HUmnK5TNvLj0w0pVdjL2eGJiIiIA+zevZvatWtnuH2H+1MufzwVZsyczYyZs2977K7Zz1DzkXcgX/FMRCoiStpmEcMwSEhIIDEx8a7PZbFYiI+PJyYmBrNZFSyykouLC66urphMJmeHIiIi4nANgwoz+7nG9J26hZCIWI5djKbL5A38+HRDqhb3cXZ4IiIiYmdJM2gzoktruLfWjfXGta3bfvszY8cvOFCKml2VsBXJLCVts0BcXBznz5/P0C0GGWEYBhaLhcjISCUX7cDLy4vixYvj7q76OSIikvdUCfDht0FN6DN1C8cuRBMaGUu3rzfyfd8GNAwq7OzwRERExI6GDRvGrl27mDdvHgAPN4Pv3gXfAqnbeuWD5CkJV1eY8zlcvZa6bVgkPPMGLF9nXe/SpQvDhg3L+hcgkocoaXuXLBYLx48fx8XFhcDAQNzd3e860Zo0a1czQrOWYRjExcVx4cIFjh8/TsWKFTWTWURE8qSShbyY+1wT+k37l12nw4iMSeCJ7zczsWcd2twT4OzwREREUkuMgVNzMJ2eT6GoYEz5A6DUY1C6K7h4Oju6HMPX15e5c+cyadIkXn75ZZavi6fZEzD7M6ifgZKzJhN431RV6d890H04HD8Dbm5ujB8/niFDhiifIXKXlLS9S3FxcVgsFkqVKoWXV9bUg1PS1n7y5cuHm5sbJ0+eJC4uDk9P/ecuIiJ5U2Fvd2YMaMSgX7az5r8LxCVYGPTLNt5/rAY9G5Z2dngiIiI3nFkEG5+C+CuAGQ8sGGFmODMftr4AjX+Ekh2cHaVjWeIhIQrio6yfE6IgITqNbcm2X99nSoji+SpR3PtxEN3HHuP4mQSa9IRP/wdDe6ecXXsrhgETf4ERH0N8PAQFBTF79mzq169v39cukkcoaZtFNGMz59DXSkRExMrL3ZXv+tbn1bm7mb/jLBYDRs3bw4XIWJ5/oIL+eCwiIs53ZhGs7WRbNWFJ8Zn4MFj7KDRfACU7Ojy82zIsyZKmt0mq3sl2S9xdh9bAD7a/C/2/hXn/wrD3YfUW+P498L1NqfuwCHh6NMz/y7reuXNnvv/+e3x9fe86LhGxynZJ2y+//JKPP/6Y4OBgatWqxcSJE2nYsGGabefNm8cHH3zAkSNHiI+Pp2LFirz88ss8+eSTtjZRUVGMHDmSBQsWcOnSJYKCghg2bBjPPfeco16SiIiISLbl5mLm06618CvgwTdrjwEwfsV/XIyK5c0O9+BiVuJWRCRNul3f/hJjrDNsATDSaWQAJtj0FDx2LvN9bxhgic2ChOpN+xKz5tk3dmF2x7eQN3NHeTNpeTwvTw1l3gqDqzGw7JtbH9rjZfhjPbi5mhj/2RcqhyBiB9kqaTtr1iyGDx/OlClTaNSoEZ9//jlt2rTh0KFDFCtWLFX7woULM3r0aKpUqYK7uztLliyhX79+FCtWjDZt2gAwfPhw/v77b3755RfKli3Ln3/+yeDBgwkMDKRjx2z4V7g8pmzZsrz44ou8+OKLAJhMJubPn0+nTp2cGpeIiEheYjabeK1dVYrmd+eD3w8C8NPGk1yMiuWz7rXxcHVxcoQiItmMbtd3jFNzrvfx7RgQdwV2vQ5FGmR+9qqRaPeXlDkmcM0Pbvmtn129r3/Of9P2W+3zTrnNxRtc3JPOzvOPQb4G3zFgwAB2Hbx9RLsPWT9Pfvdp+g8dar+XLpKHZauk7fjx4xkwYAD9+vUDYMqUKSxdupSpU6cycuTIVO1btmyZYv2FF17gxx9/ZP369bak7YYNG+jbt6+t7cCBA/n666/ZsmVLnk/aPvXUU/z444+29cKFC9OgQQPGjRtHzZo1nRLT+fPnKVSokFOuLSIiktcNbF6eovk9eHXubhIsBr/vCeZK9L9806ceBTzdnB2eiNyKZn06Tk6/Xf9uWRLBEmP9nkuMsc5OTbTTeuThO4vt4Kf2ec13wsUzZdLUljj1Tmd7BhKtLvkyXmj2LmzZsgWADvffvu0jLeHbObDlGPS3b1gieVa2SdrGxcWxbds2Ro0aZdtmNptp1aoVGzduvO3xhmHw999/c+jQIT766CPb9iZNmrBo0SKefvppAgMDWb16Nf/99x+fffaZXV5HTvPwww/zww8/ABAcHMzrr7/OI488wqlTp5wST0CAnlgtIiLiTJ3rlqSQtzuDf9nOtfhENh67RPevNzHt6QYUK6DEj0i2pFmfjuPI2/XT4siEqSUGEmOTLV//yLazUe+QyQVcC9w6oerifdMs1gxsN+fMu1MSEhKYN28eAF3b3Nj+7x54/j3r8qQ3oH5163K3h61J23nzF/LlV1Nwdc026SWRXCPb/FRdvHiRxMRE/P39U2z39/fn4MH05+aHh4dTokQJYmNjcXFx4auvvuKhhx6y7Z84cSIDBw6kZMmSuLq6Yjab+fbbb2nevHm654yNjSU2Nta2HhERAYDFYsFisaRoa7FYMAzD9pFVks6VledMi4eHh63P/f39+d///kfz5s0JDQ3Fz8+P//3vfyxYsIAzZ84QEBBAr169GDNmDG5u1tk2u3bt4qWXXmLr1q2YTCYqVqzIlClTbE+LXL9+Pa+99hpbt26laNGidOrUibFjx+Lt7Z3itSa9TrPZzLx58+jUqRMnTpygXLlyzJ07l0mTJrF582YqVqzI5MmTady4se34jFwjuaTrJX09k76GN39txX7U546nPncs9bfjqc+zVouKRZn+TEP6/7iVK1fj2X8+gscnb2BavwYU9/Hk973B/LkvmNDwqxQreJrW9wTQrnoAHm72eaOqr2sOpZmfjpHXZ33ag2FYE5NGAlgSwIi//jkBTs66s9v1twyCQrVunxRNN0kamzsTphlhcgWMO3jNJvCpCuX7p06oJs1aTb7d7O6Q2as5xapVq7h06RJFC0HLhtYfg4m/wIhxEJ9gbdOkJ3z6Pxja29qmaCFrLmf16tW0atXKuS9AJBfKNknbzCpQoAA7d+4kKiqKlStXMnz4cMqVK2crhzBx4kQ2bdrEokWLKFOmDGvXrmXIkCEEBgam+0tl7NixvP3226m2X7hwgZiYmBTb4uPjsVgsJCQkkJCQkPKAuFs8zdFshuR/iUrW1jAMEhMTIS7OWsjbZAI3tzTb2ri7p3+tdCQlLJPijoqK4ueff6ZChQoULFiQhIQEvL29+e677yhevDh79+5l0KBBeHt7M2LECAB69+5N7dq12bBhAy4uLuzatQuTyURCQgJHjx6lbdu2vP3223z99ddcvHiRF154gSFDhvDdd9+liCN53yUmJqboz9GjR/PRRx9RoUIFxowZQ69evThw4ACurq4ZvkZyCQkJWCwWLl26hJubGxaLhfDwcAzDwGw233E/yp1Tnzue+tyx1N+Opz7PeoEeMPnxSrw4/zDBkXGcunyNDhPXYxhwNd6C2QQWA8znovhjfyhvLdrHmDZlaVbON8tjiYyMzPJzip1p5qdjOGrW562SmJb4ZNvvcD1pOUvWk8V0t3EYCbfvk4w6Pg2OZ93pHMbkav1ecfEEs8eN5dutmz3BJZ11c9IxGVg3e4DZFY7/DBv7ZDBoA+4ZBUFP2LVrcqs5c+YA0PkhiLoKT4+G+X9Z93VuHoglIYYFGy4z7H1YvQW+fw8ea2WdbTtnzhwlbUXswGTYeypnBsXFxeHl5cXcuXNTPISqb9++hIWFsXDhwgyd55lnnuH06dP88ccfXLt2jYIFCzJ//nzat2+fos2ZM2dYvnx5mudIa6ZtqVKluHLlCj4+PinaxsTEcOLECYKCgvD0vGkA9NZb6QdasSL07n1j/f33IT7etmqxWG686SxbFp566kbbcePg6k1PoLzVtdLRr18/fvnlF1vc0dHRFC9enMWLF1O3bt00j/nkk0+YNWsW//77LwAFCxbkiy++oG/fvqnaPvPMM7i4uPD111/btq1fv56WLVsSFRWFp6cnQUFBvPDCC7YHkaU10/bbb7+lf39rlZz9+/dTvXp19u/fT5UqVTJ0jZvFxMRw/PhxypYti6enJxaLhQsXLuDn56c3+g6iPnc89bljqb8dT31uP8HhMTw17V/+C4m6ZTvT9X++fqIurar637LtnYqIiKBQoUKEh4enGovlVV9++SUff/wxwcHB1KpVi4kTJ9KwYcMMHRsREUHBggXt158pZn6m9Vbj+sy23DjzMym5aYm/nthM9nHzeoptcem3S/e4OLiyC86n/Z4mTQUqgnvhO0+eZmUSU24vecL0TpKkt0yCJjv+dutmj+xzi39iDMwLtM4YT/cPEwAmcPfN+nIUeURCQgIBAQFcunSJscPh61lw4iy4ubkxfvx4Bg0aRGhoKHPmzGHEiBHEx8cTVBIGdIXXPoOiRYty/vx5lUjIQhaLhdDQUIoVK6axrQM4ur8zOhbLNj9R7u7u1KtXj5UrV9qSthaLhZUrVzL0Dp5EaLFYbAnX+Ph44uPjU3W4i4vLLW+z8/DwwMPDI9V2s9mc6lxmsxmTyWT7SOFWt1okzaBNYz15Ht020zadthm61i3cf//9TJ48GYArV67w1Vdf0a5dO7Zs2UKZMmWYNWsWX3zxBUePHiUqKoqEhAR8fHxsr3X48OEMGDCAX375hVatWtG1a1fKly8PwO7du9m9eze//vqr7XpJt66eOHGCqlWr2l5j8r67uT9r1aplWw4MDASss56rVq2a4Wuk7CrruZN/PW9eF/tTnzue+tyx1N+Opz63j8BCXvzSvxGNP/ybREv6b5gNwGTAK3N3s/m1VnhmYakEfU1TmjVrFsOHD2fKlCk0atSIzz//nDZt2nDo0CGKFSvm3OAyO/PTMDKYsIzLWDsjjWMcctwt7rTLDu70oU65hcnVOmvT5Apmt1usuyXbftN6UttLW+Da2YxeGArXhSoj7iAJm40SptmBi6d1Zv7aR7H+wecWfwi690clbDMpqTQCwOjPwWKBoKAgZs+eTf369bFYLJhMJoYOHUqTJk3o1q0bx48f5/UJ1uNVIkHEPrJN0hasCcC+fftSv359GjZsyOeff050dDT9+vUDoE+fPpQoUYKxY8cC1jIG9evXp3z58sTGxvL777/z888/25KQPj4+tGjRgldeeYV8+fJRpkwZ1qxZw08//cT48ePt/4Jeey39fTe/+XjllRvLhoElIQGzq2vaCdrrs1Kzgre3NxUqVLCtf/fddxQsWJBvv/2W9u3b07t3b95++23atGlDwYIFmTlzJp9+euOJnG+99Ra9evVi6dKlLFu2jDfffJOZM2fy2GOPERUVxbPPPsuwYcNSXbd06dIZjtEtWWmIpORtUtI9q64hIiIi6Vt/5OItE7ZJDCD8WgLL9p7nsTol7R9YHjV+/HgGDBhgGyNPmTKFpUuXMnXqVEaOHJnxE8XFpV126xZlvFK5uYzXkRlw7Rb1Pm2nNeDqFfi1AGABI40JFcnfqdxuoqcj2iZy64l+d9LWBVueyW5tLdc/0mJyATdXa01PsytYXKwvIFXS8vpnVzfrh8kNDBfrR4pkZ7J1N3dwcbOuW8zWoJKfL3kC1M0dXN2vn9dsbZ/W9U1u4O4BLtfjNVysry29JKyrB7h5WNcNEyTeoiaqi4v1A6yZqptL3t3c9tSv1tv1b9W/AGbAbEDlF6FM9xR3Vd4yBsPIeJk9w7j1eTPbFjJd6i+VjJT6S69tfLw17mJt4N45sPkZiA/DwIQJA8PVbK3d7O4L9b63tkvr/OmdNz3JSw/eSduEBOv3UFa0dXO7kQewV9vERNvPxpyZM21NLBbo8thjfPf99/gWKnSj7fX/M+rXrMn2TZvo/+yzzFuwwHacrURCsvOmydX1Rj7EXm0z8rN8Jz/39m6b1s+nxXLj/2k3t1u3TS4v/o7IirYuLhlrC1nzO+JWrzOZbJW07d69OxcuXGDMmDEEBwdTu3Ztli9fbntQ1qlTp1LMtIiOjmbw4MGcOXOGfPnyUaVKFX755Re6d+9uazNz5kxGjRpF7969uXz5MmXKlOH999/nueees/8LupM6s8nbGsaNb/K0ZtBmon5tRiXNUrp27RobNmygTJkyjB492rb/5MmTqY6pVKkSlSpV4qWXXqJnz5788MMPPPbYY9StW5f9+/enSApnNUdcQ0REJK/7c1+IrYbt7ZhN8MfeECVt7SQuLo5t27YxatQo2zaz2UyrVq3YuHFjmsek95Bd45NPMNK4u8yoUCFlGa9x4zCl80bOKFMmRRkv02efwoUbecMUCgEPJFtfAVxN5w1tAaB1svW/gfRKG3sBbZOtrwXSyxu7A8lL6f4DXEynrQvQybpomFxgixmCTWAyW5OUXP+ctP5ECWvC0OwGa6/AqZiU+5N/7lcf3D2tbdecgP8uJtt/vc318xsD24N3fmvbVbsx7TlmDc5khtA1cPXUjf5+GEh6Fu9eINnEWgOgQGUo3Q1MJoxBgyBpZvbq1ZjWrEmnI8B45hkoUeJ6n/2D6a+/0m/bt6+1vBvAli2Yli1LttcCxF3/AKNnTyhXybpr505MtyiJZzz+ONxzj3Vl3z5Mc+em3/bRR6F2bevK4f8wzZiRftu2bSGptMiJE5h+/DH9tq1awb1dMLkNg5AwTKvSbYpRFahVCKNkZwgJwXR9YlGabRs3htbXv+HDwjBNmJB+2/r1Ian0X3Q0pk8+Sb9trVqQVHowLg7T9clPacdbFbp1s62b3n8//bZ38TuCzz7DdHOpv6S2xYvDwIE3NkyahCks7Ma6ZTBE7Ifwg8R7xeLSvTZGqU5Q6nH4eiqmC2nHbPj6wgsv3Njw/feYzp9Pu62XV8oJVT//jCmN98AAhptbyolaM2ZgOnIkzbYAxptv3liZOxfTgQPptx016sb7/kWLMO3alX7bESMg6SHcy5Zh2ro1/bYvvAC+vtaVFSswXf9/Y92iRQC4uZj59KHWDKleHWJjbZOljLVr8f79d/D2xjCZKAjMqVGDSTExjFjxJ/GJFtauXWttv2FDxn9H/PvvTb8jbmrbsydUuv47Ytcu+/yO+C+Lf0c0bWpdOXsWUzrP2QEwWrSA689iIjQ09e8Iw8A7Ohq8vbE0aaLfEWTgd0Tytn5+MHjwjQ1ff43pwoW02/r6Ynn++RsPNXbA7wgj2bjsVrJV0hZg6NCh6ZZDWL16dYr19957j/fee++W5wsICOCHH37IqvByndjYWIKDgwFreYRJkyYRFRVFhw4diIiI4NSpU8ycOZMGDRqwdOlS5s+fbzv22rVrvPLKKzz++OMEBQVx5swZ/v33X7p06QLA//73P+69916GDh3KM888g7e3N/v372fFihVMmjQpS+J3xDVERETyurCrcRlK2II1sRt2LZvfIp6DXbx4kcTERNukhiT+/v4cPHgwzWPSe8hudHQ0LmnMAkqIiCAmNNS27h0VhSmd2UKJkZFcS9a2aFzkHb3BMEyuWNwK25KghskMJjOGdz4S/YIwTNZZlC4+JzARj4E5VdLUUiAf8eWbYFyfZem6bxtmlyjbfsOWADVj5PPiWp0uYHbDMLnicfpvzB6hyc53/RjM4OZBVMth1lmeJjOel3/D1SP9J0pF1R1hW/Y8sQjXmP/Sb1tqmC0h41FoGW7596XbNtq7tfVNIuDhFo+b+cYbPVevanhePZWRrsYExHiWI+H6m+GrFy/aJoq6h4XhHh2d7rFXL17Ecn3GktuVK3jcou21S5dIvB5vhtpe//5xvXwZz1u0jbl8mYRMtHW5dIl8t2gbe+UK8XfS9lIEHlUn4BvSN6nQRypJvy7Dqn5O7KUIzBcv4nWL88aFhRF3PQZTeLg1UZOO+PBwYpPaXr2a4bbExZH/Fm1v/rm/k7Z38jvCOyoK07VrGWrrFRmJ+eY43MpjFClHtJcXloqDrJO6LkWk3fY6i4sLV5OdN19kJC7ptDUsFqIz2tbVNUVbz4gIXG/Rb1F32jbpd0R4OG63aBt94QLG9f0Zant9hl/yn/uFnTszZt06BtetS92AAK5evZrid4TrlSsY1x/Knry04dP33EPtIkX44vJlXv/gA0JDQ/U74nrbO/m5T6utYRjEXO/zeP2OSLPtLX/uPT1T/Nzf7ndEVGio7aHG3g74HRGdwaRttnkQWXZ2qwLBSQ+1SvNBZJlkGAYJCQm4urqmrpObhZ566il+TPZXogIFClClShX+97//2RKvr776KlOnTiU2Npb27dtz77338tZbbxEWFkZcXBx9+/bln3/+ISQkhKJFi9K5c2c+/vhjW1/8+++/jB49mo0bN2IYBuXLl6d79+68dv2vDWXLluXFF1+0PYjMZDIxf/5824PIgoKC2LFjB7Wv/xUsLCyMQoUKsWrVKlpe/6vU7a5xs5u/Zirw7Xjqc8dTnzuW+tvx1Of29dzP2/hzf3CGZ9q2rhbAlCfrZdn17f7grBzk3LlzlChRgg0bNtC4cWPb9ldffZU1a9awefPmVMek+5DdkJC0+/Mubms0reoMZxdhSu8e/mSnNRJMUKIjRtOZqdvZ6xZIyF23PifGYFpUFuLDrcnDdMojGABuvhgdj9+o+ZnObdJpcsTtzDnt1ufTCzBt6I8p+e36SZ/dfDEafw+lO1nb3u6249vdJp2cbn22Pnz04kX8AgNv/J+v3xF33vZ2P3PJ2lri47kQHJz+A1/1O+Lu2qbx85niIbsqj5B22ywsj2BxcbnR34mJdv8dERERQSF//5zzIDJxvGnTpjFt2rRbthk3bhzjxo1LsS0pweru7s6MW9xGANCgQQP+/PPPdPefOHEixXryvyGULVuWm/+m4Ovrm2rb7a4hIiIid6f1Pf4s3xecobYWA9pU9799Q8mUokWL4uLiQkhISIrtISEhBAQEpHlMug/Z9fTEnJFJB3cyMaFcFwhJ//bV5EyuBpR7HFNGzp9G/A5vm9nSZ3Zt6wnNfr7+kCZIUfD2+gRjMFnzuM1+wuTtm/Z5zeaUb25vJbu0zehT6u3VtkxnKNkOTs2F0/OIjQrGPX8AlOqMqfTjmG5+IFbyeom3kx3a3snPvb3apvfzabFgcndP+fBR/Y6487Z38jPn5obJw8P6/8bt/jiu3xF33hZS/3xaLOn3uX5HWGXlz/L1h+2ZzWbr86XsEUOyn09zBmvaaiqKiIiIiNxSuxrF8cnnmnad0mRMQMF8rrStXtwRYeVJ7u7u1KtXj5UrV9q2WSwWVq5cmWLmrdOU7gpuhUinqm0yJnAvBKUfd0RUuVvJDtB8gfVhTGAt7ZDsM+6+0HyhtZ1kLRdPCHoC4765XKk7D+O+uRD0xI3ZzCIiIndBSVsRERERuSVPNxfGd60NpvRTcabr/3zatTaebncwU0Pu2PDhw/n222/58ccfOXDgAIMGDSI6Opp+/fo5OzRrsqpxUvmtW363wL0/KrmVVUp2hMfOQeOfoeSjxPo2hpKPWtcfO6eErYiISA6k8ggiIiIiclutqvnzzZP1GTFnJ+HXEjCbrKUQkj775HPl0661aVVNpRHsrXv37ly4cIExY8YQHBxM7dq1Wb58eaqHkzlN0szPTU9B3BUMzJiw2D7j7mtN2CqRmLWSZn2W6cWV6zW+TarxLSIikmMpaSsiIiIiGfJQNX82v9aKZXvPs3xvMBfCo/Er6M3D1QNoW724Ztg60NChQxk6dKizw0hf0szPNOp9UvpxzbAVERERuQ0lbUVEREQkwzzdXHisTkkerRVI6PXZfLd9KInkTZr5KSIiIpJpGjVlEcMwbt9IsgV9rUREREREREREJDtT0vYuubm5AXD16lUnRyIZlfS1SvraiYiIiIiIiIiIZCcqj3CXXFxc8PX1JTQ0FAAvLy9MpvSelJsxhmGQkJCAq6vrXZ9LbjAMg6tXrxIaGoqvry8uLqq7JyIiIiIiIiIi2Y+StlkgICAAwJa4vVuGYWCxWDCbzUra2oGvr6/tayYiIiIiIiIiIpLdKGmbBUwmE8WLF6dYsWLEx8ff9fksFguXLl2iSJEierBHFnNzc9MMWxERERERERERydaUtM1CLi4uWZIQtFgsuLm54enpqaStiIiIiIiIiIhIHqOMoIiIiIiIiIiIiEg2oqStiIiIiIiIiIiISDaipK2IiIiIiIiIiIhINqKathlgGAYAERERDrmexWIhMjJSNW0dRP3teOpzx1OfO5b62/HU547nyD5PGoMljcnk7mhsm7upvx1Pfe5Y6m/HU587nvrcsRzd3xkd2yppmwGRkZEAlCpVysmRiIiIiORdkZGRFCxY0Nlh5Hga24qIiIg43+3GtiZDUxZuy2KxcO7cOQoUKIDJZLL79SIiIihVqhSnT5/Gx8fH7tfL69Tfjqc+dzz1uWOpvx1Pfe54juxzwzCIjIwkMDBQs02ygMa2uZv62/HU546l/nY89bnjqc8dy9H9ndGxrWbaZoDZbKZkyZIOv66Pj49+OB1I/e146nPHU587lvrb8dTnjueoPtcM26yjsW3eoP52PPW5Y6m/HU997njqc8dyZH9nZGyrqQoiIiIiIiIiIiIi2YiStiIiIiIiIiIiIiLZiJK22ZCHhwdvvvkmHh4ezg4lT1B/O5763PHU546l/nY89bnjqc8lo/S94ljqb8dTnzuW+tvx1OeOpz53rOza33oQmYiIiIiIiIiIiEg2opm2IiIiIiIiIiIiItmIkrYiIiIiIiIiIiIi2YiStiIiIiIiIiIiIiLZiJK22cyXX35J2bJl8fT0pFGjRmzZssXZIeUaa9eupUOHDgQGBmIymViwYEGK/YZhMGbMGIoXL06+fPlo1aoVhw8fdk6wucDYsWNp0KABBQoUoFixYnTq1IlDhw6laBMTE8OQIUMoUqQI+fPnp0uXLoSEhDgp4pxv8uTJ1KxZEx8fH3x8fGjcuDHLli2z7Vd/29eHH36IyWTixRdftG1Tn2ett956C5PJlOKjSpUqtv3qb/s4e/YsTzzxBEWKFCFfvnzUqFGDrVu32vbr/0+5FY1t7UdjW8fS2NbxNLZ1Lo1t7U9jW8fLaeNaJW2zkVmzZjF8+HDefPNNtm/fTq1atWjTpg2hoaHODi1XiI6OplatWnz55Zdp7h83bhxffPEFU6ZMYfPmzXh7e9OmTRtiYmIcHGnusGbNGoYMGcKmTZtYsWIF8fHxtG7dmujoaFubl156icWLFzNnzhzWrFnDuXPn6Ny5sxOjztlKlizJhx9+yLZt29i6dSsPPPAAjz76KPv27QPU3/b077//8vXXX1OzZs0U29XnWe+ee+7h/Pnzto/169fb9qm/s96VK1do2rQpbm5uLFu2jP379/Ppp59SqFAhWxv9/ynp0djWvjS2dSyNbR1PY1vn0djWcTS2dZwcOa41JNto2LChMWTIENt6YmKiERgYaIwdO9aJUeVOgDF//nzbusViMQICAoyPP/7Yti0sLMzw8PAwZsyY4YQIc5/Q0FADMNasWWMYhrV/3dzcjDlz5tjaHDhwwACMjRs3OivMXKdQoULGd999p/62o8jISKNixYrGihUrjBYtWhgvvPCCYRj6HreHN99806hVq1aa+9Tf9vG///3PuO+++9Ldr/8/5VY0tnUcjW0dT2Nb59DY1v40tnUcjW0dKyeOazXTNpuIi4tj27ZttGrVyrbNbDbTqlUrNm7c6MTI8objx48THBycov8LFixIo0aN1P9ZJDw8HIDChQsDsG3bNuLj41P0eZUqVShdurT6PAskJiYyc+ZMoqOjady4sfrbjoYMGUL79u1T9C3oe9xeDh8+TGBgIOXKlaN3796cOnUKUH/by6JFi6hfvz5du3alWLFi1KlTh2+//da2X/9/Sno0tnUu/Wzan8a2jqWxreNobOtYGts6Tk4c1yppm01cvHiRxMRE/P39U2z39/cnODjYSVHlHUl9rP63D4vFwosvvkjTpk2pXr06YO1zd3d3fH19U7RVn9+dPXv2kD9/fjw8PHjuueeYP38+1apVU3/bycyZM9m+fTtjx45NtU99nvUaNWrEtGnTWL58OZMnT+b48eM0a9aMyMhI9bedHDt2jMmTJ1OxYkX++OMPBg0axLBhw/jxxx8B/f8p6dPY1rn0s2lfGts6jsa2jqWxrWNpbOtYOXFc6+qUq4pInjJkyBD27t2boj6P2EflypXZuXMn4eHhzJ07l759+7JmzRpnh5UrnT59mhdeeIEVK1bg6enp7HDyhLZt29qWa9asSaNGjShTpgyzZ88mX758Tows97JYLNSvX58PPvgAgDp16rB3716mTJlC3759nRydiIhzaGzrOBrbOo7Gto6nsa1j5cRxrWbaZhNFixbFxcUl1ZMAQ0JCCAgIcFJUeUdSH6v/s97QoUNZsmQJq1atomTJkrbtAQEBxMXFERYWlqK9+vzuuLu7U6FCBerVq8fYsWOpVasWEyZMUH/bwbZt2wgNDaVu3bq4urri6urKmjVr+OKLL3B1dcXf3199bme+vr5UqlSJI0eO6HvcTooXL061atVSbKtatart1j39/ynp0djWufSzaT8a2zqWxraOo7Gt82lsa185cVyrpG024e7uTr169Vi5cqVtm8ViYeXKlTRu3NiJkeUNQUFBBAQEpOj/iIgINm/erP7PJMMwGDp0KPPnz+fvv/8mKCgoxf569erh5uaWos8PHTrEqVOn1OdZyGKxEBsbq/62gwcffJA9e/awc+dO20f9+vXp3bu3bVl9bl9RUVEcPXqU4sWL63vcTpo2bcqhQ4dSbPvvv/8oU6YMoP8/JX0a2zqXfjaznsa22YPGtvajsa3zaWxrXzlyXOuUx59JmmbOnGl4eHgY06ZNM/bv328MHDjQ8PX1NYKDg50dWq4QGRlp7Nixw9ixY4cBGOPHjzd27NhhnDx50jAMw/jwww8NX19fY+HChcbu3buNRx991AgKCjKuXbvm5MhzpkGDBhkFCxY0Vq9ebZw/f972cfXqVVub5557zihdurTx999/G1u3bjUaN25sNG7c2IlR52wjR4401qxZYxw/ftzYvXu3MXLkSMNkMhl//vmnYRjqb0dI/oRdw1CfZ7WXX37ZWL16tXH8+HHjn3/+MVq1amUULVrUCA0NNQxD/W0PW7ZsMVxdXY3333/fOHz4sDF9+nTDy8vL+OWXX2xt9P+npEdjW/vS2NaxNLZ1PI1tnU9jW/vS2NaxcuK4VknbbGbixIlG6dKlDXd3d6Nhw4bGpk2bnB1SrrFq1SoDSPXRt29fwzAMw2KxGG+88Ybh7+9veHh4GA8++KBx6NAh5wadg6XV14Dxww8/2Npcu3bNGDx4sFGoUCHDy8vLeOyxx4zz5887L+gc7umnnzbKlCljuLu7G35+fsaDDz5oG9QahvrbEW4e2KrPs1b37t2N4sWLG+7u7kaJEiWM7t27G0eOHLHtV3/bx+LFi43q1asbHh4eRpUqVYxvvvkmxX79/ym3orGt/Whs61ga2zqexrbOp7GtfWls63g5bVxrMgzDcNy8XhERERERERERERG5FdW0FREREREREREREclGlLQVERERERERERERyUaUtBURERERERERERHJRpS0FREREREREREREclGlLQVERERERERERERyUaUtBURERERERERERHJRpS0FREREREREREREclGlLQVERERERERERERyUaUtBURsaOnnnqKsmXLOjuMbGfatGmYTCZOnDiRofaDBw/moYceyrLrjxw5kkaNGmXZ+URERETyAo1t06axrYjYg5K2IpIrJA2Ukj48PT2pVKkSQ4cOJSQkxNnhOUXLli2pXr26s8O4a8ePH+e7777jtddes22LjY3l+eefx8/Pj5IlS/Lee++lOu7MmTPkz5+ff/75J9W+F198kV27drFo0SK7xi4iIiKSGRrbpqaxrca2InmNq7MDEBHJSu+88w5BQUHExMSwfv16Jk+ezO+//87evXvx8vJyeDzffvstFovF4dfNTSZMmEBQUBD333+/bdvHH3/MTz/9xOjRo4mMjOSdd96hfPny9OzZ09bmlVdeoWPHjjRt2jTVOQMCAnj00Uf55JNP6Nixo0Neh4iIiMid0tg299HYVkQySklbEclV2rZtS/369QF45plnKFKkCOPHj2fhwoUpBj3JRUdH4+3tbZd43Nzc7HLevCI+Pp7p06fz3HPPpdi+ZMkSXn75ZV599VUATp8+zaJFi2xf4/Xr17N48WIOHjyY7rm7detG165dOXbsGOXKlbPfixARERHJJI1tcxeNbUXkTqg8gojkag888ABgvQ0JrHW48ufPz9GjR2nXrh0FChSgd+/eAJQtW5annnoq1TlatmxJy5YtbeurV6/GZDIxe/Zs3n//fUqWLImnpycPPvggR44cSXHszXW/Tpw4gclk4pNPPuGbb76hfPnyeHh40KBBA/79999U154zZw7VqlXD09OT6tWrM3/+/CyvJbZs2TKaNWuGt7c3BQoUoH379uzbt8+2/5NPPsFkMnHy5MlUx44aNQp3d3euXLli27Z582YefvhhChYsiJeXFy1atEjzNq6MWL9+PRcvXqRVq1Yptl+7do1ChQrZ1gsXLszVq1cBsFgsvPDCC7z66quULFky3XMnnXPhwoWZik1ERETE0TS2vT2NbTW2FcktlLQVkVzt6NGjABQpUsS2LSEhgTZt2lCsWDE++eQTunTpkqlzf/jhh8yfP58RI0YwatQoNm3aZBsk386vv/7Kxx9/zLPPPst7773HiRMn6Ny5M/Hx8bY2S5cupXv37ri5uTF27Fg6d+5M//792bZtW6biTcvPP/9M+/btyZ8/Px999BFvvPEG+/fv57777rM9SKFbt262gfzNZs+eTevWrW2DzL///pvmzZsTERHBm2++yQcffEBYWBgPPPAAW7ZsueP4NmzYgMlkok6dOim2N2jQgG+++YY9e/awceNGZsyYQcOGDQH4/vvvuXjxIq+88sotz12wYEHKly+f6UG3iIiIiKNpbHtrGttqbCuSqxgiIrnADz/8YADGX3/9ZVy4cME4ffq0MXPmTKNIkSJGvnz5jDNnzhiGYRh9+/Y1AGPkyJGpzlGmTBmjb9++qba3aNHCaNGihW191apVBmBUrVrViI2NtW2fMGGCARh79uyxbevbt69RpkwZ2/rx48cNwChSpIhx+fJl2/aFCxcagLF48WLbtho1ahglS5Y0IiMjbdtWr15tACnOmZ4WLVoY99xzT7r7IyMjDV9fX2PAgAEptgcHBxsFCxZMsb1x48ZGvXr1UrTbsmWLARg//fSTYRiGYbFYjIoVKxpt2rQxLBaLrd3Vq1eNoKAg46GHHrJtS/p6HT9+/Jav4YknnjCKFCmSavvp06eNe+65xwAMwGjWrJkRGRlphIWFGX5+fsbMmTNved4krVu3NqpWrZqhtiIiIiKOorFtahrb3p7GtiK5i2baikiu0qpVK/z8/ChVqhQ9evQgf/78zJ8/nxIlSqRoN2jQoLu+Vr9+/XB3d7etN2vWDIBjx47d9tju3bunuAXq5mPPnTvHnj176NOnD/nz57e1a9GiBTVq1Ljr2AFWrFhBWFgYPXv25OLFi7YPFxcXGjVqxKpVq1LEu23bNtvsDoBZs2bh4eHBo48+CsDOnTs5fPgwvXr14tKlS7bzRUdH8+CDD7J27do7fnDFpUuXUvRTkpIlS7Jjxw527NjBvn37WL16Nfnz5+ftt9+mcuXKdO/enfXr19OoUSNKlSrFsGHDiIuLS3WeQoUKcfHixTuKSURERMRRNLbNOI1tNbYVyW30IDIRyVW+/PJLKlWqhKurK/7+/lSuXBmzOeXfp1xdXW9ZDyqjSpcunWI9aQCWvAZWZo9NqrFVoUKFVMdWqFCB7du333nANzl8+DBwozbazXx8fGzLXbt2Zfjw4cyaNYvXXnsNwzCYM2cObdu2tbVLOl/fvn3TvWZ4eHiaA9VbMQwjze1ubm7Url3btn7w4EG++uorNmzYwOXLl2nfvj0jR47k/vvvp1+/frz//vu8/fbbqc5tMpnuKB4RERERR9HYNuM0ttXYViS3UdJWRHKVhg0b2p6wmx4PD49Ug10g3QFOYmIiLi4uqbantQ3SH4hl1bFZJWlmwM8//0xAQECq/a6uN/6LCAwMpFmzZsyePZvXXnuNTZs2cerUKT766KNU5/v4449TDDiTSz6zIiOKFCmSoTcKAC+99BJPPPEEdevW5eeff6Zw4cKMGjUKgFdffTXNge2VK1coWrToHcUkIiIi4iga22acxrYa24rkNkraiohcV6hQIcLCwlJtP3nyJOXKlXNoLGXKlAFI9cTe9LZlRvny5QEoVqxYqifYpqV79+4MHjyYQ4cOMWvWLLy8vOjQoUOq8/n4+GTofBlRpUoVpk+fTnh4OAULFky33ZIlS9iwYYNtRsS5c+coXry4bX9gYCBnz55Nddzx48epVatWlsQqIiIikp1obHtrGtuKSHanmrYiIteVL1+eTZs2pagPtWTJEk6fPu3wWAIDA6levTo//fQTUVFRtu1r1qxhz549WXKNNm3a4OPjwwcffJDiyb5JLly4kGK9S5cuuLi4MGPGDObMmcMjjzyCt7e3bX+9evUoX748n3zySYqY0ztfRjRu3BjDMG75VOG4uDiGDx/O66+/TrFixQDw9/fnyJEjJCQkAHDgwIFUMy7Cw8M5evQoTZo0ueO4RERERLI7jW1T0thWRHIazbQVEbnumWeeYe7cuTz88MN069aNo0eP8ssvv9j+yu5oH3zwAY8++ihNmzalX79+XLlyhUmTJlG9evU0B45puXDhAu+9916q7UFBQfTu3ZvJkyfz5JNPUrduXXr06IGfnx+nTp1i6dKlNG3alEmTJtmOKVasGPfffz/jx48nMjKS7t27pzin2Wzmu+++o23bttxzzz3069ePEiVKcPbsWVatWoWPjw+LFy++oz647777KFKkCH/99Ve69ckmTJgAwAsvvGDb1q5dO4YMGUKvXr1o0qQJ7777Ls8880yK4/766y8Mw7A9bEJEREQkN9HYVmNbEcnZlLQVEbmuTZs2fPrpp4wfP54XX3yR+vXrs2TJEl5++WWnxNOhQwdmzJjBW2+9xciRI6lYsSLTpk3jxx9/ZN++fRk6R2hoKG+88Uaq7Q8++CC9e/emV69eBAYG8uGHH/Lxxx8TGxtLiRIlaNasGf369Ut1XPfu3fnrr78oUKAA7dq1S7W/ZcuWbNy4kXfffZdJkyYRFRVFQEAAjRo14tlnn73jPnB3d6d3797MmTOHDz74INX+kJAQ3n33XaZPn57iacfFihXjt99+46WXXmLFihV07NiRN998M8Wxc+bM4b777nPaGxcRERERe9LYVmNbEcnZTIYjK4OLiMhdq127Nn5+fqxYscLZoTjEsWPHqFKlCsuWLePBBx/MknMGBwcTFBTEzJkzNRtBRERExIk0tr17GtuK5E6qaSsikk3Fx8fb6lYlWb16Nbt27aJly5bOCcoJypUrR//+/fnwww+z7Jyff/45NWrU0KBWRERExEE0trXS2FZEMkozbUVEsqkTJ07QqlUrnnjiCQIDAzl48CBTpkyhYMGC7N27lyJFijg7RBERERGRDNHYVkTkzqimrYhINlWoUCHq1avHd999x4ULF/D29qZ9+/Z8+OGHGtSKiIiISI6isa2IyJ3RTFsRERERERERERGRbEQ1bUVERERERERERESyESVtRURERERERERERLIRJW1FREREREREREREshElbUVERERERERERESyESVtRURERERERERERLIRJW1FREREREREREREshElbUVERERERERERESyESVtRURERERERERERLIRJW1FREREREREREREspH/A2Y6ecdM/kKUAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š Visualization saved to: /content/drive/MyDrive/glu_pruning/results/llama_1b_performance_analysis.png\n"
          ]
        }
      ],
      "source": [
        "# Visualization: Performance across pruning levels\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Accuracy plot\n",
        "axes[0].plot(summary_df['pruning'], summary_df['avg_accuracy'], marker='o', linewidth=2, markersize=8)\n",
        "axes[0].axhline(y=baseline_acc, color='r', linestyle='--', alpha=0.5, label='Baseline')\n",
        "axes[0].set_xlabel('Pruning Level (%)', fontsize=12)\n",
        "axes[0].set_ylabel('Average Accuracy', fontsize=12)\n",
        "axes[0].set_title('Accuracy vs. Pruning Level', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].legend()\n",
        "\n",
        "# Highlight star model\n",
        "star_idx = summary_df[summary_df['star'] == 'â­'].index[0]\n",
        "axes[0].plot(summary_df.loc[star_idx, 'pruning'], summary_df.loc[star_idx, 'avg_accuracy'],\n",
        "             marker='*', markersize=20, color='gold', markeredgecolor='black', markeredgewidth=1.5)\n",
        "\n",
        "# Perplexity plot\n",
        "axes[1].plot(summary_df['pruning'], summary_df['avg_perplexity'], marker='o', linewidth=2, markersize=8, color='orange')\n",
        "axes[1].axhline(y=baseline_ppl, color='r', linestyle='--', alpha=0.5, label='Baseline')\n",
        "axes[1].set_xlabel('Pruning Level (%)', fontsize=12)\n",
        "axes[1].set_ylabel('Average Perplexity', fontsize=12)\n",
        "axes[1].set_title('Perplexity vs. Pruning Level', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "axes[1].legend()\n",
        "\n",
        "# Highlight star model\n",
        "axes[1].plot(summary_df.loc[star_idx, 'pruning'], summary_df.loc[star_idx, 'avg_perplexity'],\n",
        "             marker='*', markersize=20, color='gold', markeredgecolor='black', markeredgewidth=1.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{RESULTS_DIR}/llama_1b_performance_analysis.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nğŸ“Š Visualization saved to: {RESULTS_DIR}/llama_1b_performance_analysis.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4H7r1PNIvXI"
      },
      "source": [
        "# 7. Decision Matrix: Which Models to Upload?\n",
        "\n",
        "Based on the evaluation results, determine which models should be uploaded to HuggingFace Hub for Phase 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "l5sHLEjwIvXI",
        "outputId": "eef56ed4-05b0-4327-e1be-94c551057620",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ğŸ¯ DECISION MATRIX: Models for HuggingFace Hub Upload\n",
            "======================================================================\n",
            "\n",
            "Evaluation Criteria:\n",
            "  1. Performance degradation (avg_accuracy) < 15% vs baseline\n",
            "  2. Outperforms or matches baseline in at least 3 tasks (Primary Metric)\n",
            "  3. Accuracy degradation (avg_accuracy) < 50% vs baseline\n",
            "  4. Sufficient parameter reduction to justify storage\n",
            "\n",
            "Building primary metric map from BENCHMARKS_BASE...\n",
            "âœ… Found BENCHMARKS_BASE with 13 tasks.\n",
            "Built primary metric map for 13 tasks.\n",
            "Captured 11 valid scores from baseline model.\n",
            "\n",
            "Upload Decisions (Updated Logic with Task Details):\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Model                               Pruning    Star   Tasks Won/Tied   Upload?    Reason\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Llama-3.2-1B-pruned-10%             10        %        3                âœ… YES      Low degradation (acc: 2.8%) AND Won/Tied: winogrande, truthfulqa_mc1, truthfulqa_mc2\n",
            "Llama-3.2-1B-pruned-20%             20        %        2                âŒ NO       Only 2 tasks won (truthfulqa_mc1, truthfulqa_mc2)\n",
            "Llama-3.2-1B-pruned-30%             30        %        2                âŒ NO       Only 2 tasks won (truthfulqa_mc1, truthfulqa_mc2)\n",
            "Llama-3.2-1B-pruned-40%             40        % â­      2                âœ… YES      Star model. Won/Tied: truthfulqa_mc1, truthfulqa_mc2\n",
            "Llama-3.2-1B-pruned-50%             50        %        2                âŒ NO       Only 2 tasks won (truthfulqa_mc1, truthfulqa_mc2)\n",
            "Llama-3.2-1B-pruned-60%             60        %        2                âŒ NO       Only 2 tasks won (truthfulqa_mc1, truthfulqa_mc2)\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "ğŸ“¦ Total models to upload to HF Hub: 2/6\n",
            "\n",
            "âœ… PHASE 3 COMPLETE - Ready for Phase 2 (Model Factory)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # Need numpy for nan checks\n",
        "import pandas as pd # Ensure pandas is imported\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"ğŸ¯ DECISION MATRIX: Models for HuggingFace Hub Upload\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "print(\"Evaluation Criteria:\")\n",
        "print(\"  1. Performance degradation (avg_accuracy) < 15% vs baseline\")\n",
        "print(\"  2. Outperforms or matches baseline in at least 3 tasks (Primary Metric)\")\n",
        "print(\"  3. Accuracy degradation (avg_accuracy) < 50% vs baseline\")\n",
        "print(\"  4. Sufficient parameter reduction to justify storage\\n\")\n",
        "\n",
        "# --- Setup: Load BENCHMARKS_BASE and Baseline Scores (as before) ---\n",
        "print(\"Building primary metric map from BENCHMARKS_BASE...\")\n",
        "TASK_PRIMARY_METRICS = {}\n",
        "if 'BENCHMARKS_BASE' not in globals():\n",
        "    print(\"=\"*70)\n",
        "    print(\"âŒ Error: BENCHMARKS_BASE variable not found in global scope.\")\n",
        "    print(\"   Please ensure you have run the setup cell that imports from utils.py:\")\n",
        "    print(\"   >>> from utils import BENCHMARKS_BASE\")\n",
        "    print(\"=\"*70)\n",
        "    raise NameError(\"BENCHMARKS_BASE is not defined.\")\n",
        "else:\n",
        "    print(f\"âœ… Found BENCHMARKS_BASE with {len(BENCHMARKS_BASE)} tasks.\")\n",
        "\n",
        "for task_spec in BENCHMARKS_BASE:\n",
        "    task_name = task_spec[\"name\"]\n",
        "    if task_name == 'wikitext':\n",
        "        TASK_PRIMARY_METRICS[task_name] = ('word_perplexity,none', False) # Lower is better\n",
        "    elif task_name == 'lambada_openai':\n",
        "        TASK_PRIMARY_METRICS[task_name] = ('perplexity', False) # Lower is better\n",
        "    elif task_name == 'gsm8k':\n",
        "        TASK_PRIMARY_METRICS[task_name] = ('exact_match,strict-match', True) # Higher is better\n",
        "    else:\n",
        "        TASK_PRIMARY_METRICS[task_name] = ('accuracy', True) # Higher is better\n",
        "print(f\"Built primary metric map for {len(TASK_PRIMARY_METRICS)} tasks.\")\n",
        "\n",
        "try:\n",
        "    df_baseline = df[df['pruning_pct'] == 0].set_index('task')\n",
        "    baseline_scores = {}\n",
        "    for task, (metric, _) in TASK_PRIMARY_METRICS.items():\n",
        "        if task in df_baseline.index and metric in df_baseline.columns:\n",
        "            score = df_baseline.loc[task, metric]\n",
        "            if not pd.isna(score):\n",
        "                baseline_scores[task] = score\n",
        "    print(f\"Captured {len(baseline_scores)} valid scores from baseline model.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error: Could not get baseline scores from 'df'. {e}\")\n",
        "    baseline_scores = {}\n",
        "# --- End Setup ---\n",
        "\n",
        "\n",
        "# Decision logic\n",
        "decisions = []\n",
        "if 'summary_df' not in globals():\n",
        "     print(\"âŒ Error: 'summary_df' not found. Please run the previous analysis cell.\")\n",
        "else:\n",
        "    for _, row in summary_df.iterrows():\n",
        "        if row['pruning'] == 0:\n",
        "            continue  # Skip baseline\n",
        "\n",
        "        decision = {\n",
        "            \"model\": row['model'],\n",
        "            \"pruning\": row['pruning'],\n",
        "            \"star\": row['star'],\n",
        "        }\n",
        "\n",
        "        acc_degradation = abs((row['avg_accuracy'] - baseline_acc) / baseline_acc * 100) if baseline_acc and not pd.isna(row['avg_accuracy']) else 999\n",
        "        ppl_degradation = abs((row['avg_perplexity'] - baseline_ppl) / baseline_ppl * 100) if baseline_ppl and not pd.isna(row['avg_perplexity']) else 999\n",
        "\n",
        "        # --- MODIFIED: Check Criterion 2 AND store task names ---\n",
        "        outperform_count = 0\n",
        "        outperforming_tasks = []  # <-- NEW: List to store names\n",
        "        model_tasks_df = df[df['model'] == row['model']].set_index('task')\n",
        "\n",
        "        for task, (metric, higher_is_better) in TASK_PRIMARY_METRICS.items():\n",
        "            if task not in baseline_scores or task not in model_tasks_df.index:\n",
        "                continue\n",
        "\n",
        "            model_score = model_tasks_df.loc[task, metric]\n",
        "            if pd.isna(model_score):\n",
        "                continue\n",
        "\n",
        "            baseline_score = baseline_scores[task]\n",
        "\n",
        "            if higher_is_better:\n",
        "                if model_score >= baseline_score:\n",
        "                    outperform_count += 1\n",
        "                    outperforming_tasks.append(task) # <-- NEW: Store task name\n",
        "            else: # Lower is better\n",
        "                if model_score <= baseline_score:\n",
        "                    outperform_count += 1\n",
        "                    outperforming_tasks.append(task) # <-- NEW: Store task name\n",
        "\n",
        "        decision['outperform_count'] = outperform_count\n",
        "        decision['outperforming_tasks'] = outperforming_tasks # <-- NEW: Store list\n",
        "        tasks_str = \", \".join(outperforming_tasks) if outperforming_tasks else \"None\"\n",
        "        # --- End Criterion 2 Check ---\n",
        "\n",
        "\n",
        "        # --- MODIFIED: Updated Decision Logic with task list ---\n",
        "        is_star = row['star'] == 'â­'\n",
        "        crit_1_low_degrad = (acc_degradation < 15)\n",
        "        crit_2_tasks = (outperform_count >= 3)\n",
        "        crit_3_not_catastrophic = (acc_degradation < 50)\n",
        "\n",
        "        if is_star:\n",
        "            decision['upload'] = True\n",
        "            decision['reason'] = f\"Star model. Won/Tied: {tasks_str}\"\n",
        "        elif crit_1_low_degrad and crit_2_tasks:\n",
        "            decision['upload'] = True\n",
        "            decision['reason'] = f\"Low degradation (acc: {acc_degradation:.1f}%) AND Won/Tied: {tasks_str}\"\n",
        "        elif crit_3_not_catastrophic and crit_2_tasks:\n",
        "            decision['upload'] = True\n",
        "            decision['reason'] = f\"Acceptable degradation (acc: {acc_degradation:.1f}%) AND Won/Tied: {tasks_str}\"\n",
        "        else:\n",
        "            decision['upload'] = False\n",
        "            reason_parts = []\n",
        "            if not crit_3_not_catastrophic:\n",
        "                reason_parts.append(f\"High acc degradation ({acc_degradation:.1f}%)\")\n",
        "            if not crit_2_tasks:\n",
        "                reason_parts.append(f\"Only {outperform_count} tasks won ({tasks_str})\")\n",
        "\n",
        "            if not reason_parts:\n",
        "                 reason_parts.append(f\"Degradation (acc: {acc_degradation:.1f}%) or task count ({outperform_count}) too low\")\n",
        "\n",
        "            decision['reason'] = \" AND \".join(reason_parts)\n",
        "\n",
        "        decisions.append(decision)\n",
        "\n",
        "# Display decision table\n",
        "print(\"\\nUpload Decisions (Updated Logic with Task Details):\")\n",
        "print(\"-\" * 140) # <-- Widen table\n",
        "# <-- MODIFIED: Widen Reason column\n",
        "print(f\"{'Model':<35} {'Pruning':<10} {'Star':<6} {'Tasks Won/Tied':<16} {'Upload?':<10} {'Reason'}\")\n",
        "print(\"-\" * 140) # <-- Widen table\n",
        "\n",
        "for dec in decisions:\n",
        "    upload_status = \"âœ… YES\" if dec['upload'] else \"âŒ NO\"\n",
        "    print(f\"{dec['model']:<35} {dec['pruning']:<10}% {dec['star']:<6} {dec.get('outperform_count', 'N/A'):<16} {upload_status:<10} {dec['reason']}\")\n",
        "\n",
        "print(\"-\" * 140) # <-- Widen table\n",
        "\n",
        "# Summary\n",
        "models_to_upload = sum(1 for d in decisions if d['upload'])\n",
        "print(f\"\\nğŸ“¦ Total models to upload to HF Hub: {models_to_upload}/{len(decisions)}\")\n",
        "print(f\"\\nâœ… PHASE 3 COMPLETE - Ready for Phase 2 (Model Factory)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n{'='*70}\")\n",
        "print(\"ğŸ’¾ SAVING COMPLETE RESULTS FOR RESEARCH SHARING\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "# --- Dynamic Model Info Setup ---\n",
        "# Build a lookup for expansion rates from EXPERIMENT_CONFIG (if it exists)\n",
        "exp_rate_map = {}\n",
        "if 'EXPERIMENT_CONFIG' in globals():\n",
        "    try:\n",
        "        # --- ROBUST PARSING ---\n",
        "        # Only add if all keys are present\n",
        "        for cfg in EXPERIMENT_CONFIG:\n",
        "            if (cfg.get(\"base_model\", \"\") == \"meta-llama/Llama-3.2-1B\"\n",
        "                and 'pruning_pct' in cfg\n",
        "                and 'expansion_rate' in cfg):\n",
        "                 exp_rate_map[cfg['pruning_pct']] = cfg['expansion_rate']\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Warning: Could not parse EXPERIMENT_CONFIG. {e}\")\n",
        "exp_rate_map[0] = 300 # Baseline expansion rate\n",
        "\n",
        "print(f\"Loaded {len(exp_rate_map)} expansion rates from config (Baseline included).\")\n",
        "\n",
        "# Build 'models_evaluated' section dynamically from the 'df'\n",
        "models_evaluated = {}\n",
        "if 'df' not in globals():\n",
        "    print(\"âŒ Error: 'df' DataFrame not found. Cannot build results.\")\n",
        "    raise NameError(\"'df' is not defined. Please run consolidation cell.\")\n",
        "\n",
        "# Group by model to rebuild the nested result structure\n",
        "grouped_by_model = df.groupby(['model', 'pruning_pct', 'is_star'])\n",
        "\n",
        "for (model_name, pruning_pct, is_star_bool), model_df in grouped_by_model:\n",
        "    model_key = f\"pruned_{int(pruning_pct)}pct\" if pruning_pct > 0 else \"baseline\"\n",
        "\n",
        "    # Rebuild the nested results dict\n",
        "    model_results_dict = {}\n",
        "    for _, row in model_df.iterrows():\n",
        "        task_name = row['task']\n",
        "        metrics = row.drop(['model', 'pruning_pct', 'is_star', 'task'])\n",
        "\n",
        "        task_metrics = {}\n",
        "        for col, val in metrics.dropna().items():\n",
        "            # Convert numpy types to native Python types\n",
        "            if isinstance(val, (np.integer, np.int64)):\n",
        "                task_metrics[col] = int(val)\n",
        "            elif isinstance(val, (np.floating, np.float64)):\n",
        "                task_metrics[col] = float(val)\n",
        "            else:\n",
        "                task_metrics[col] = val\n",
        "        model_results_dict[task_name] = task_metrics\n",
        "\n",
        "    # Assemble the entry for this model\n",
        "    models_evaluated[model_key] = {\n",
        "        \"name\": model_name,\n",
        "        \"pruning_pct\": int(pruning_pct), # Cast to native int\n",
        "        \"expansion_rate\": exp_rate_map.get(int(pruning_pct), None), # Get from map\n",
        "        \"is_star\": bool(is_star_bool), # <--- *** CRITICAL FIX: Cast to native bool ***\n",
        "        \"hf_repo\": (\n",
        "            \"meta-llama/Llama-3.2-1B\" if pruning_pct == 0\n",
        "            else f\"peremartra/Llama-3.2-1B-pruned-{int(pruning_pct)}pct\"\n",
        "        ),\n",
        "        \"results\": model_results_dict\n",
        "    }\n",
        "print(f\"Dynamically built {len(models_evaluated)} model entries from 'df'.\")\n",
        "# --- End Dynamic Model Setup ---\n",
        "\n",
        "\n",
        "# Consolidate all data into a comprehensive JSON\n",
        "complete_results = {\n",
        "    \"experiment_metadata\": {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"notebook\": \"02_Evaluate_1B.ipynb\",\n",
        "        \"model_family\": \"Llama-3.2-1B\",\n",
        "        \"pruning_method\": \"MAW (Maximum Absolute Weight)\",\n",
        "        #\"library_versions\": library_versions,\n",
        "        \"hardware\": {\n",
        "            \"device\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\",\n",
        "            \"gpu_memory_gb\": torch.cuda.get_device_properties(0).total_memory / 1e9 if torch.cuda.is_available() else None\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"benchmarks\": [\n",
        "        {\"name\": task[\"name\"], \"num_fewshot\": task[\"num_fewshot\"]}\n",
        "        for task in BENCHMARKS_BASE\n",
        "    ],\n",
        "\n",
        "    \"models_evaluated\": models_evaluated, # Use dynamic model data\n",
        "\n",
        "    \"summary_statistics\": {\n",
        "        \"baseline\": {\n",
        "            \"avg_accuracy\": float(summary_df.loc[summary_df['pruning'] == 0, 'avg_accuracy'].values[0]),\n",
        "            \"avg_perplexity\": float(summary_df.loc[summary_df['pruning'] == 0, 'avg_perplexity'].values[0]),\n",
        "        },\n",
        "        \"pruned_models\": [\n",
        "            {\n",
        "                \"pruning_pct\": int(row['pruning']),\n",
        "                \"is_star\": row['star'] == 'â­', # This is native bool, so it's fine\n",
        "                \"avg_accuracy\": float(row['avg_accuracy']) if pd.notna(row['avg_accuracy']) else None,\n",
        "                \"avg_perplexity\": float(row['avg_perplexity']) if pd.notna(row['avg_perplexity']) else None,\n",
        "                \"accuracy_degradation_pct\": float(((row['avg_accuracy'] - baseline_acc) / baseline_acc * 100)) if baseline_acc and pd.notna(row['avg_accuracy']) else None,\n",
        "                \"perplexity_degradation_pct\": float(((row['avg_perplexity'] - baseline_ppl) / baseline_ppl * 100)) if baseline_ppl and pd.notna(row['avg_perplexity']) else None\n",
        "            }\n",
        "            for _, row in summary_df.iterrows() if row['pruning'] > 0\n",
        "        ]\n",
        "    },\n",
        "\n",
        "    \"upload_decisions\": decisions, # Use dynamic decisions\n",
        "\n",
        "    \"citation\": {\n",
        "        \"paper\": \"Exploring GLU Expansion Ratios: Structured Pruning in Llama-3.2 Models\",\n",
        "        \"author\": \"Pere Martra\",\n",
        "        \"doi\": \"https://doi.org/10.31219/osf.io/qgxea\",\n",
        "        \"github\": \"https://github.com/peremartra/llama-glu-expansion-pruning\",\n",
        "        \"note\": \"Results are freely available for research purposes. Please cite the paper if you use this data.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# --- Save to JSON ---\n",
        "try:\n",
        "    # Ensure RESULTS_DIR is defined\n",
        "    if 'RESULTS_DIR' not in globals():\n",
        "        print(\"âŒ Error: RESULTS_DIR not defined. Defaulting to './results'\")\n",
        "        RESULTS_DIR = \"./results\"\n",
        "\n",
        "    # Create RESULTS_DIR if it doesn't exist\n",
        "    os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    json_path = f\"{RESULTS_DIR}/llama_1b_complete_results_{timestamp}.json\"\n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(complete_results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"âœ… Complete results saved to:\")\n",
        "    print(f\"   {json_path}\")\n",
        "\n",
        "    # Also save a \"latest\" version\n",
        "    latest_json = f\"{RESULTS_DIR}/llama_1b_complete_results_latest.json\"\n",
        "    with open(latest_json, 'w') as f:\n",
        "        json.dump(complete_results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"âœ… Latest version:\")\n",
        "    print(f\"   {latest_json}\")\n",
        "\n",
        "    # Display file size\n",
        "    file_size_kb = Path(json_path).stat().st_size / 1024\n",
        "    print(f\"\\nğŸ“Š File size: {file_size_kb:.1f} KB\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error saving JSON files: {e}\")\n",
        "    print(f\"   Please ensure RESULTS_DIR is defined and writeable: {RESULTS_DIR}\")\n",
        "\n",
        "\n",
        "print(f\"\\nğŸ“¦ Models included: {len(complete_results['models_evaluated'])}\")\n",
        "print(f\"ğŸ“‹ Benchmarks per model: {len(BENCHMARKS_BASE)}\")\n",
        "print(f\"ğŸ”¬ Total result entries: {len(df)}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"âœ… COMPLETE RESULTS SAVED - Ready for research sharing\")\n",
        "# --- THIS IS THE CORRECTED LINE ---\n",
        "print(f\"{'='*70}\\n\")"
      ],
      "metadata": {
        "id": "nfjYJe0yNNhK",
        "outputId": "391ad29a-d571-4dbc-b586-b67627db554e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ğŸ’¾ SAVING COMPLETE RESULTS FOR RESEARCH SHARING\n",
            "======================================================================\n",
            "\n",
            "Loaded 1 expansion rates from config (Baseline included).\n",
            "Dynamically built 7 model entries from 'df'.\n",
            "âœ… Complete results saved to:\n",
            "   /content/drive/MyDrive/glu_pruning/results/llama_1b_complete_results_20251023_091722.json\n",
            "âœ… Latest version:\n",
            "   /content/drive/MyDrive/glu_pruning/results/llama_1b_complete_results_latest.json\n",
            "\n",
            "ğŸ“Š File size: 17.5 KB\n",
            "\n",
            "ğŸ“¦ Models included: 7\n",
            "ğŸ“‹ Benchmarks per model: 13\n",
            "ğŸ”¬ Total result entries: 84\n",
            "\n",
            "======================================================================\n",
            "âœ… COMPLETE RESULTS SAVED - Ready for research sharing\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6JVP-5RIvXI"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ“ Key Takeaways\n",
        "\n",
        "This notebook evaluated the Llama-3.2-1B model family across 10 comprehensive benchmarks to determine:\n",
        "\n",
        "1. **Optimal pruning level** for GLU-MLP layers\n",
        "2. **Performance-efficiency trade-offs** at different expansion ratios\n",
        "3. **Which models justify upload** to HuggingFace Hub\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Powered by OptiPFair** - Structured Pruning for GLU Architectures\n",
        "\n",
        "If this research helps your work:\n",
        "- â­ Star [the repo](https://github.com/peremartra/optipfair)\n",
        "- ğŸ“– Read the [documentation](https://peremartra.github.io/optipfair/)\n",
        "- ğŸ› Report issues or suggest features\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2oEyjdt9E42b"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}