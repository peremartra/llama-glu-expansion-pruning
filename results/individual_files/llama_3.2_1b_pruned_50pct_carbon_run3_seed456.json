{
  "metadata": {
    "model_name": "Llama-3.2-1B-pruned-50%-run3",
    "started_at": "2025-11-07T13:14:02.720880",
    "last_updated": "2025-11-07T13:18:39.441369",
    "mode": "carbon_profiling"
  },
  "results": {
    "hellaswag_latency_b1": {
      "mode": "latency",
      "avg_ttft_ms": 390.00236360650314,
      "std_ttft_ms": 7.0622575895214785,
      "throughput_tokens_per_sec": 51.28174048755049,
      "total_loop_time_sec": 39.13539171218872,
      "total_new_tokens": 1900,
      "avg_new_tokens_per_prompt": 20.0,
      "num_measured_prompts": 95,
      "num_warmup_prompts": 5,
      "memory_allocated_gb": 1.5607962608337402,
      "memory_reserved_gb": 2.39453125,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 1.5518836975097656,
      "energy_kwh": 0.0001191710408002776,
      "energy_raw_kwh": 0.00046911245124555263,
      "energy_idle_kwh": 0.00034994141044527503,
      "joules_per_token": 0.22579776151631545,
      "joules_per_token_calculation": {
        "total_joules": 429.01574688099936,
        "total_tokens": 1900,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T13:14:44.355528",
        "project_name": "N/A",
        "duration_sec": 39.92581248283386,
        "energy_kwh": 0.0001191710408002776,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 1.5607962608337402,
        "gpu_memory_reserved_gb": 2.39453125,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 76,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.00046911245124555263,
        "energy_idle_contribution_kwh": 0.00034994141044527503,
        "energy_net_kwh": 0.0001191710408002776,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0013432910802882358,
        "codecarbon_cpu_energy_kwh": 0.000470085329199339,
        "codecarbon_gpu_energy_kwh": 0.0006520491327500072
      },
      "batch_size": 1,
      "num_prompts": 100,
      "max_new_tokens": 20,
      "workload_description": "Short responses (Latency, TTFT, bsz=1)"
    },
    "mmlu_latency_b1": {
      "mode": "latency",
      "avg_ttft_ms": 963.6403234381424,
      "std_ttft_ms": 98.40513745955728,
      "throughput_tokens_per_sec": 51.35132821109292,
      "total_loop_time_sec": 96.53892660140991,
      "total_new_tokens": 4701,
      "avg_new_tokens_per_prompt": 49.48421052631579,
      "num_measured_prompts": 95,
      "num_warmup_prompts": 5,
      "memory_allocated_gb": 1.5607962608337402,
      "memory_reserved_gb": 2.3984375,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 1.5518836975097656,
      "energy_kwh": 0.0002861089596135954,
      "energy_raw_kwh": 0.001139895507947009,
      "energy_idle_kwh": 0.0008537865483334137,
      "joules_per_token": 0.21910067105061548,
      "joules_per_token_calculation": {
        "total_joules": 1029.9922546089433,
        "total_tokens": 4701,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T13:16:23.445477",
        "project_name": "N/A",
        "duration_sec": 97.41093969345093,
        "energy_kwh": 0.0002861089596135954,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 1.5607962608337402,
        "gpu_memory_reserved_gb": 2.3984375,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 76,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.001139895507947009,
        "energy_idle_contribution_kwh": 0.0008537865483334137,
        "energy_net_kwh": 0.0002861089596135954,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0032640605983070494,
        "codecarbon_cpu_energy_kwh": 0.0011473274564812981,
        "codecarbon_gpu_energy_kwh": 0.0015769779282479995
      },
      "batch_size": 1,
      "num_prompts": 100,
      "max_new_tokens": 50,
      "workload_description": "Knowledge QA (Latency, TTFT, bsz=1)"
    },
    "ifeval_latency_b1": {
      "mode": "latency",
      "avg_ttft_ms": 2794.1260051727295,
      "std_ttft_ms": 567.9116854617001,
      "throughput_tokens_per_sec": 51.55100368893193,
      "total_loop_time_sec": 84.41544890403748,
      "total_new_tokens": 3601,
      "avg_new_tokens_per_prompt": 144.04,
      "num_measured_prompts": 25,
      "num_warmup_prompts": 5,
      "memory_allocated_gb": 1.5607962608337402,
      "memory_reserved_gb": 2.388671875,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 1.5518836975097656,
      "energy_kwh": 0.0002514754087616503,
      "energy_raw_kwh": 0.0009990428737338295,
      "energy_idle_kwh": 0.0007475674649721792,
      "joules_per_token": 0.251405573880017,
      "joules_per_token_calculation": {
        "total_joules": 905.3114715419412,
        "total_tokens": 3601,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T13:17:50.412574",
        "project_name": "N/A",
        "duration_sec": 85.29210186004639,
        "energy_kwh": 0.0002514754087616503,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 1.5607962608337402,
        "gpu_memory_reserved_gb": 2.388671875,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 76,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.0009990428737338295,
        "energy_idle_contribution_kwh": 0.0007475674649721792,
        "energy_net_kwh": 0.0002514754087616503,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0028607328105425176,
        "codecarbon_cpu_energy_kwh": 0.0010046045713853992,
        "codecarbon_gpu_energy_kwh": 0.0013835030512460017
      },
      "batch_size": 1,
      "num_prompts": 30,
      "max_new_tokens": 150,
      "workload_description": "Instruction (Latency, TTFT, bsz=1)"
    },
    "hellaswag_throughput_b8": {
      "mode": "throughput",
      "avg_ttft_ms": null,
      "std_ttft_ms": null,
      "avg_batch_time_ms": 573.3211040496826,
      "throughput_tokens_per_sec": 266.3904601600672,
      "total_loop_time_sec": 7.515228509902954,
      "total_new_tokens": 1680,
      "avg_new_tokens_per_prompt": 19.09090909090909,
      "num_measured_prompts": 88,
      "num_warmup_batches": 2,
      "memory_allocated_gb": 1.5607962608337402,
      "memory_reserved_gb": 2.416015625,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 1.5518836975097656,
      "energy_kwh": 2.3377386705401645e-05,
      "energy_raw_kwh": 9.624210071928188e-05,
      "energy_idle_kwh": 7.286471401388023e-05,
      "joules_per_token": 0.05009440008300352,
      "joules_per_token_calculation": {
        "total_joules": 84.15859213944591,
        "total_tokens": 1680,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T13:18:00.376625",
        "project_name": "N/A",
        "duration_sec": 8.313342809677124,
        "energy_kwh": 2.3377386705401645e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 1.5607962608337402,
        "gpu_memory_reserved_gb": 2.416015625,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 75,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 9.624210071928188e-05,
        "energy_idle_contribution_kwh": 7.286471401388023e-05,
        "energy_net_kwh": 2.3377386705401645e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.00027558670655864197,
        "codecarbon_cpu_energy_kwh": 9.793558861041005e-05,
        "codecarbon_gpu_energy_kwh": 0.00013158816082600722
      },
      "batch_size": 8,
      "num_prompts": 100,
      "max_new_tokens": 20,
      "workload_description": "Short responses (Throughput, bsz=8)"
    },
    "mmlu_throughput_b8": {
      "mode": "throughput",
      "avg_ttft_ms": null,
      "std_ttft_ms": null,
      "avg_batch_time_ms": 1369.599689136852,
      "throughput_tokens_per_sec": 278.78086191652903,
      "total_loop_time_sec": 17.836957216262817,
      "total_new_tokens": 4200,
      "avg_new_tokens_per_prompt": 47.72727272727273,
      "num_measured_prompts": 88,
      "num_warmup_batches": 2,
      "memory_allocated_gb": 1.5607962608337402,
      "memory_reserved_gb": 2.412109375,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 1.5518836975097656,
      "energy_kwh": 5.224782359145204e-05,
      "energy_raw_kwh": 0.0002159378073402622,
      "energy_idle_kwh": 0.00016368998374881015,
      "joules_per_token": 0.04478384879267318,
      "joules_per_token_calculation": {
        "total_joules": 188.09216492922735,
        "total_tokens": 4200,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T13:18:20.715651",
        "project_name": "N/A",
        "duration_sec": 18.675856590270996,
        "energy_kwh": 5.224782359145204e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 1.5607962608337402,
        "gpu_memory_reserved_gb": 2.412109375,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 76,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.0002159378073402622,
        "energy_idle_contribution_kwh": 0.00016368998374881015,
        "energy_net_kwh": 5.224782359145204e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0006183321924775359,
        "codecarbon_cpu_energy_kwh": 0.00021997130532640897,
        "codecarbon_gpu_energy_kwh": 0.000294883569240012
      },
      "batch_size": 8,
      "num_prompts": 100,
      "max_new_tokens": 50,
      "workload_description": "Knowledge QA (Throughput, bsz=8)"
    },
    "ifeval_throughput_b8": {
      "mode": "throughput",
      "avg_ttft_ms": null,
      "std_ttft_ms": null,
      "avg_batch_time_ms": 3991.217295328776,
      "throughput_tokens_per_sec": 275.6051396368254,
      "total_loop_time_sec": 15.950262308120728,
      "total_new_tokens": 3300,
      "avg_new_tokens_per_prompt": 137.5,
      "num_measured_prompts": 24,
      "num_warmup_batches": 1,
      "memory_allocated_gb": 1.5607962608337402,
      "memory_reserved_gb": 2.416015625,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 1.5518836975097656,
      "energy_kwh": 4.260516816006045e-05,
      "energy_raw_kwh": 0.00019028538989185453,
      "energy_idle_kwh": 0.00014768022173179408,
      "joules_per_token": 0.04647836526552049,
      "joules_per_token_calculation": {
        "total_joules": 153.37860537621762,
        "total_tokens": 3300,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T13:18:39.439613",
        "project_name": "N/A",
        "duration_sec": 16.849257230758667,
        "energy_kwh": 4.260516816006045e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 1.5607962608337402,
        "gpu_memory_reserved_gb": 2.416015625,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 77,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.00019028538989185453,
        "energy_idle_contribution_kwh": 0.00014768022173179408,
        "energy_net_kwh": 4.260516816006045e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0005448771744860411,
        "codecarbon_cpu_energy_kwh": 0.00019852620816736505,
        "codecarbon_gpu_energy_kwh": 0.0002529749246020091
      },
      "batch_size": 8,
      "num_prompts": 30,
      "max_new_tokens": 150,
      "workload_description": "Instruction (Throughput, bsz=8)"
    }
  },
  "completed_workloads": [
    "hellaswag_latency_b1",
    "mmlu_latency_b1",
    "ifeval_latency_b1",
    "hellaswag_throughput_b8",
    "mmlu_throughput_b8",
    "ifeval_throughput_b8"
  ],
  "failed_workloads": []
}