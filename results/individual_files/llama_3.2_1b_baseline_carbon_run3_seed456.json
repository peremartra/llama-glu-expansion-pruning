{
  "metadata": {
    "model_name": "Llama-3.2-1B-baseline-run3",
    "started_at": "2025-11-07T12:11:04.031502",
    "last_updated": "2025-11-07T12:14:17.045810",
    "mode": "carbon_profiling"
  },
  "results": {
    "hellaswag_latency_b1": {
      "mode": "latency",
      "avg_ttft_ms": 121.2929324099892,
      "std_ttft_ms": 144.54338943183492,
      "throughput_tokens_per_sec": 49.46702071410934,
      "total_loop_time_sec": 12.25619912147522,
      "total_new_tokens": 570,
      "avg_new_tokens_per_prompt": 6.0,
      "num_measured_prompts": 95,
      "num_warmup_prompts": 5,
      "memory_allocated_gb": 2.3098196983337402,
      "memory_reserved_gb": 2.365234375,
      "max_memory_allocated_gb": 2.6879000663757324,
      "model_size_gb": 2.3018836975097656,
      "energy_kwh": 4.710218865602621e-05,
      "energy_raw_kwh": 0.00016155389883360945,
      "energy_idle_kwh": 0.00011445171017758324,
      "joules_per_token": 0.29748750730121815,
      "joules_per_token_calculation": {
        "total_joules": 169.56787916169435,
        "total_tokens": 570,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T12:11:18.739989",
        "project_name": "N/A",
        "duration_sec": 13.058121681213379,
        "energy_kwh": 4.710218865602621e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 2.3098196983337402,
        "gpu_memory_reserved_gb": 2.365234375,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 78,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.00016155389883360945,
        "energy_idle_contribution_kwh": 0.00011445171017758324,
        "energy_net_kwh": 4.710218865602621e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0004626053107581697,
        "codecarbon_cpu_energy_kwh": 0.00015372862668194557,
        "codecarbon_gpu_energy_kwh": 0.00023655380035400055
      },
      "batch_size": 1,
      "num_prompts": 100,
      "max_new_tokens": 20,
      "workload_description": "Short responses (Latency, TTFT, bsz=1)"
    },
    "mmlu_latency_b1": {
      "mode": "latency",
      "avg_ttft_ms": 855.3358128196314,
      "std_ttft_ms": 271.00457173887344,
      "throughput_tokens_per_sec": 51.737143371873664,
      "total_loop_time_sec": 86.24099779129028,
      "total_new_tokens": 4204,
      "avg_new_tokens_per_prompt": 44.252631578947366,
      "num_measured_prompts": 95,
      "num_warmup_prompts": 5,
      "memory_allocated_gb": 2.3098196983337402,
      "memory_reserved_gb": 2.3671875,
      "max_memory_allocated_gb": 2.6879000663757324,
      "model_size_gb": 2.3018836975097656,
      "energy_kwh": 0.0003302215930320616,
      "energy_raw_kwh": 0.0010947079392499717,
      "energy_idle_kwh": 0.0007644863462179101,
      "joules_per_token": 0.28277776758216505,
      "joules_per_token_calculation": {
        "total_joules": 1188.7977349154219,
        "total_tokens": 4204,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T12:12:47.589522",
        "project_name": "N/A",
        "duration_sec": 87.22242522239685,
        "energy_kwh": 0.0003302215930320616,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 2.3098196983337402,
        "gpu_memory_reserved_gb": 2.3671875,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 76,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.0010947079392499717,
        "energy_idle_contribution_kwh": 0.0007644863462179101,
        "energy_net_kwh": 0.0003302215930320616,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.003134667192079021,
        "codecarbon_cpu_energy_kwh": 0.0010273960049479102,
        "codecarbon_gpu_energy_kwh": 0.001623915188019999
      },
      "batch_size": 1,
      "num_prompts": 100,
      "max_new_tokens": 50,
      "workload_description": "Knowledge QA (Latency, TTFT, bsz=1)"
    },
    "ifeval_latency_b1": {
      "mode": "latency",
      "avg_ttft_ms": 1272.6420497894287,
      "std_ttft_ms": 1365.551252441776,
      "throughput_tokens_per_sec": 51.51487805298242,
      "total_loop_time_sec": 38.47461414337158,
      "total_new_tokens": 1639,
      "avg_new_tokens_per_prompt": 65.56,
      "num_measured_prompts": 25,
      "num_warmup_prompts": 5,
      "memory_allocated_gb": 2.3098196983337402,
      "memory_reserved_gb": 2.337890625,
      "max_memory_allocated_gb": 2.6879000663757324,
      "model_size_gb": 2.3018836975097656,
      "energy_kwh": 0.0001481547422431393,
      "energy_raw_kwh": 0.0004940847980930216,
      "energy_idle_kwh": 0.00034593005584988227,
      "joules_per_token": 0.32541615135771906,
      "joules_per_token_calculation": {
        "total_joules": 533.3570720753015,
        "total_tokens": 1639,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T12:13:28.707869",
        "project_name": "N/A",
        "duration_sec": 39.46814560890198,
        "energy_kwh": 0.0001481547422431393,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 2.3098196983337402,
        "gpu_memory_reserved_gb": 2.337890625,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 76,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.0004940847980930216,
        "energy_idle_contribution_kwh": 0.00034593005584988227,
        "energy_net_kwh": 0.0001481547422431393,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0014147987341247574,
        "codecarbon_cpu_energy_kwh": 0.0004649134354909779,
        "codecarbon_gpu_energy_kwh": 0.0007311608627060002
      },
      "batch_size": 1,
      "num_prompts": 30,
      "max_new_tokens": 150,
      "workload_description": "Instruction (Latency, TTFT, bsz=1)"
    },
    "hellaswag_throughput_b8": {
      "mode": "throughput",
      "avg_ttft_ms": null,
      "std_ttft_ms": null,
      "avg_batch_time_ms": 491.18239229375666,
      "throughput_tokens_per_sec": 239.8664603345949,
      "total_loop_time_sec": 6.689528465270996,
      "total_new_tokens": 1296,
      "avg_new_tokens_per_prompt": 14.727272727272727,
      "num_measured_prompts": 88,
      "num_warmup_batches": 2,
      "memory_allocated_gb": 2.3098196983337402,
      "memory_reserved_gb": 2.861328125,
      "max_memory_allocated_gb": 2.6879000663757324,
      "model_size_gb": 2.3018836975097656,
      "energy_kwh": 2.4370514229474187e-05,
      "energy_raw_kwh": 9.001531281185214e-05,
      "energy_idle_kwh": 6.564479858237796e-05,
      "joules_per_token": 0.06769587285965052,
      "joules_per_token_calculation": {
        "total_joules": 87.73385122610708,
        "total_tokens": 1296,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T12:13:37.849353",
        "project_name": "N/A",
        "duration_sec": 7.489602088928223,
        "energy_kwh": 2.4370514229474187e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 2.3098196983337402,
        "gpu_memory_reserved_gb": 2.861328125,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 74,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 9.001531281185214e-05,
        "energy_idle_contribution_kwh": 6.564479858237796e-05,
        "energy_net_kwh": 2.4370514229474187e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.00025775646429436504,
        "codecarbon_cpu_energy_kwh": 8.809449050903066e-05,
        "codecarbon_gpu_energy_kwh": 0.0001282248248020007
      },
      "batch_size": 8,
      "num_prompts": 100,
      "max_new_tokens": 20,
      "workload_description": "Short responses (Throughput, bsz=8)"
    },
    "mmlu_throughput_b8": {
      "mode": "throughput",
      "avg_ttft_ms": null,
      "std_ttft_ms": null,
      "avg_batch_time_ms": 1384.6538933840666,
      "throughput_tokens_per_sec": 275.7499066319207,
      "total_loop_time_sec": 18.052234888076782,
      "total_new_tokens": 4200,
      "avg_new_tokens_per_prompt": 47.72727272727273,
      "num_measured_prompts": 88,
      "num_warmup_batches": 2,
      "memory_allocated_gb": 2.3098196983337402,
      "memory_reserved_gb": 2.81640625,
      "max_memory_allocated_gb": 2.6879000663757324,
      "model_size_gb": 2.3018836975097656,
      "energy_kwh": 6.320581306072111e-05,
      "energy_raw_kwh": 0.00022889310490251322,
      "energy_idle_kwh": 0.0001656872918417921,
      "joules_per_token": 0.054176411194903816,
      "joules_per_token_calculation": {
        "total_joules": 227.54092701859602,
        "total_tokens": 4200,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T12:13:58.406779",
        "project_name": "N/A",
        "duration_sec": 18.903735160827637,
        "energy_kwh": 6.320581306072111e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 2.3098196983337402,
        "gpu_memory_reserved_gb": 2.81640625,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 76,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.00022889310490251322,
        "energy_idle_contribution_kwh": 0.0001656872918417921,
        "energy_net_kwh": 6.320581306072111e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0006554293439422759,
        "codecarbon_cpu_energy_kwh": 0.0002226917558736113,
        "codecarbon_gpu_energy_kwh": 0.0003279819290519983
      },
      "batch_size": 8,
      "num_prompts": 100,
      "max_new_tokens": 50,
      "workload_description": "Knowledge QA (Throughput, bsz=8)"
    },
    "ifeval_throughput_b8": {
      "mode": "throughput",
      "avg_ttft_ms": null,
      "std_ttft_ms": null,
      "avg_batch_time_ms": 3977.1578311920166,
      "throughput_tokens_per_sec": 276.579418441212,
      "total_loop_time_sec": 15.963367462158203,
      "total_new_tokens": 3300,
      "avg_new_tokens_per_prompt": 137.5,
      "num_measured_prompts": 24,
      "num_warmup_batches": 1,
      "memory_allocated_gb": 2.3098196983337402,
      "memory_reserved_gb": 2.4453125,
      "max_memory_allocated_gb": 2.6879000663757324,
      "model_size_gb": 2.3018836975097656,
      "energy_kwh": 5.259011256399847e-05,
      "energy_raw_kwh": 0.00020126875429710798,
      "energy_idle_kwh": 0.0001486786417331095,
      "joules_per_token": 0.05737103188799833,
      "joules_per_token_calculation": {
        "total_joules": 189.3244052303945,
        "total_tokens": 3300,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T12:14:17.044208",
        "project_name": "N/A",
        "duration_sec": 16.963169813156128,
        "energy_kwh": 5.259011256399847e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 2.3098196983337402,
        "gpu_memory_reserved_gb": 2.4453125,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 77,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.00020126875429710798,
        "energy_idle_contribution_kwh": 0.0001486786417331095,
        "energy_net_kwh": 5.259011256399847e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0005763277475798887,
        "codecarbon_cpu_energy_kwh": 0.00019981918504166822,
        "codecarbon_gpu_energy_kwh": 0.0002825341149159978
      },
      "batch_size": 8,
      "num_prompts": 30,
      "max_new_tokens": 150,
      "workload_description": "Instruction (Throughput, bsz=8)"
    }
  },
  "completed_workloads": [
    "hellaswag_latency_b1",
    "mmlu_latency_b1",
    "ifeval_latency_b1",
    "hellaswag_throughput_b8",
    "mmlu_throughput_b8",
    "ifeval_throughput_b8"
  ],
  "failed_workloads": []
}