{
  "metadata": {
    "model_name": "Llama-3.2-1B-pruned-20%-run1",
    "started_at": "2025-11-07T12:25:21.146638",
    "last_updated": "2025-11-07T12:29:16.412314",
    "mode": "carbon_profiling"
  },
  "results": {
    "hellaswag_latency_b1": {
      "mode": "latency",
      "avg_ttft_ms": 300.47687982258043,
      "std_ttft_ms": 148.65143283115052,
      "throughput_tokens_per_sec": 50.866511045177596,
      "total_loop_time_sec": 29.9518039226532,
      "total_new_tokens": 1452,
      "avg_new_tokens_per_prompt": 15.284210526315789,
      "num_measured_prompts": 95,
      "num_warmup_prompts": 5,
      "memory_allocated_gb": 2.012814998626709,
      "memory_reserved_gb": 2.474609375,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 2.0019569396972656,
      "energy_kwh": 0.00010617439401086414,
      "energy_raw_kwh": 0.00037650594400808363,
      "energy_idle_kwh": 0.0002703315499972195,
      "joules_per_token": 0.26324229920048964,
      "joules_per_token_calculation": {
        "total_joules": 382.22781843911093,
        "total_tokens": 1452,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T12:25:53.698195",
        "project_name": "N/A",
        "duration_sec": 30.842896699905396,
        "energy_kwh": 0.00010617439401086414,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 2.012814998626709,
        "gpu_memory_reserved_gb": 2.474609375,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 80,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.00037650594400808363,
        "energy_idle_contribution_kwh": 0.0002703315499972195,
        "energy_net_kwh": 0.00010617439401086414,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.001078114799380643,
        "codecarbon_cpu_energy_kwh": 0.0003632083671215335,
        "codecarbon_gpu_energy_kwh": 0.0005440326574479987
      },
      "batch_size": 1,
      "num_prompts": 100,
      "max_new_tokens": 20,
      "workload_description": "Short responses (Latency, TTFT, bsz=1)"
    },
    "mmlu_latency_b1": {
      "mode": "latency",
      "avg_ttft_ms": 788.1705585278963,
      "std_ttft_ms": 342.6227434838673,
      "throughput_tokens_per_sec": 51.885643785637356,
      "total_loop_time_sec": 78.80224370956421,
      "total_new_tokens": 3885,
      "avg_new_tokens_per_prompt": 40.89473684210526,
      "num_measured_prompts": 95,
      "num_warmup_prompts": 5,
      "memory_allocated_gb": 2.012814998626709,
      "memory_reserved_gb": 2.47265625,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 2.0019569396972656,
      "energy_kwh": 0.00027573245567632935,
      "energy_raw_kwh": 0.0009748988580155027,
      "energy_idle_kwh": 0.0006991664023391734,
      "joules_per_token": 0.25550497823289203,
      "joules_per_token_calculation": {
        "total_joules": 992.6368404347857,
        "total_tokens": 3885,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T12:27:15.120354",
        "project_name": "N/A",
        "duration_sec": 79.76988673210144,
        "energy_kwh": 0.00027573245567632935,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 2.012814998626709,
        "gpu_memory_reserved_gb": 2.47265625,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 77,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.0009748988580155027,
        "energy_idle_contribution_kwh": 0.0006991664023391734,
        "energy_net_kwh": 0.00027573245567632935,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.002791597060956986,
        "codecarbon_cpu_energy_kwh": 0.0009396060137638822,
        "codecarbon_gpu_energy_kwh": 0.0014099508501819978
      },
      "batch_size": 1,
      "num_prompts": 100,
      "max_new_tokens": 50,
      "workload_description": "Knowledge QA (Latency, TTFT, bsz=1)"
    },
    "ifeval_latency_b1": {
      "mode": "latency",
      "avg_ttft_ms": 2306.141595840454,
      "std_ttft_ms": 1002.5445274024751,
      "throughput_tokens_per_sec": 51.79213636119819,
      "total_loop_time_sec": 69.33761763572693,
      "total_new_tokens": 2986,
      "avg_new_tokens_per_prompt": 119.44,
      "num_measured_prompts": 25,
      "num_warmup_prompts": 5,
      "memory_allocated_gb": 2.012814998626709,
      "memory_reserved_gb": 2.46875,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 2.0019569396972656,
      "energy_kwh": 0.00024258377578597376,
      "energy_raw_kwh": 0.0008582204371309295,
      "energy_idle_kwh": 0.0006156366613449557,
      "joules_per_token": 0.29246536933339096,
      "joules_per_token_calculation": {
        "total_joules": 873.3015928295055,
        "total_tokens": 2986,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T12:28:27.010971",
        "project_name": "N/A",
        "duration_sec": 70.23974061012268,
        "energy_kwh": 0.00024258377578597376,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 2.012814998626709,
        "gpu_memory_reserved_gb": 2.46875,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 75,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.0008582204371309295,
        "energy_idle_contribution_kwh": 0.0006156366613449557,
        "energy_net_kwh": 0.00024258377578597376,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0024574914928352748,
        "codecarbon_cpu_energy_kwh": 0.0008272859068986049,
        "codecarbon_gpu_energy_kwh": 0.001241005159470003
      },
      "batch_size": 1,
      "num_prompts": 30,
      "max_new_tokens": 150,
      "workload_description": "Instruction (Latency, TTFT, bsz=1)"
    },
    "hellaswag_throughput_b8": {
      "mode": "throughput",
      "avg_ttft_ms": null,
      "std_ttft_ms": null,
      "avg_batch_time_ms": 603.8428219881924,
      "throughput_tokens_per_sec": 252.92554149175453,
      "total_loop_time_sec": 7.925017356872559,
      "total_new_tokens": 1680,
      "avg_new_tokens_per_prompt": 19.09090909090909,
      "num_measured_prompts": 88,
      "num_warmup_batches": 2,
      "memory_allocated_gb": 2.012814998626709,
      "memory_reserved_gb": 2.494140625,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 2.0019569396972656,
      "energy_kwh": 2.8011042669147282e-05,
      "energy_raw_kwh": 0.00010597191484639838,
      "energy_idle_kwh": 7.79608721772511e-05,
      "joules_per_token": 0.06002366286245846,
      "joules_per_token_calculation": {
        "total_joules": 100.83975360893021,
        "total_tokens": 1680,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T12:28:37.558868",
        "project_name": "N/A",
        "duration_sec": 8.89477801322937,
        "energy_kwh": 2.8011042669147282e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 2.012814998626709,
        "gpu_memory_reserved_gb": 2.494140625,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 74,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.00010597191484639838,
        "energy_idle_contribution_kwh": 7.79608721772511e-05,
        "energy_net_kwh": 2.8011042669147282e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0003034477716297473,
        "codecarbon_cpu_energy_kwh": 0.00010478048683818962,
        "codecarbon_gpu_energy_kwh": 0.00014937845283600343
      },
      "batch_size": 8,
      "num_prompts": 100,
      "max_new_tokens": 20,
      "workload_description": "Short responses (Throughput, bsz=8)"
    },
    "mmlu_throughput_b8": {
      "mode": "throughput",
      "avg_ttft_ms": null,
      "std_ttft_ms": null,
      "avg_batch_time_ms": 1362.9779815673828,
      "throughput_tokens_per_sec": 280.13525308684933,
      "total_loop_time_sec": 17.796435594558716,
      "total_new_tokens": 4200,
      "avg_new_tokens_per_prompt": 47.72727272727273,
      "num_measured_prompts": 88,
      "num_warmup_batches": 2,
      "memory_allocated_gb": 2.012814998626709,
      "memory_reserved_gb": 2.494140625,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 2.0019569396972656,
      "energy_kwh": 5.977665652266768e-05,
      "energy_raw_kwh": 0.00022351646890728685,
      "energy_idle_kwh": 0.00016373981238461917,
      "joules_per_token": 0.051237134162286584,
      "joules_per_token_calculation": {
        "total_joules": 215.19596348160366,
        "total_tokens": 4200,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T12:28:57.881022",
        "project_name": "N/A",
        "duration_sec": 18.681541681289673,
        "energy_kwh": 5.977665652266768e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 2.012814998626709,
        "gpu_memory_reserved_gb": 2.494140625,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 77,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.00022351646890728685,
        "energy_idle_contribution_kwh": 0.00016373981238461917,
        "energy_net_kwh": 5.977665652266768e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.000640033489163389,
        "codecarbon_cpu_energy_kwh": 0.0002199937321513864,
        "codecarbon_gpu_energy_kwh": 0.0003165569199120033
      },
      "batch_size": 8,
      "num_prompts": 100,
      "max_new_tokens": 50,
      "workload_description": "Knowledge QA (Throughput, bsz=8)"
    },
    "ifeval_throughput_b8": {
      "mode": "throughput",
      "avg_ttft_ms": null,
      "std_ttft_ms": null,
      "avg_batch_time_ms": 3994.6797688802085,
      "throughput_tokens_per_sec": 275.3662530271739,
      "total_loop_time_sec": 15.997307777404785,
      "total_new_tokens": 3300,
      "avg_new_tokens_per_prompt": 137.5,
      "num_measured_prompts": 24,
      "num_warmup_batches": 1,
      "memory_allocated_gb": 2.012814998626709,
      "memory_reserved_gb": 2.49609375,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 2.0019569396972656,
      "energy_kwh": 5.210701256628191e-05,
      "energy_raw_kwh": 0.00020003111146067146,
      "energy_idle_kwh": 0.00014792409889438955,
      "joules_per_token": 0.056844013708671176,
      "joules_per_token_calculation": {
        "total_joules": 187.58524523861487,
        "total_tokens": 3300,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T12:29:16.410751",
        "project_name": "N/A",
        "duration_sec": 16.877081871032715,
        "energy_kwh": 5.210701256628191e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 2.012814998626709,
        "gpu_memory_reserved_gb": 2.49609375,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 78,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.00020003111146067146,
        "energy_idle_contribution_kwh": 0.00014792409889438955,
        "energy_net_kwh": 5.210701256628191e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.000572783790095167,
        "codecarbon_cpu_energy_kwh": 0.0001987856472569435,
        "codecarbon_gpu_energy_kwh": 0.00028049244661600137
      },
      "batch_size": 8,
      "num_prompts": 30,
      "max_new_tokens": 150,
      "workload_description": "Instruction (Throughput, bsz=8)"
    }
  },
  "completed_workloads": [
    "hellaswag_latency_b1",
    "mmlu_latency_b1",
    "ifeval_latency_b1",
    "hellaswag_throughput_b8",
    "mmlu_throughput_b8",
    "ifeval_throughput_b8"
  ],
  "failed_workloads": []
}