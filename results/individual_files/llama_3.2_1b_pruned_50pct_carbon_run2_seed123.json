{
  "metadata": {
    "model_name": "Llama-3.2-1B-pruned-50%-run2",
    "started_at": "2025-11-07T13:09:19.268796",
    "last_updated": "2025-11-07T13:13:57.302965",
    "mode": "carbon_profiling"
  },
  "results": {
    "hellaswag_latency_b1": {
      "mode": "latency",
      "avg_ttft_ms": 391.9446869900352,
      "std_ttft_ms": 9.965052600496257,
      "throughput_tokens_per_sec": 51.02760839441735,
      "total_loop_time_sec": 39.325252056121826,
      "total_new_tokens": 1900,
      "avg_new_tokens_per_prompt": 20.0,
      "num_measured_prompts": 95,
      "num_warmup_prompts": 5,
      "memory_allocated_gb": 1.5607962608337402,
      "memory_reserved_gb": 2.39453125,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 1.5518836975097656,
      "energy_kwh": 0.00012051925179107749,
      "energy_raw_kwh": 0.00047197078022019167,
      "energy_idle_kwh": 0.0003514515284291142,
      "joules_per_token": 0.22835226655151525,
      "joules_per_token_calculation": {
        "total_joules": 433.86930644787896,
        "total_tokens": 1900,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T13:10:01.066864",
        "project_name": "N/A",
        "duration_sec": 40.098106145858765,
        "energy_kwh": 0.00012051925179107749,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 1.5607962608337402,
        "gpu_memory_reserved_gb": 2.39453125,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 76,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.00047197078022019167,
        "energy_idle_contribution_kwh": 0.0003514515284291142,
        "energy_net_kwh": 0.00012051925179107749,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.001351475829607866,
        "codecarbon_cpu_energy_kwh": 0.00047235365936321237,
        "codecarbon_gpu_energy_kwh": 0.0006569035810779916
      },
      "batch_size": 1,
      "num_prompts": 100,
      "max_new_tokens": 20,
      "workload_description": "Short responses (Latency, TTFT, bsz=1)"
    },
    "mmlu_latency_b1": {
      "mode": "latency",
      "avg_ttft_ms": 961.5117123252467,
      "std_ttft_ms": 98.31681715129929,
      "throughput_tokens_per_sec": 51.46501066185345,
      "total_loop_time_sec": 96.33633494377136,
      "total_new_tokens": 4701,
      "avg_new_tokens_per_prompt": 49.48421052631579,
      "num_measured_prompts": 95,
      "num_warmup_prompts": 5,
      "memory_allocated_gb": 1.5607962608337402,
      "memory_reserved_gb": 2.40234375,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 1.5518836975097656,
      "energy_kwh": 0.0002842130433984956,
      "energy_raw_kwh": 0.001136503261516536,
      "energy_idle_kwh": 0.0008522902181180404,
      "joules_per_token": 0.21764878881824803,
      "joules_per_token_calculation": {
        "total_joules": 1023.1669562345841,
        "total_tokens": 4701,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T13:11:39.964915",
        "project_name": "N/A",
        "duration_sec": 97.24021911621094,
        "energy_kwh": 0.0002842130433984956,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 1.5607962608337402,
        "gpu_memory_reserved_gb": 2.40234375,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 76,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.001136503261516536,
        "energy_idle_contribution_kwh": 0.0008522902181180404,
        "energy_net_kwh": 0.0002842130433984956,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.003254346990492771,
        "codecarbon_cpu_energy_kwh": 0.0011453259534416494,
        "codecarbon_gpu_energy_kwh": 0.001570190145039993
      },
      "batch_size": 1,
      "num_prompts": 100,
      "max_new_tokens": 50,
      "workload_description": "Knowledge QA (Latency, TTFT, bsz=1)"
    },
    "ifeval_latency_b1": {
      "mode": "latency",
      "avg_ttft_ms": 2871.1993980407715,
      "std_ttft_ms": 54.92512525015581,
      "throughput_tokens_per_sec": 52.04793512494249,
      "total_loop_time_sec": 86.30251717567444,
      "total_new_tokens": 3736,
      "avg_new_tokens_per_prompt": 149.44,
      "num_measured_prompts": 25,
      "num_warmup_prompts": 5,
      "memory_allocated_gb": 1.5607962608337402,
      "memory_reserved_gb": 2.388671875,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 1.5518836975097656,
      "energy_kwh": 0.0002581742140961616,
      "energy_raw_kwh": 0.0010224505862669036,
      "energy_idle_kwh": 0.000764276372170742,
      "joules_per_token": 0.24877600930036986,
      "joules_per_token_calculation": {
        "total_joules": 929.4271707461818,
        "total_tokens": 3736,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T13:13:08.820714",
        "project_name": "N/A",
        "duration_sec": 87.19846868515015,
        "energy_kwh": 0.0002581742140961616,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 1.5607962608337402,
        "gpu_memory_reserved_gb": 2.388671875,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 76,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.0010224505862669036,
        "energy_idle_contribution_kwh": 0.000764276372170742,
        "energy_net_kwh": 0.0002581742140961616,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0029277601754571416,
        "codecarbon_cpu_energy_kwh": 0.001027023528856276,
        "codecarbon_gpu_energy_kwh": 0.0014175647451619977
      },
      "batch_size": 1,
      "num_prompts": 30,
      "max_new_tokens": 150,
      "workload_description": "Instruction (Latency, TTFT, bsz=1)"
    },
    "hellaswag_throughput_b8": {
      "mode": "throughput",
      "avg_ttft_ms": null,
      "std_ttft_ms": null,
      "avg_batch_time_ms": 560.0757598876953,
      "throughput_tokens_per_sec": 272.69038166889624,
      "total_loop_time_sec": 7.344274520874023,
      "total_new_tokens": 1680,
      "avg_new_tokens_per_prompt": 19.09090909090909,
      "num_measured_prompts": 88,
      "num_warmup_batches": 2,
      "memory_allocated_gb": 1.5607962608337402,
      "memory_reserved_gb": 2.416015625,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 1.5518836975097656,
      "energy_kwh": 2.3290392893255963e-05,
      "energy_raw_kwh": 9.484697199947192e-05,
      "energy_idle_kwh": 7.155657910621596e-05,
      "joules_per_token": 0.04990798477126278,
      "joules_per_token_calculation": {
        "total_joules": 83.84541441572146,
        "total_tokens": 1680,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T13:13:18.675309",
        "project_name": "N/A",
        "duration_sec": 8.164093971252441,
        "energy_kwh": 2.3290392893255963e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 1.5607962608337402,
        "gpu_memory_reserved_gb": 2.416015625,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 76,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 9.484697199947192e-05,
        "energy_idle_contribution_kwh": 7.155657910621596e-05,
        "energy_net_kwh": 2.3290392893255963e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0002715917924176961,
        "codecarbon_cpu_energy_kwh": 9.617505150414636e-05,
        "codecarbon_gpu_energy_kwh": 0.0001301767708079965
      },
      "batch_size": 8,
      "num_prompts": 100,
      "max_new_tokens": 20,
      "workload_description": "Short responses (Throughput, bsz=8)"
    },
    "mmlu_throughput_b8": {
      "mode": "throughput",
      "avg_ttft_ms": null,
      "std_ttft_ms": null,
      "avg_batch_time_ms": 1349.7756177728827,
      "throughput_tokens_per_sec": 282.8752992650573,
      "total_loop_time_sec": 17.696841716766357,
      "total_new_tokens": 4200,
      "avg_new_tokens_per_prompt": 47.72727272727273,
      "num_measured_prompts": 88,
      "num_warmup_batches": 2,
      "memory_allocated_gb": 1.5607962608337402,
      "memory_reserved_gb": 2.416015625,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 1.5518836975097656,
      "energy_kwh": 5.4620060890184187e-05,
      "energy_raw_kwh": 0.00021728268871316444,
      "energy_idle_kwh": 0.00016266262782298026,
      "joules_per_token": 0.046817195048729304,
      "joules_per_token_calculation": {
        "total_joules": 196.63221920466307,
        "total_tokens": 4200,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T13:13:38.892098",
        "project_name": "N/A",
        "duration_sec": 18.558642625808716,
        "energy_kwh": 5.4620060890184187e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 1.5607962608337402,
        "gpu_memory_reserved_gb": 2.416015625,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 77,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.00021728268871316444,
        "energy_idle_contribution_kwh": 0.00016266262782298026,
        "energy_net_kwh": 5.4620060890184187e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0006221832246713495,
        "codecarbon_cpu_energy_kwh": 0.00021846291916180325,
        "codecarbon_gpu_energy_kwh": 0.0003009635741039879
      },
      "batch_size": 8,
      "num_prompts": 100,
      "max_new_tokens": 50,
      "workload_description": "Knowledge QA (Throughput, bsz=8)"
    },
    "ifeval_throughput_b8": {
      "mode": "throughput",
      "avg_ttft_ms": null,
      "std_ttft_ms": null,
      "avg_batch_time_ms": 3961.9220892588296,
      "throughput_tokens_per_sec": 277.64301650004955,
      "total_loop_time_sec": 15.875733375549316,
      "total_new_tokens": 3300,
      "avg_new_tokens_per_prompt": 137.5,
      "num_measured_prompts": 24,
      "num_warmup_batches": 1,
      "memory_allocated_gb": 1.5607962608337402,
      "memory_reserved_gb": 2.416015625,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 1.5518836975097656,
      "energy_kwh": 4.273957219580877e-05,
      "energy_raw_kwh": 0.00018965397094729776,
      "energy_idle_kwh": 0.000146914398751489,
      "joules_per_token": 0.04662498784997321,
      "joules_per_token_calculation": {
        "total_joules": 153.8624599049116,
        "total_tokens": 3300,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T13:13:57.301052",
        "project_name": "N/A",
        "duration_sec": 16.761882305145264,
        "energy_kwh": 4.273957219580877e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 1.5607962608337402,
        "gpu_memory_reserved_gb": 2.416015625,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 77,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.00018965397094729776,
        "energy_idle_contribution_kwh": 0.000146914398751489,
        "energy_net_kwh": 4.273957219580877e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0005430691230606396,
        "codecarbon_cpu_energy_kwh": 0.00019744423218820404,
        "codecarbon_gpu_energy_kwh": 0.000252757424427999
      },
      "batch_size": 8,
      "num_prompts": 30,
      "max_new_tokens": 150,
      "workload_description": "Instruction (Throughput, bsz=8)"
    }
  },
  "completed_workloads": [
    "hellaswag_latency_b1",
    "mmlu_latency_b1",
    "ifeval_latency_b1",
    "hellaswag_throughput_b8",
    "mmlu_throughput_b8",
    "ifeval_throughput_b8"
  ],
  "failed_workloads": []
}