{
  "metadata": {
    "model_name": "Llama-3.2-1B-pruned-10%-run2",
    "started_at": "2025-11-07T12:18:06.868224",
    "last_updated": "2025-11-07T12:21:28.919051",
    "mode": "carbon_profiling"
  },
  "results": {
    "hellaswag_latency_b1": {
      "mode": "latency",
      "avg_ttft_ms": 162.0165046892668,
      "std_ttft_ms": 159.925096872734,
      "throughput_tokens_per_sec": 49.76750924358762,
      "total_loop_time_sec": 15.8522310256958,
      "total_new_tokens": 766,
      "avg_new_tokens_per_prompt": 8.063157894736841,
      "num_measured_prompts": 95,
      "num_warmup_prompts": 5,
      "memory_allocated_gb": 2.1616110801696777,
      "memory_reserved_gb": 2.490234375,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 2.1519203186035156,
      "energy_kwh": 5.82943590008138e-05,
      "energy_raw_kwh": 0.00020436196976908645,
      "energy_idle_kwh": 0.00014606761076827265,
      "joules_per_token": 0.2739682668445557,
      "joules_per_token_calculation": {
        "total_joules": 209.85969240292968,
        "total_tokens": 766,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T12:18:25.217829",
        "project_name": "N/A",
        "duration_sec": 16.66526985168457,
        "energy_kwh": 5.82943590008138e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 2.1616110801696777,
        "gpu_memory_reserved_gb": 2.490234375,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 77,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.00020436196976908645,
        "energy_idle_contribution_kwh": 0.00014606761076827265,
        "energy_net_kwh": 5.82943590008138e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0005851850881639767,
        "codecarbon_cpu_energy_kwh": 0.00019612559252708546,
        "codecarbon_gpu_energy_kwh": 0.0002967894040980003
      },
      "batch_size": 1,
      "num_prompts": 100,
      "max_new_tokens": 20,
      "workload_description": "Short responses (Latency, TTFT, bsz=1)"
    },
    "mmlu_latency_b1": {
      "mode": "latency",
      "avg_ttft_ms": 730.873966217041,
      "std_ttft_ms": 391.21882405176285,
      "throughput_tokens_per_sec": 51.27242991632034,
      "total_loop_time_sec": 73.52876901626587,
      "total_new_tokens": 3560,
      "avg_new_tokens_per_prompt": 37.473684210526315,
      "num_measured_prompts": 95,
      "num_warmup_prompts": 5,
      "memory_allocated_gb": 2.1616110801696777,
      "memory_reserved_gb": 2.498046875,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 2.1519203186035156,
      "energy_kwh": 0.00027320788508806407,
      "energy_raw_kwh": 0.0009255030757119329,
      "energy_idle_kwh": 0.0006522951906238688,
      "joules_per_token": 0.2762776366059075,
      "joules_per_token_calculation": {
        "total_joules": 983.5483863170307,
        "total_tokens": 3560,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T12:19:41.286971",
        "project_name": "N/A",
        "duration_sec": 74.42221665382385,
        "energy_kwh": 0.00027320788508806407,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 2.1616110801696777,
        "gpu_memory_reserved_gb": 2.498046875,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 73,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.0009255030757119329,
        "energy_idle_contribution_kwh": 0.0006522951906238688,
        "energy_net_kwh": 0.00027320788508806407,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0026501535465158974,
        "codecarbon_cpu_energy_kwh": 0.0008764162705923406,
        "codecarbon_gpu_energy_kwh": 0.0013614263669180018
      },
      "batch_size": 1,
      "num_prompts": 100,
      "max_new_tokens": 50,
      "workload_description": "Knowledge QA (Latency, TTFT, bsz=1)"
    },
    "ifeval_latency_b1": {
      "mode": "latency",
      "avg_ttft_ms": 1811.6924476623535,
      "std_ttft_ms": 1346.0320198914972,
      "throughput_tokens_per_sec": 51.620240577074696,
      "total_loop_time_sec": 55.15206217765808,
      "total_new_tokens": 2338,
      "avg_new_tokens_per_prompt": 93.52,
      "num_measured_prompts": 25,
      "num_warmup_prompts": 5,
      "memory_allocated_gb": 2.1616110801696777,
      "memory_reserved_gb": 2.484375,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 2.1519203186035156,
      "energy_kwh": 0.00020426618454436572,
      "energy_raw_kwh": 0.0006955754971353173,
      "energy_idle_kwh": 0.0004913093125909516,
      "joules_per_token": 0.3145244928826846,
      "joules_per_token_calculation": {
        "total_joules": 735.3582643597166,
        "total_tokens": 2338,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T12:20:38.998417",
        "project_name": "N/A",
        "duration_sec": 56.0548791885376,
        "energy_kwh": 0.00020426618454436572,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 2.1616110801696777,
        "gpu_memory_reserved_gb": 2.484375,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 78,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.0006955754971353173,
        "energy_idle_contribution_kwh": 0.0004913093125909516,
        "energy_net_kwh": 0.00020426618454436572,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.001991762014604564,
        "codecarbon_cpu_energy_kwh": 0.0006602384514805585,
        "codecarbon_gpu_energy_kwh": 0.0010209335945240011
      },
      "batch_size": 1,
      "num_prompts": 30,
      "max_new_tokens": 150,
      "workload_description": "Instruction (Latency, TTFT, bsz=1)"
    },
    "hellaswag_throughput_b8": {
      "mode": "throughput",
      "avg_ttft_ms": null,
      "std_ttft_ms": null,
      "avg_batch_time_ms": 598.9876226945357,
      "throughput_tokens_per_sec": 245.26231485088599,
      "total_loop_time_sec": 7.920431613922119,
      "total_new_tokens": 1616,
      "avg_new_tokens_per_prompt": 18.363636363636363,
      "num_measured_prompts": 88,
      "num_warmup_batches": 2,
      "memory_allocated_gb": 2.1616110801696777,
      "memory_reserved_gb": 2.51171875,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 2.1519203186035156,
      "energy_kwh": 3.396912422577093e-05,
      "energy_raw_kwh": 0.00011030507090182718,
      "energy_idle_kwh": 7.633594667605625e-05,
      "joules_per_token": 0.07567379159206396,
      "joules_per_token_calculation": {
        "total_joules": 122.28884721277535,
        "total_tokens": 1616,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T12:20:49.367702",
        "project_name": "N/A",
        "duration_sec": 8.709385633468628,
        "energy_kwh": 3.396912422577093e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 2.1616110801696777,
        "gpu_memory_reserved_gb": 2.51171875,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 76,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.00011030507090182718,
        "energy_idle_contribution_kwh": 7.633594667605625e-05,
        "energy_net_kwh": 3.396912422577093e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0003158556492362781,
        "codecarbon_cpu_energy_kwh": 0.00010257644801805617,
        "codecarbon_gpu_energy_kwh": 0.00016502290979599973
      },
      "batch_size": 8,
      "num_prompts": 100,
      "max_new_tokens": 20,
      "workload_description": "Short responses (Throughput, bsz=8)"
    },
    "mmlu_throughput_b8": {
      "mode": "throughput",
      "avg_ttft_ms": null,
      "std_ttft_ms": null,
      "avg_batch_time_ms": 1417.2012372450395,
      "throughput_tokens_per_sec": 269.4170536856256,
      "total_loop_time_sec": 18.670921325683594,
      "total_new_tokens": 4200,
      "avg_new_tokens_per_prompt": 47.72727272727273,
      "num_measured_prompts": 88,
      "num_warmup_batches": 2,
      "memory_allocated_gb": 2.1616110801696777,
      "memory_reserved_gb": 2.759765625,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 2.1519203186035156,
      "energy_kwh": 7.72969607812152e-05,
      "energy_raw_kwh": 0.0002487160712140613,
      "energy_idle_kwh": 0.0001714191104328461,
      "joules_per_token": 0.06625453781247016,
      "joules_per_token_calculation": {
        "total_joules": 278.2690588123747,
        "total_tokens": 4200,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T12:21:10.574087",
        "project_name": "N/A",
        "duration_sec": 19.557694673538208,
        "energy_kwh": 7.72969607812152e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 2.1616110801696777,
        "gpu_memory_reserved_gb": 2.759765625,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 76,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.0002487160712140613,
        "energy_idle_contribution_kwh": 0.0001714191104328461,
        "energy_net_kwh": 7.72969607812152e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0007121918829890567,
        "codecarbon_cpu_energy_kwh": 0.00023019281079861417,
        "codecarbon_gpu_energy_kwh": 0.0003737244656459998
      },
      "batch_size": 8,
      "num_prompts": 100,
      "max_new_tokens": 50,
      "workload_description": "Knowledge QA (Throughput, bsz=8)"
    },
    "ifeval_throughput_b8": {
      "mode": "throughput",
      "avg_ttft_ms": null,
      "std_ttft_ms": null,
      "avg_batch_time_ms": 3927.833000818888,
      "throughput_tokens_per_sec": 280.05263965414724,
      "total_loop_time_sec": 15.730024814605713,
      "total_new_tokens": 3300,
      "avg_new_tokens_per_prompt": 137.5,
      "num_measured_prompts": 24,
      "num_warmup_batches": 1,
      "memory_allocated_gb": 2.1616110801696777,
      "memory_reserved_gb": 2.51171875,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 2.1519203186035156,
      "energy_kwh": 6.229794340405296e-05,
      "energy_raw_kwh": 0.00020857426186791895,
      "energy_idle_kwh": 0.000146276318463866,
      "joules_per_token": 0.06796139280442141,
      "joules_per_token_calculation": {
        "total_joules": 224.27259625459067,
        "total_tokens": 3300,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T12:21:28.917374",
        "project_name": "N/A",
        "duration_sec": 16.68908190727234,
        "energy_kwh": 6.229794340405296e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 2.1616110801696777,
        "gpu_memory_reserved_gb": 2.51171875,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 76,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.00020857426186791895,
        "energy_idle_contribution_kwh": 0.000146276318463866,
        "energy_net_kwh": 6.229794340405296e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0005972468750317239,
        "codecarbon_cpu_energy_kwh": 0.0001965134894486122,
        "codecarbon_gpu_energy_kwh": 0.0003082985799719995
      },
      "batch_size": 8,
      "num_prompts": 30,
      "max_new_tokens": 150,
      "workload_description": "Instruction (Throughput, bsz=8)"
    }
  },
  "completed_workloads": [
    "hellaswag_latency_b1",
    "mmlu_latency_b1",
    "ifeval_latency_b1",
    "hellaswag_throughput_b8",
    "mmlu_throughput_b8",
    "ifeval_throughput_b8"
  ],
  "failed_workloads": []
}