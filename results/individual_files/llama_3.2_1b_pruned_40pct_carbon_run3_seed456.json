{
  "metadata": {
    "model_name": "Llama-3.2-1B-pruned-40%-run3",
    "started_at": "2025-11-07T13:00:07.017908",
    "last_updated": "2025-11-07T13:04:32.404822",
    "mode": "carbon_profiling"
  },
  "results": {
    "hellaswag_latency_b1": {
      "mode": "latency",
      "avg_ttft_ms": 399.53350016945285,
      "std_ttft_ms": 6.498772356378358,
      "throughput_tokens_per_sec": 50.05838056512774,
      "total_loop_time_sec": 40.09999990463257,
      "total_new_tokens": 1900,
      "avg_new_tokens_per_prompt": 20.0,
      "num_measured_prompts": 95,
      "num_warmup_prompts": 5,
      "memory_allocated_gb": 1.7099661827087402,
      "memory_reserved_gb": 1.748046875,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 1.7020301818847656,
      "energy_kwh": 0.00012067297565965528,
      "energy_raw_kwh": 0.0004791997106420525,
      "energy_idle_kwh": 0.0003585267349823972,
      "joules_per_token": 0.22864353282882052,
      "joules_per_token_calculation": {
        "total_joules": 434.422712374759,
        "total_tokens": 1900,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T13:00:49.574877",
        "project_name": "N/A",
        "duration_sec": 40.90533661842346,
        "energy_kwh": 0.00012067297565965528,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 1.7099661827087402,
        "gpu_memory_reserved_gb": 1.748046875,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 73,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.0004791997106420525,
        "energy_idle_contribution_kwh": 0.0003585267349823972,
        "energy_net_kwh": 0.00012067297565965528,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.001372175680421732,
        "codecarbon_cpu_energy_kwh": 0.00048182409477707584,
        "codecarbon_gpu_energy_kwh": 0.0006636744198279948
      },
      "batch_size": 1,
      "num_prompts": 100,
      "max_new_tokens": 20,
      "workload_description": "Short responses (Latency, TTFT, bsz=1)"
    },
    "mmlu_latency_b1": {
      "mode": "latency",
      "avg_ttft_ms": 931.581795843024,
      "std_ttft_ms": 216.79075794570116,
      "throughput_tokens_per_sec": 50.5761165406279,
      "total_loop_time_sec": 93.5502564907074,
      "total_new_tokens": 4476,
      "avg_new_tokens_per_prompt": 47.11578947368421,
      "num_measured_prompts": 95,
      "num_warmup_prompts": 5,
      "memory_allocated_gb": 1.7099661827087402,
      "memory_reserved_gb": 1.771484375,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 1.7020301818847656,
      "energy_kwh": 0.00027663510585712895,
      "energy_raw_kwh": 0.0011043351920738095,
      "energy_idle_kwh": 0.0008277000862166805,
      "joules_per_token": 0.2224947232094871,
      "joules_per_token_calculation": {
        "total_joules": 995.8863810856642,
        "total_tokens": 4476,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T13:02:25.683868",
        "project_name": "N/A",
        "duration_sec": 94.43466091156006,
        "energy_kwh": 0.00027663510585712895,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 1.7099661827087402,
        "gpu_memory_reserved_gb": 1.771484375,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 73,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.0011043351920738095,
        "energy_idle_contribution_kwh": 0.0008277000862166805,
        "energy_net_kwh": 0.00027663510585712895,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0031622345755743944,
        "codecarbon_cpu_energy_kwh": 0.0011122861544659612,
        "codecarbon_gpu_energy_kwh": 0.0015266714991139935
      },
      "batch_size": 1,
      "num_prompts": 100,
      "max_new_tokens": 50,
      "workload_description": "Knowledge QA (Latency, TTFT, bsz=1)"
    },
    "ifeval_latency_b1": {
      "mode": "latency",
      "avg_ttft_ms": 2468.4543228149414,
      "std_ttft_ms": 959.5751430210199,
      "throughput_tokens_per_sec": 50.93065682359202,
      "total_loop_time_sec": 74.76772046089172,
      "total_new_tokens": 3143,
      "avg_new_tokens_per_prompt": 125.72,
      "num_measured_prompts": 25,
      "num_warmup_prompts": 5,
      "memory_allocated_gb": 1.7099661827087402,
      "memory_reserved_gb": 1.7421875,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 1.7020301818847656,
      "energy_kwh": 0.00021902761974947386,
      "energy_raw_kwh": 0.0008820335660195391,
      "energy_idle_kwh": 0.0006630059462700653,
      "joules_per_token": 0.250874779223069,
      "joules_per_token_calculation": {
        "total_joules": 788.4994310981059,
        "total_tokens": 3143,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T13:03:43.001752",
        "project_name": "N/A",
        "duration_sec": 75.64423727989197,
        "energy_kwh": 0.00021902761974947386,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 1.7099661827087402,
        "gpu_memory_reserved_gb": 1.7421875,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 72,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.0008820335660195391,
        "energy_idle_contribution_kwh": 0.0006630059462700653,
        "energy_net_kwh": 0.00021902761974947386,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.002525679756747033,
        "codecarbon_cpu_energy_kwh": 0.0008910442050708127,
        "codecarbon_gpu_energy_kwh": 0.0012154434723539997
      },
      "batch_size": 1,
      "num_prompts": 30,
      "max_new_tokens": 150,
      "workload_description": "Instruction (Latency, TTFT, bsz=1)"
    },
    "hellaswag_throughput_b8": {
      "mode": "throughput",
      "avg_ttft_ms": null,
      "std_ttft_ms": null,
      "avg_batch_time_ms": 592.9201082749801,
      "throughput_tokens_per_sec": 257.584910000121,
      "total_loop_time_sec": 7.7771570682525635,
      "total_new_tokens": 1680,
      "avg_new_tokens_per_prompt": 19.09090909090909,
      "num_measured_prompts": 88,
      "num_warmup_batches": 2,
      "memory_allocated_gb": 1.7099661827087402,
      "memory_reserved_gb": 2.044921875,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 1.7020301818847656,
      "energy_kwh": 2.4802112072226998e-05,
      "energy_raw_kwh": 9.97923010786519e-05,
      "energy_idle_kwh": 7.49901890064249e-05,
      "joules_per_token": 0.053147383011914996,
      "joules_per_token_calculation": {
        "total_joules": 89.2876034600172,
        "total_tokens": 1680,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T13:03:53.230621",
        "project_name": "N/A",
        "duration_sec": 8.5558443069458,
        "energy_kwh": 2.4802112072226998e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 1.7099661827087402,
        "gpu_memory_reserved_gb": 2.044921875,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 72,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 9.97923010786519e-05,
        "energy_idle_contribution_kwh": 7.49901890064249e-05,
        "energy_net_kwh": 2.4802112072226998e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0002857526112651056,
        "codecarbon_cpu_energy_kwh": 0.00010078543367776768,
        "codecarbon_gpu_energy_kwh": 0.00013756761005400547
      },
      "batch_size": 8,
      "num_prompts": 100,
      "max_new_tokens": 20,
      "workload_description": "Short responses (Throughput, bsz=8)"
    },
    "mmlu_throughput_b8": {
      "mode": "throughput",
      "avg_ttft_ms": null,
      "std_ttft_ms": null,
      "avg_batch_time_ms": 1391.9987245039506,
      "throughput_tokens_per_sec": 274.29492218410303,
      "total_loop_time_sec": 18.140650749206543,
      "total_new_tokens": 4200,
      "avg_new_tokens_per_prompt": 47.72727272727273,
      "num_measured_prompts": 88,
      "num_warmup_batches": 2,
      "memory_allocated_gb": 1.7099661827087402,
      "memory_reserved_gb": 2.13671875,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 1.7020301818847656,
      "energy_kwh": 5.546860315828499e-05,
      "energy_raw_kwh": 0.00022196986023711388,
      "energy_idle_kwh": 0.0001665012570788289,
      "joules_per_token": 0.04754451699281571,
      "joules_per_token_calculation": {
        "total_joules": 199.68697136982595,
        "total_tokens": 4200,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T13:04:13.883873",
        "project_name": "N/A",
        "duration_sec": 18.996602773666382,
        "energy_kwh": 5.546860315828499e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 1.7099661827087402,
        "gpu_memory_reserved_gb": 2.13671875,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 75,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.00022196986023711388,
        "energy_idle_contribution_kwh": 0.0001665012570788289,
        "energy_net_kwh": 5.546860315828499e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.0006356048161963346,
        "codecarbon_cpu_energy_kwh": 0.00022375193785278087,
        "codecarbon_gpu_energy_kwh": 0.0003066033008379959
      },
      "batch_size": 8,
      "num_prompts": 100,
      "max_new_tokens": 50,
      "workload_description": "Knowledge QA (Throughput, bsz=8)"
    },
    "ifeval_throughput_b8": {
      "mode": "throughput",
      "avg_ttft_ms": null,
      "std_ttft_ms": null,
      "avg_batch_time_ms": 3969.849427541097,
      "throughput_tokens_per_sec": 277.08859493981714,
      "total_loop_time_sec": 15.950626134872437,
      "total_new_tokens": 3300,
      "avg_new_tokens_per_prompt": 137.5,
      "num_measured_prompts": 24,
      "num_warmup_batches": 1,
      "memory_allocated_gb": 1.7099661827087402,
      "memory_reserved_gb": 1.84765625,
      "max_memory_allocated_gb": 5.055957794189453,
      "model_size_gb": 1.7020301818847656,
      "energy_kwh": 4.620249663256701e-05,
      "energy_raw_kwh": 0.00019372698846600108,
      "energy_idle_kwh": 0.00014752449183343407,
      "joules_per_token": 0.050402723599164014,
      "joules_per_token_calculation": {
        "total_joules": 166.32898787724125,
        "total_tokens": 3300,
        "formula": "total_joules / total_tokens"
      },
      "hardware_metadata": {
        "timestamp": "2025-11-07T13:04:32.403079",
        "project_name": "N/A",
        "duration_sec": 16.83148956298828,
        "energy_kwh": 4.620249663256701e-05,
        "co2_g": "N/A",
        "carbon_intensity_gCO2_kWh": "N/A",
        "country_name": "N/A",
        "country_iso_code": "N/A",
        "region": "N/A",
        "cloud_provider": "N/A",
        "cloud_region": "N/A",
        "os": "N/A",
        "python_version": "N/A",
        "codecarbon_version": "3.0.8",
        "cpu_model": "N/A",
        "cpu_count": 0,
        "cpu_power_usage_W": "N/A",
        "gpu_model": "N/A",
        "gpu_count": 0,
        "gpu_power_usage_W": "N/A",
        "gpu_name_torch": "NVIDIA L4",
        "gpu_total_memory_gb": 22.1610107421875,
        "gpu_compute_capability": "8.9",
        "gpu_memory_allocated_gb": 1.7099661827087402,
        "gpu_memory_reserved_gb": 1.84765625,
        "cuda_version": "12.6",
        "torch_version": "2.8.0+cu126",
        "gpu_temperature_celsius": 77,
        "idle_power_watts": 31.553248368950225,
        "idle_power_applied": true,
        "energy_raw_kwh": 0.00019372698846600108,
        "energy_idle_contribution_kwh": 0.00014752449183343407,
        "energy_net_kwh": 4.620249663256701e-05,
        "idle_correction_note": "Net energy = Raw energy - (Idle power \u00d7 Duration)",
        "codecarbon_overhead_estimated_pct": 2.5,
        "pue_assumption": "unknown (datacenter PUE not measured)",
        "codecarbon_total_energy_internal_kwh": 0.000554732100856699,
        "codecarbon_cpu_energy_kwh": 0.0001981729817069348,
        "codecarbon_gpu_energy_kwh": 0.0002633332662219934
      },
      "batch_size": 8,
      "num_prompts": 30,
      "max_new_tokens": 150,
      "workload_description": "Instruction (Throughput, bsz=8)"
    }
  },
  "completed_workloads": [
    "hellaswag_latency_b1",
    "mmlu_latency_b1",
    "ifeval_latency_b1",
    "hellaswag_throughput_b8",
    "mmlu_throughput_b8",
    "ifeval_throughput_b8"
  ],
  "failed_workloads": []
}